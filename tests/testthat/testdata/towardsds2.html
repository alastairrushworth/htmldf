<!doctype html><html lang="en"><head><script>!function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a="pointerup",u="pointercancel";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;"pointerdown"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)}}function w(e){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(n){e(n,l,r)})}w(c),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){e.push(n),s()}}(addEventListener,removeEventListener)</script><script defer src="https://cdn.optimizely.com/js/16180790160.js"></script><title data-rh="true">Multinomial Mixture Model for Supermarket Shoppers Segmentation | by Adrien Biarnes | Oct, 2020 | Towards Data Science</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2020-10-16T04:19:56.407Z"/><meta data-rh="true" name="title" content="Multinomial Mixture Model for Supermarket Shoppers Segmentation | by Adrien Biarnes | Oct, 2020 | Towards Data Science"/><meta data-rh="true" property="og:title" content="Multinomial Mixture Model for Supermarket Shoppers Segmentation (A complete tutorial)"/><meta data-rh="true" property="twitter:title" content="Multinomial Mixture Model for Supermarket Shoppers Segmentation (A complete tutorial)"/><meta data-rh="true" name="twitter:site" content="@TDataScience"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/268974d905da"/><meta data-rh="true" property="al:android:url" content="medium://p/268974d905da"/><meta data-rh="true" property="al:ios:url" content="medium://p/268974d905da"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="In my last article, I wrote a detailed explanation of the Gaussian Mixture Model (GMM) and the way it is trained using the Expectation-Maximization (EM) algorithm. This time, I wanted to show that a…"/><meta data-rh="true" property="og:description" content="Complete analysis and implementation of a multinomial mixture model for supermarket shopper segmentation and predictive profiles prediction"/><meta data-rh="true" property="twitter:description" content="Complete analysis and implementation of a multinomial mixture model for supermarket shopper segmentation and predictive profiles prediction"/><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/multinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da"/><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/multinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/0*x_whGwu1M7rsjHAM"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/0*x_whGwu1M7rsjHAM"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" property="article:author" content="https://towardsdatascience.com/@biarnes.adrien"/><meta data-rh="true" name="author" content="Adrien Biarnes"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" name="twitter:label1" value="Reading time"/><meta data-rh="true" name="twitter:data1" value="31 min read"/><meta data-rh="true" name="parsely-post-id" content="268974d905da"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://towardsdatascience.com/@biarnes.adrien"/><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/multinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/268974d905da"/><link data-rh="true" rel="icon" href="https://miro.medium.com/fit/c/256/256/1*ChFMdf--f5jbm-AYv6VdYA@2x.png"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F0*x_whGwu1M7rsjHAM"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da","dateCreated":"2020-10-14T15:01:15.741Z","datePublished":"2020-10-14T15:01:15.741Z","dateModified":"2020-10-16T04:20:05.633Z","headline":"Multinomial Mixture Model for Supermarket Shoppers Segmentation","name":"Multinomial Mixture Model for Supermarket Shoppers Segmentation","description":"In my last article, I wrote a detailed explanation of the Gaussian Mixture Model (GMM) and the way it is trained using the Expectation-Maximization (EM) algorithm. This time, I wanted to show that a…","identifier":"268974d905da","keywords":["Lite:true","Tag:Bayesian Statistics","Tag:Marketing","Tag:Statistics","Tag:Machine Learning","Tag:Mixture Models","Topic:Machine Learning","Topic:Math","Topic:Data Science","Publication:towards-data-science","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_UGC","LayerCake:3"],"author":{"@type":"Person","name":"Adrien Biarnes","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@biarnes.adrien"},"creator":["Adrien Biarnes"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F330\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da","isAccessibleForFree":"False","hasPart":{"@type":"WebPageElement","isAccessibleForFree":"False","cssSelector":".meteredContent"}}</script><script data-rh="true" >(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><link rel="preload" href="https://cdn.optimizely.com/js/16180790160.js" as="script"><style type="text/css" data-fela-rehydration="732" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{transform:translateX(-1%)}20%{transform:translateX(1%)}40%{transform:translateX(-1%)}60%{transform:translateX(1%)}80%{transform:translateX(-1%)}100%{transform:translateX(1%)}}@-moz-keyframes k1{0%{transform:translateX(-1%)}20%{transform:translateX(1%)}40%{transform:translateX(-1%)}60%{transform:translateX(1%)}80%{transform:translateX(-1%)}100%{transform:translateX(1%)}}@keyframes k1{0%{transform:translateX(-1%)}20%{transform:translateX(1%)}40%{transform:translateX(-1%)}60%{transform:translateX(1%)}80%{transform:translateX(-1%)}100%{transform:translateX(1%)}}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{height:35px}.r{fill:rgba(41, 41, 41, 1)}.s{display:block}.t{position:absolute}.u{top:0}.v{left:0}.w{right:0}.x{z-index:500}.y{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.ah{max-width:1192px}.ai{min-width:0}.aj{width:100%}.ak{height:65px}.an{flex:1 0 auto}.ao{height:25px}.ap{fill:rgba(25, 25, 25, 1)}.aq{flex:0 0 auto}.ar{visibility:hidden}.as{margin-left:16px}.at{color:rgba(102, 138, 170, 1)}.au{fill:rgba(102, 138, 170, 1)}.av{font-size:inherit}.aw{border:inherit}.ax{font-family:inherit}.ay{letter-spacing:inherit}.az{font-weight:inherit}.ba{padding:0}.bb{margin:0}.bc:hover{cursor:pointer}.bd:hover{color:rgba(90, 118, 144, 1)}.be:hover{fill:rgba(90, 118, 144, 1)}.bf:disabled{cursor:default}.bg:disabled{color:rgba(26, 137, 23, 0.3)}.bh:disabled{fill:rgba(26, 137, 23, 0.3)}.bi{border-top:none}.bj{background-color:rgba(53, 88, 118, 1)}.bl{height:54px}.bm{overflow:hidden}.bn{margin-right:40px}.bo{height:36px}.bp{width:100px}.bq{overflow:auto}.br{flex:0 1 auto}.bs{list-style-type:none}.bt{line-height:40px}.bu{white-space:nowrap}.bv{overflow-x:auto}.bw{align-items:flex-start}.bx{margin-top:20px}.by{padding-top:20px}.bz{height:80px}.ca{height:20px}.cb{margin-right:15px}.cc{margin-left:15px}.cd:first-child{margin-left:0}.ce{min-width:1px}.cf{background-color:rgba(178, 195, 212, 1)}.cg{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.ch{font-size:13px}.ci{line-height:20px}.cj{color:rgba(233, 241, 250, 1)}.ck{text-transform:uppercase}.cl{letter-spacing:1px}.cm{color:inherit}.cn{fill:inherit}.co:hover{color:rgba(242, 248, 253, 1)}.cp:hover{fill:rgba(242, 248, 253, 1)}.cq:disabled{color:rgba(197, 210, 225, 1)}.cr:disabled{fill:rgba(197, 210, 225, 1)}.cs{margin-bottom:0px}.ct{margin-top:0px}.cu{height:119px}.cx{padding-left:24px}.cy{padding-right:24px}.cz{margin-left:auto}.da{margin-right:auto}.db{max-width:728px}.dc{box-sizing:border-box}.dd{top:calc(100vh + 100px)}.de{bottom:calc(100vh + 100px)}.df{width:10px}.dg{pointer-events:none}.dh{word-break:break-word}.di{word-wrap:break-word}.dj:after{display:block}.dk:after{content:""}.dl:after{clear:both}.dm{max-width:680px}.dn{line-height:1.23}.do{letter-spacing:0}.dp{font-style:normal}.dq{font-family:fell, Georgia, Cambria, "Times New Roman", Times, serif}.el{margin-bottom:-0.27em}.em{color:rgba(41, 41, 41, 1)}.en{line-height:1.394}.fd{margin-bottom:-0.42em}.fe{color:rgba(117, 117, 117, 1)}.ff{margin-top:32px}.fg{justify-content:space-between}.fk{position:relative}.fl{width:48px}.fm{height:48px}.fn{fill:rgba(26, 137, 23, 1)}.fo{flex-direction:row}.fp{width:calc(100% + 25px)}.fq{height:calc(100% + 25px)}.fr{top:50%}.fs{left:50%}.ft{transform:translateX(-50%) translateY(-50%)}.fu{border-radius:50%}.fv{margin-left:12px}.fw{font-size:14px}.fx{margin-bottom:2px}.fz{max-height:20px}.ga{text-overflow:ellipsis}.gb{display:-webkit-box}.gc{-webkit-line-clamp:1}.gd{-webkit-box-orient:vertical}.gf:hover{text-decoration:underline}.gg:disabled{color:rgba(117, 117, 117, 1)}.gh:disabled{fill:rgba(117, 117, 117, 1)}.gi{margin-left:8px}.gj{padding:0px 8px 1px}.gk{background:0}.gl{border-color:rgba(117, 117, 117, 1)}.gm:hover{color:rgba(8, 8, 8, 1)}.gn:hover{fill:rgba(8, 8, 8, 1)}.go:hover{border-color:rgba(41, 41, 41, 1)}.gp:disabled{cursor:inherit}.gq:disabled{opacity:0.3}.gr:disabled:hover{color:rgba(41, 41, 41, 1)}.gs:disabled:hover{fill:rgba(41, 41, 41, 1)}.gt:disabled:hover{border-color:rgba(117, 117, 117, 1)}.gu{border-radius:4px}.gv{border-width:1px}.gw{border-style:solid}.gx{display:inline-block}.gy{text-decoration:none}.gz{align-items:flex-end}.hh{padding-right:6px}.hi:hover{color:rgba(25, 25, 25, 1)}.hj:hover{fill:rgba(25, 25, 25, 1)}.hk{fill:rgba(117, 117, 117, 1)}.hl{margin-right:8px}.hm{margin-right:-6px}.hn{clear:both}.hw{max-width:4696px}.ic{padding-bottom:5px}.id{padding-top:5px}.ie{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.if{cursor:zoom-in}.ig{z-index:auto}.ih{opacity:0}.ii{transition:opacity 100ms 400ms}.ij{height:100%}.ik{will-change:transform}.il{transform:translateZ(0)}.im{margin:auto}.in{background-color:rgba(242, 242, 242, 1)}.io{padding-bottom:66.67376490630325%}.ip{height:0}.iq{filter:blur(20px)}.ir{transform:scale(1.1)}.is{visibility:visible}.it{margin-top:10px}.iu{text-align:center}.ix{text-decoration:underline}.iy{line-height:1.58}.iz{letter-spacing:-0.004em}.ja{font-family:charter, Georgia, Cambria, "Times New Roman", Times, serif}.jt{margin-bottom:-0.46em}.ju{box-shadow:inset 3px 0 0 0 rgba(41, 41, 41, 1)}.jv{padding-left:23px}.jw{margin-left:-20px}.jx{font-style:italic}.jy{font-weight:700}.jz{line-height:1.12}.ka{letter-spacing:-0.022em}.kb{font-weight:500}.ku{margin-bottom:-0.28em}.la{list-style-type:decimal}.lb{margin-left:30px}.lc{padding-left:0px}.li{padding-bottom:7.788719785138765%}.lj{line-height:1.18}.lr{margin-bottom:-0.31em}.ls{max-width:536px}.lt{padding-bottom:9.701492537313433%}.lu{max-width:393px}.lv{padding-bottom:72.264631043257%}.lw{max-width:475px}.lx{padding-bottom:31.157894736842103%}.ly{padding-bottom:39.1578947368421%}.lz{max-width:582px}.ma{padding-bottom:74.22680412371133%}.mb{max-width:407px}.mc{padding-bottom:69.77886977886978%}.md{max-width:697px}.me{padding-bottom:52.22381635581061%}.mf{max-width:725px}.mg{padding-bottom:48.689655172413794%}.mh{max-width:899px}.mi{padding-bottom:27.91991101223582%}.mj{max-width:446px}.mk{padding-bottom:97.75784753363229%}.ml{max-width:516px}.mm{padding-bottom:80.62015503875969%}.mn{max-width:923px}.mo{padding-bottom:46.15384615384616%}.mp{max-width:930px}.mq{padding-bottom:18.709677419354836%}.mr{max-width:333px}.ms{padding-bottom:28.22822822822823%}.mt{max-width:760px}.mu{padding-bottom:21.973684210526315%}.mv{max-width:982px}.mw{padding-bottom:35.13238289205703%}.mx{max-width:325px}.my{padding-bottom:107.38461538461539%}.ne{padding-bottom:22.77314611671786%}.nf{max-width:396px}.ng{padding-bottom:87.37373737373737%}.nh{padding-bottom:18.410852713178294%}.ni{padding-bottom:23.063063063063062%}.nj{max-width:335px}.nk{padding-bottom:29.552238805970152%}.nl{max-width:341px}.nm{padding-bottom:23.75366568914956%}.nn{max-width:481px}.no{padding-bottom:9.563409563409563%}.np{max-width:1306px}.nq{padding-bottom:9.571209800918837%}.nr{max-width:444px}.ns{padding-bottom:28.153153153153152%}.nt{max-width:239px}.nu{padding-bottom:38.912133891213394%}.nv{max-width:520px}.nw{padding-bottom:43.269230769230774%}.nx{max-width:1398px}.ny{padding-bottom:16.80972818311874%}.nz{max-width:125px}.oa{padding-bottom:133.6%}.ob{max-width:1449px}.oc{padding-bottom:9.66183574879227%}.od{max-width:1607px}.oe{padding-bottom:85.31425015556938%}.of{max-width:1602px}.og{padding-bottom:63.73283395755306%}.oh{padding-bottom:NaN%}.oi{list-style-type:disc}.oj{max-width:684px}.ok{padding-bottom:17.982456140350877%}.ol{max-width:921px}.om{padding-bottom:48.534201954397396%}.on{max-width:950px}.oo{padding-bottom:13.473684210526315%}.op{max-width:689px}.oq{padding-bottom:18.72278664731495%}.or{max-width:948px}.os{padding-bottom:12.763713080168777%}.ot{padding-bottom:18.274853801169588%}.ou{max-width:957px}.ov{padding-bottom:13.375130616509926%}.ow{max-width:324px}.ox{padding-bottom:20.061728395061728%}.oy{max-width:968px}.oz{padding-bottom:30.578512396694215%}.pa{max-width:960px}.pb{padding-bottom:33.229166666666664%}.pc{max-width:4600px}.pd{padding-bottom:74.95652173913044%}.pe{max-width:738px}.pf{padding-bottom:95.66395663956641%}.pg{max-width:729px}.ph{padding-bottom:34.43072702331961%}.pi{max-width:870px}.pj{padding-bottom:44.48275862068966%}.pk{max-width:640px}.pl{padding-bottom:59.53125%}.pm{max-width:301px}.pn{padding-bottom:60.797342192691026%}.po{max-width:1829px}.pp{padding-bottom:56.15090213231274%}.pq{max-width:1062px}.pr{padding-bottom:31.638418079096045%}.ps{max-width:241px}.pt{padding-bottom:39.004149377593365%}.pu{padding-bottom:51.71467764060357%}.pv{max-width:1755px}.pw{padding-bottom:76.80911680911682%}.px{max-width:750px}.py{padding-bottom:15.200000000000001%}.pz{max-width:387px}.qa{padding-bottom:24.54780361757106%}.qb{max-width:1852px}.qc{padding-bottom:22.08423326133909%}.qd{max-width:912px}.qe{padding-bottom:13.267543859649123%}.qf{max-width:712px}.qg{padding-bottom:54.21348314606742%}.qh{max-width:678px}.qi{padding-bottom:17.10914454277286%}.qj{padding-bottom:48.43412526997841%}.qk{max-width:454px}.ql{padding-bottom:24.669603524229075%}.qm{max-width:289px}.qn{padding-bottom:70.24221453287197%}.qo{padding-bottom:34.6875%}.qp{max-width:615px}.qq{padding-bottom:95.77235772357724%}.qr{will-change:opacity}.qs{position:fixed}.qt{width:188px}.qu{transform:translateX(406px)}.qv{top:calc(65px + 54px + 14px)}.qy{top:159px}.ra{width:131px}.rb{flex-direction:column}.rc{font-size:16px}.rd{padding-bottom:28px}.re{border-bottom:1px solid rgba(230, 230, 230, 1)}.rf{padding-bottom:20px}.rg{padding-top:2px}.rh{max-height:120px}.ri{-webkit-line-clamp:6}.rj{padding:4px 12px 6px}.rk{border-color:rgba(102, 138, 170, 1)}.rl:hover{border-color:rgba(90, 118, 144, 1)}.rm:disabled:hover{color:rgba(102, 138, 170, 1)}.rn:disabled:hover{fill:rgba(102, 138, 170, 1)}.ro:disabled:hover{border-color:rgba(102, 138, 170, 1)}.rp{padding-top:28px}.rq{margin-bottom:19px}.rr{margin-left:-3px}.rx{outline:0}.ry{border:0}.rz{user-select:none}.sa{cursor:pointer}.sb> svg{pointer-events:none}.sc:active{border-style:none}.sd{-webkit-user-select:none}.se:focus{fill:rgba(117, 117, 117, 1)}.sf:hover{fill:rgba(117, 117, 117, 1)}.sn button{text-align:left}.so{opacity:0.4}.sp{cursor:not-allowed}.sq{padding-right:4px}.sz{margin-top:40px}.ta{border-top:3px solid rgba(102, 138, 170, 1)}.tb{padding:32px 32px 26px 32px}.tc{margin-top:8px}.td{margin-bottom:25px}.te{background-color:rgba(250, 250, 250, 1)}.tg{padding-top:4px}.th{padding-bottom:10px}.ti{padding-top:8px}.tt{flex-wrap:wrap}.tu{justify-content:flex-start}.tv{display:inline}.tw{height:56px}.ub{margin-top:}.ud{background:transparent}.ue{border:none}.uf{outline:none}.ug::-webkit-inner-spin-button{-webkit-appearance:none}.uh::-webkit-inner-spin-button{-moz-appearance:none}.ui::-webkit-inner-spin-button{appearance:none}.uj::-webkit-inner-spin-button{margin:0}.uk::-webkit-outer-spin-button{-webkit-appearance:none}.ul::-webkit-outer-spin-button{-moz-appearance:none}.um::-webkit-outer-spin-button{appearance:none}.un::-webkit-outer-spin-button{margin:0}.uo{width:375px}.up{font:inherit}.uq{padding-left:auto}.ur{padding-right:auto}.us{text-align:start}.ut::placeholder{color:rgba(117, 117, 117, 1)}.uu{padding-bottom:1px}.uv{border-bottom:1px solid rgba(168, 168, 168, 1)}.uw{line-height:24px}.ux{margin-bottom:auto}.uz{color:rgba(255, 255, 255, 1)}.va{padding:7px 20px 9px}.vb{fill:rgba(255, 255, 255, 1)}.vc{background:rgba(102, 138, 170, 1)}.vd:hover{background:rgba(90, 118, 144, 1)}.ve:disabled:hover{background:rgba(102, 138, 170, 1)}.vf{padding-top:}.vg{font-size:11px}.vh{line-height:16px}.vi{margin-bottom:15px}.vj{margin-top:5px}.vk{display:none}.vl{margin-top:25px}.vm{margin-bottom:8px}.vn{line-height:22px}.vo{border-radius:3px}.vp{padding:5px 10px}.vq{background:rgba(242, 242, 242, 1)}.vr{max-width:155px}.vv{top:1px}.wj{margin-left:-1px}.wk{margin-left:-4px}.ws{padding-right:8px}.wt{padding-top:32px}.wu{border-top:1px solid rgba(230, 230, 230, 1)}.ww{margin-bottom:32px}.wx{min-height:80px}.xc{width:80px}.xd{padding-left:102px}.xf{line-height:18px}.xg{letter-spacing:0.077em}.xh{margin-bottom:6px}.xi{font-size:22px}.xj{line-height:28px}.xk{max-width:555px}.xl{max-width:450px}.xn{max-width:550px}.xo{padding-top:24px}.xp{width:40px}.xq{height:40px}.xr{font-size:12px}.xs{letter-spacing:0.083em}.xt{padding-top:25px}.xv{background:rgba(255, 255, 255, 1)}.xw{margin-bottom:40px}.xx{margin-top:24px}.xy{padding-bottom:16px}.xz{margin-bottom:24px}.zj{flex-grow:0}.zk{padding-bottom:24px}.zl{max-width:500px}.zp{padding-bottom:8px}.zx{padding-bottom:100%}.abi{padding:60px 0}.abj{background-color:rgba(0, 0, 0, 0.9)}.abl{padding-bottom:48px}.abm{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.abn{margin:0 -12px}.abo{margin:0 12px}.abp{flex:1 1 0}.abq:hover{color:rgba(255, 255, 255, 0.99)}.abr:hover{fill:rgba(255, 255, 255, 0.99)}.abs:disabled{color:rgba(255, 255, 255, 0.7)}.abt:disabled{fill:rgba(255, 255, 255, 0.7)}.abu{font-size:20px}.abv{color:rgba(255, 255, 255, 0.98)}.abw{color:rgba(255, 255, 255, 0.7)}.abx{height:22px}.aby{width:200px}.ace{margin-right:16px}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.ag{margin:0 64px}.eh{font-size:48px}.ei{margin-top:0.55em}.ej{line-height:60px}.ek{letter-spacing:-0.011em}.fa{font-size:22px}.fb{margin-top:0.92em}.fc{line-height:28px}.hg{margin-left:30px}.hv{max-width:1192px}.ib{margin-top:56px}.jp{font-size:21px}.jq{margin-top:2em}.jr{line-height:32px}.js{letter-spacing:-0.003em}.kq{font-size:30px}.kr{margin-top:1.95em}.ks{line-height:36px}.kt{letter-spacing:0}.kz{margin-top:0.86em}.lh{margin-top:1.05em}.lq{margin-top:1.72em}.nd{margin-top:80px}.rw{margin-right:5px}.sm{margin-top:5px}.sy{padding-left:6px}.tr{font-size:16px}.ts{line-height:24px}.vx{display:inline-block}.wc{margin-left:7px}.wd{margin-top:8px}.wi{width:25px}.wq{padding-left:7px}.wr{top:3px}.yo{width:calc(100% + 32px)}.yp{margin-left:-16px}.yq{margin-right:-16px}.zf{padding-left:16px}.zg{padding-right:16px}.zh{flex-basis:25%}.zi{max-width:25%}.zu{line-height:20px}.abg{min-width:70px}.abh{min-height:70px}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.hf{margin-left:30px}.iv{margin-left:auto}.iw{text-align:center}.rv{margin-right:5px}.sl{margin-top:5px}.sx{padding-left:6px}.vw{display:inline-block}.wa{margin-left:7px}.wb{margin-top:8px}.wh{width:25px}.wo{padding-left:7px}.wp{top:3px}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.he{margin-left:30px}.ru{margin-right:5px}.sk{margin-top:5px}.sv{padding-left:6px}.sw{top:3px}.vu{display:inline-block}.vy{margin-left:7px}.vz{margin-top:8px}.wg{width:15px}.wn{padding-left:3px}.zo{margin-right:16px}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.al{height:56px}.am{display:flex}.bk{display:block}.cv{margin-bottom:0px}.cw{height:110px}.fi{margin-top:32px}.fj{flex-direction:column-reverse}.hc{margin-bottom:30px}.hd{margin-left:0px}.rt{margin-left:8px}.si{margin-top:2px}.sj{margin-right:8px}.st{padding-left:6px}.su{top:3px}.tf{padding:24px 24px 28px 24px}.tx{padding-top:16px}.ty{height:130px}.tz{align-items:flex-start}.ua{flex-direction:column}.uc{margin-top:0}.uy{margin-top:15px}.vt{display:inline-block}.wf{width:15px}.wm{padding-left:3px}.wv{padding-top:0}.wy{margin-bottom:24px}.wz{align-items:center}.xa{width:102px}.xb{position:relative}.xe{padding-left:0}.xm{margin-top:24px}.xu{border-top:none}.ya{padding-bottom:12px}.yb{margin-top:16px}.zn{margin-right:16px}.zv{margin-left:16px}.zw{margin-right:0px}.abk{padding:32px 0}.abz{width:140px}.aca{margin-bottom:16px}.acb{margin-top:30px}.acc{width:100%}.acd{flex-direction:row}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.ab{margin:0 24px}.dr{font-size:34px}.ds{margin-top:0.56em}.dt{line-height:42px}.du{letter-spacing:-0.016em}.eo{font-size:18px}.ep{margin-top:0.79em}.eq{line-height:24px}.fh{margin-top:32px}.fy{margin-bottom:0px}.ha{margin-bottom:30px}.hb{margin-left:0px}.ho{margin:0}.hp{max-width:100%}.hx{margin-top:40px}.jb{margin-top:1.56em}.jc{line-height:28px}.jd{letter-spacing:-0.003em}.kc{font-size:22px}.kd{margin-top:1.2em}.ke{letter-spacing:0}.kv{margin-top:0.67em}.ld{margin-top:1.34em}.lk{font-size:20px}.ll{margin-top:1.23em}.mz{margin-top:48px}.rs{margin-left:8px}.sg{margin-top:2px}.sh{margin-right:8px}.sr{padding-left:6px}.ss{top:3px}.tj{font-size:14px}.tk{line-height:20px}.vs{display:inline-block}.we{width:15px}.wl{padding-left:3px}.yc{width:calc(100% + 24px)}.yd{margin-left:-12px}.ye{margin-right:-12px}.yr{padding-left:12px}.ys{padding-right:12px}.yt{flex-basis:100%}.zm{margin-right:16px}.zq{font-size:16px}.zy{min-width:48px}.zz{min-height:48px}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.af{margin:0 64px}.ed{font-size:48px}.ee{margin-top:0.55em}.ef{line-height:60px}.eg{letter-spacing:-0.011em}.ex{font-size:22px}.ey{margin-top:0.92em}.ez{line-height:28px}.hu{max-width:1192px}.ia{margin-top:56px}.jl{font-size:21px}.jm{margin-top:2em}.jn{line-height:32px}.jo{letter-spacing:-0.003em}.km{font-size:30px}.kn{margin-top:1.95em}.ko{line-height:36px}.kp{letter-spacing:0}.ky{margin-top:0.86em}.lg{margin-top:1.05em}.lp{margin-top:1.72em}.nc{margin-top:80px}.tp{font-size:16px}.tq{line-height:24px}.yl{width:calc(100% + 32px)}.ym{margin-left:-16px}.yn{margin-right:-16px}.zb{padding-left:16px}.zc{padding-right:16px}.zd{flex-basis:25%}.ze{max-width:25%}.zt{line-height:20px}.abe{min-width:70px}.abf{min-height:70px}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.ae{margin:0 48px}.dz{font-size:48px}.ea{margin-top:0.55em}.eb{line-height:60px}.ec{letter-spacing:-0.011em}.eu{font-size:22px}.ev{margin-top:0.92em}.ew{line-height:28px}.hs{margin:0}.ht{max-width:100%}.hz{margin-top:56px}.jh{font-size:21px}.ji{margin-top:2em}.jj{line-height:32px}.jk{letter-spacing:-0.003em}.ki{font-size:30px}.kj{margin-top:1.95em}.kk{line-height:36px}.kl{letter-spacing:0}.kx{margin-top:0.86em}.lf{margin-top:1.05em}.lo{margin-top:1.72em}.nb{margin-top:80px}.tn{font-size:16px}.to{line-height:24px}.yi{width:calc(100% + 28px)}.yj{margin-left:-14px}.yk{margin-right:-14px}.yx{padding-left:14px}.yy{padding-right:14px}.yz{flex-basis:50%}.za{max-width:50%}.zs{line-height:20px}.abc{min-width:48px}.abd{min-height:48px}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ac{margin:0 24px}.dv{font-size:34px}.dw{margin-top:0.56em}.dx{line-height:42px}.dy{letter-spacing:-0.016em}.er{font-size:18px}.es{margin-top:0.79em}.et{line-height:24px}.hq{margin:0}.hr{max-width:100%}.hy{margin-top:40px}.je{margin-top:1.56em}.jf{line-height:28px}.jg{letter-spacing:-0.003em}.kf{font-size:22px}.kg{margin-top:1.2em}.kh{letter-spacing:0}.kw{margin-top:0.67em}.le{margin-top:1.34em}.lm{font-size:20px}.ln{margin-top:1.23em}.na{margin-top:48px}.tl{font-size:14px}.tm{line-height:20px}.yf{width:calc(100% + 24px)}.yg{margin-left:-12px}.yh{margin-right:-12px}.yu{padding-left:12px}.yv{padding-right:12px}.yw{flex-basis:100%}.zr{font-size:16px}.aba{min-width:48px}.abb{min-height:48px}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="print">.z{display:none}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.ge{max-height:none}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.qw{transition:opacity 200ms}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (max-width: 1230px)">.qx{display:none}</style><style type="text/css" data-fela-rehydration="732" data-fela-type="RULE" media="all and (max-width: 1198px)">.qz{display:none}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><nav class="s t u v w c x y z"><div><div class="s c"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="ak n o al am"><div class="n o an x"><a href="https://medium.com/?source=post_page-----268974d905da--------------------------------" rel="noopener"><svg viewBox="0 0 1043.63 592.71" class="ao ap"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a></div><div class="s aq x"><div class="n o"><div class="n o g"><div class="ar" id="lo-post-page-navbar-sign-in-link"><div class="as s"><span><a href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=--------------------------nav_reg-----------" class="at au av aw ax ay az ba bb bc bd be bf bg bh" rel="noopener">Sign in</a></span></div></div></div></div></div></div></div></div></div><div class="bi s bj bk"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="bl bm n o"><div class="bn s aq"><a href="https://towardsdatascience.com/?source=post_page-----268974d905da--------------------------------" rel="noopener"><div class="bo bp s"><img alt="Towards Data Science" class="" src="https://miro.medium.com/max/200/1*mG6i4Bh_LgixUYXJgQpYsg@2x.png" width="100" height="36"/></div></a></div><div class="bq s br"><ul class="bs bb bt bu bv n bw g bx by bz"><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://towardsdatascience.com/data-science/home?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">Data Science</a></span></li><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://towardsdatascience.com/machine-learning/home?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">Machine Learning</a></span></li><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://towardsdatascience.com/programming/home?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">Programming</a></span></li><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://towardsdatascience.com/data-visualization/home?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">Visualization</a></span></li><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://towardsdatascience.com/video/home?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">Video</a></span></li><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://towardsdatascience.com/editors-picks/home?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">★</a></span></li><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://towardsdatascience.com/about-us/home?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">About</a></span></li><span class="ca ce cf"></span><li class="n o ca cb cc cd"><span class="cg b ch ci cj ck cl"><a href="https://towardsdatascience.com/contribute/home?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc co cp bf cq cr" rel="noopener">Contribute</a></span></li></ul></div></div></div></div></div></div></nav><div class="cs ct cu s cv cw"></div><article class="meteredContent"><section class="cx cy cz da aj db dc s"></section><span class="s"></span><div><div class="t v dd de df dg"></div><section class="dh di dj dk dl"><div class="n p"><div class="ab ac ae af ag dm ai aj"><div><h1 id="b3ba" class="dn do dp dq b dr ds dt du dv dw dx dy dz ea eb ec ed ee ef eg eh ei ej ek el em">Multinomial Mixture Model for Supermarket Shoppers Segmentation</h1></div><h2 id="5d70" class="en do dp cg b eo ep eq er es et eu ev ew ex ey ez fa fb fc fd fe">A complete tutorial</h2><div class="ff"><div class="n fg fh fi fj"><div class="o n"><div><a href="/@biarnes.adrien?source=post_page-----268974d905da--------------------------------" rel="noopener"><div class="fk fl fm"><div class="fn n fo o p t fp fq fr fs ft dg"><svg width="57" height="57" viewBox="0 0 57 57"><path fill-rule="evenodd" clip-rule="evenodd" d="M28.5 1.2A27.45 27.45 0 0 0 4.06 15.82L3 15.27A28.65 28.65 0 0 1 28.5 0C39.64 0 49.29 6.2 54 15.27l-1.06.55A27.45 27.45 0 0 0 28.5 1.2zM4.06 41.18A27.45 27.45 0 0 0 28.5 55.8a27.45 27.45 0 0 0 24.44-14.62l1.06.55A28.65 28.65 0 0 1 28.5 57 28.65 28.65 0 0 1 3 41.73l1.06-.55z"></path></svg></div><img alt="Adrien Biarnes" class="s fu fm fl" src="https://miro.medium.com/fit/c/96/96/0*WCSvEV6fU3deUzGB." width="48" height="48"/></div></a></div><div class="fv aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="fx n o fy"><span class="cg b fw ci bm fz ga gb gc gd ge em"><a href="/@biarnes.adrien?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Adrien Biarnes</a></span><div class="gi s aq h"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fuser%2F151fca431deb&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=-151fca431deb-------------------------follow_byline-----------" class="cg b ch ci em gj r gk gl gm gn go bc gp gq gr gs gt gu gv gw dc gx gy" rel="noopener">Follow</a></span></div></div></span></div></div><span class="cg b fw ci fe"><span class="cg b fw ci bm fz ga gb gc gd ge fe"><div><a class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener" href="/multinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da?source=post_page-----268974d905da--------------------------------">Oct 14</a> <!-- -->·<!-- --> <!-- -->31<!-- --> min read<span style="padding-left:4px"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top:-2px"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div><div class="n gz ha hb hc hd he hf hg z"><div class="n o"><div class="hh s aq"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" aria-label="Share on twitter"><svg width="29" height="29" class="hk"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></button></div><div class="hh s aq"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" aria-label="Share on linkedin"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="hk"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="hh s aq"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" aria-label="Share on facebook"><svg width="29" height="29" class="hk"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></button></div><div class="hl s"><div class="hk"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=post_actions_header--------------------------bookmark_preview-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div><div class="hm s an"></div></div></div></div></div></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da hw"><div class="im s fk in"><div class="io ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/0*x_whGwu1M7rsjHAM?q=20" width="4696" height="3131"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="4696" height="3131"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/9392/0*x_whGwu1M7rsjHAM" width="4696" height="3131" srcSet="https://miro.medium.com/max/552/0*x_whGwu1M7rsjHAM 276w, https://miro.medium.com/max/1104/0*x_whGwu1M7rsjHAM 552w, https://miro.medium.com/max/1280/0*x_whGwu1M7rsjHAM 640w, https://miro.medium.com/max/1456/0*x_whGwu1M7rsjHAM 728w, https://miro.medium.com/max/1632/0*x_whGwu1M7rsjHAM 816w, https://miro.medium.com/max/1808/0*x_whGwu1M7rsjHAM 904w, https://miro.medium.com/max/1984/0*x_whGwu1M7rsjHAM 992w, https://miro.medium.com/max/2000/0*x_whGwu1M7rsjHAM 1000w" sizes="1000px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Photo by <a href="https://unsplash.com/@pvsbond?utm_source=medium&amp;utm_medium=referral" class="cm ix" rel="noopener nofollow">Peter Bond</a> on <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" class="cm ix" rel="noopener nofollow">Unsplash</a></figcaption></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="2482" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In <a class="cm ix" rel="noopener" href="/gaussian-mixture-models-and-expectation-maximization-a-full-explanation-50fa94111ddd">my last article</a>, I wrote a detailed explanation of the Gaussian Mixture Model (GMM) and the way it is trained using the Expectation-Maximization (EM) algorithm. This time, I wanted to show that a mixture model is not necessarily a mixture of Gaussian densities. It can be a mixture of any distribution. In this example, we are going to use a mixture of multinomial distributions.</p><p id="d5d8" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Also, the idea is, for once, not to solely focus on the mathematical and computer science aspects of a data science project but on the business side too. Therefore we are going to use a real-world data set with a concrete application in the marketing domain. It will hopefully allow the reader to get a better vision of why we do the things we do :-). Additionally, we will introduce a bit of data visualization on the matter of picturing the multinomial distribution.</p><blockquote class="ju jv jw"><p id="6fc1" class="iy iz jx ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">This work has been <strong class="ja jy">majorly inspired</strong> by a research paper from Cadez et al. entitled “<a href="http://www.datalab.uci.edu/papers/profiles.pdf" class="cm ix" rel="noopener nofollow"><strong class="ja jy">Predictive Profiles for Transaction Data using Finite Mixture Models</strong></a>”. A big part of the credit goes to them.</p></blockquote><h1 id="65a3" class="jz ka dp cg kb kc kd jc ke kf kg jf kh ki kj kk kl km kn ko kp kq kr ks kt ku em">Framing the business context</h1><p id="a0df" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">In this era of supercomputers, machine learning, and data science, almost every business out there is collecting data about the different facets of its activities and try to use it for its own benefit. The food industry and in particular supermarkets are no exception to that rule. Supermarkets collect purchasing data or what is most commonly known as transaction data. It can be mined in order to extract insights and improve the efficiency of overall operations.</p><p id="000a" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">One way to extract relevant patterns is to start by a clustering process. The idea is to group similar items together. It can be thought of as splitting the data set into clusters in such a way that data points inside a cluster have high similarity and points outside that cluster a low similarity.</p><p id="d53b" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In traditional marketing applications, the most important usage of such a clustering procedure is exploratory data analysis. We want to split the observations into a small number of clusters in order to better describe, interpret, and study them independently. The common usage is to proceed with customer segmentation. Each segment will have its own set of characteristics. For example, an output segment, for an online e-commerce website, could be described as “<em class="jx">price-sensitive customers under 30, engaged primarily through digital channels”</em>. Such projects are among the most frequently performed in marketing analytics because of their strategic importance. It allows building corporate marketing strategies around customer segments and their typical needs and properties.</p><p id="10d1" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The goal of this project is to perform the clustering of a supermarket transaction data set in order to build predictive profiles of individuals. Such profiles support many different types of further analysis. Among them we find building customer segments for targeted marketing strategies, extracting somewhat hidden product associations, forecasting individual purchasing behaviors, change detection, cross-selling, personalization, and more…</p><p id="990c" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In this article, we are going to:</p><ol class=""><li id="f835" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt la lb lc em">Quickly explore the data set</li><li id="2b02" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt la lb lc em">Explain the modelization using a mixture of multinomial random variables</li><li id="efe2" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt la lb lc em">Derive the mathematical update rules for the Expectation-Maximization</li><li id="bebf" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt la lb lc em">Describe the way to select the optimal number of clusters</li><li id="c65b" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt la lb lc em">Implement everything in plain Python</li><li id="6f13" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt la lb lc em">Analyze the results and derive some insights</li><li id="db20" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt la lb lc em">Explore a second formulation of the problem to better characterize individuals</li></ol><h1 id="3a33" class="jz ka dp cg kb kc kd jc ke kf kg jf kh ki kj kk kl km kn ko kp kq kr ks kt ku em">Dataset exploration</h1><p id="4ca5" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">The dataset for this project was found on Kaggle: “<a href="https://www.kaggle.com/frtgnn/dunnhumby-the-complete-journey" class="cm ix" rel="noopener nofollow">Dunnhumby — The Complete Journey</a>”. Quoting Kaggle, it: “<em class="jx">contains household level transactions over two years from a group of 2,500 households who are frequent shoppers at a retailer. For certain households, demographic information, as well as direct marketing contact history, are included”.</em></p><p id="3caf" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In this work, we are going to focus on the transaction data and the associated products. So let&#x27;s see what the first few transactions look like:</p></div></div><div class="hn aj"><figure class="hx hy hz ia ib hn aj paragraph-image"><div class="im s fk in"><div class="li ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*KuxiYUlTWosoktgnntET8g.png?q=20" width="2234" height="174"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="2234" height="174"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/4468/1*KuxiYUlTWosoktgnntET8g.png" width="2234" height="174" srcSet="https://miro.medium.com/max/552/1*KuxiYUlTWosoktgnntET8g.png 276w, https://miro.medium.com/max/1104/1*KuxiYUlTWosoktgnntET8g.png 552w, https://miro.medium.com/max/1280/1*KuxiYUlTWosoktgnntET8g.png 640w, https://miro.medium.com/max/1456/1*KuxiYUlTWosoktgnntET8g.png 728w, https://miro.medium.com/max/1632/1*KuxiYUlTWosoktgnntET8g.png 816w, https://miro.medium.com/max/1808/1*KuxiYUlTWosoktgnntET8g.png 904w, https://miro.medium.com/max/1984/1*KuxiYUlTWosoktgnntET8g.png 992w, https://miro.medium.com/max/2160/1*KuxiYUlTWosoktgnntET8g.png 1080w, https://miro.medium.com/max/2700/1*KuxiYUlTWosoktgnntET8g.png 1350w, https://miro.medium.com/max/3240/1*KuxiYUlTWosoktgnntET8g.png 1620w, https://miro.medium.com/max/3780/1*KuxiYUlTWosoktgnntET8g.png 1890w, https://miro.medium.com/max/4320/1*KuxiYUlTWosoktgnntET8g.png 2160w, https://miro.medium.com/max/4468/1*KuxiYUlTWosoktgnntET8g.png 2234w" sizes="2234px"/></noscript></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="a22d" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Every line corresponds to a certain quantity of a product being bought in a specific basket (one basket corresponds to one specific checkout) by a given household. This dataset contains 2595732 transactions made among 276484 baskets. The transactions were performed by 2500 households for 92339 different products in 44 department stores among 308 categories and 2383 subcategories.</p><p id="b819" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">There is a lot of useful information but we are not interested in using everything. This exercise is about the unsupervised clustering of the transaction data set using a multinomial mixture model. As we will see, <strong class="ja jy">multinomial mixture models are to be used with categorical data only.</strong> Therefore, we will not consider continuously valued predictors like price or retail discount.</p><p id="e112" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now in order to understand the data selection and preparation process that we are about to perform, we need to make sure that you properly understand the multinomial distribution (if you are already well versed with the multinomial, you can skip this section).</p><h2 id="6611" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Disgression on the multinomial distribution</h2><p id="0fc9" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">The <a href="https://en.wikipedia.org/wiki/Multinomial_distribution" class="cm ix" rel="noopener nofollow">Multinomial distribution</a> is a generalization of the <a href="https://en.wikipedia.org/wiki/Binomial_distribution" class="cm ix" rel="noopener nofollow">Binomial distribution</a> which itself is a generalization of the <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution" class="cm ix" rel="noopener nofollow">Bernoulli distribution</a>. So let&#x27;s start with the Bernoulli.</p><p id="7b75" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">A Bernoulli random variable X depicts the result of a single trial with 2 possible outcomes, 1 or 0, with respective probabilities θ and 1-θ.</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da ls"><div class="im s fk in"><div class="lt ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*2y0kEIeo48sps6uL3m15eQ.png?q=20" width="536" height="52"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="536" height="52"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1072/1*2y0kEIeo48sps6uL3m15eQ.png" width="536" height="52" srcSet="https://miro.medium.com/max/552/1*2y0kEIeo48sps6uL3m15eQ.png 276w, https://miro.medium.com/max/1072/1*2y0kEIeo48sps6uL3m15eQ.png 536w" sizes="536px"/></noscript></div></div></div></figure><p id="8426" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">For example, we could picture the probability mass function of Ber(0.3):</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da lu"><div class="im s fk in"><div class="lv ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*6iWUsgm_BWrfj20hI3Uz5A.png?q=20" width="393" height="284"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="393" height="284"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/786/1*6iWUsgm_BWrfj20hI3Uz5A.png" width="393" height="284" srcSet="https://miro.medium.com/max/552/1*6iWUsgm_BWrfj20hI3Uz5A.png 276w, https://miro.medium.com/max/786/1*6iWUsgm_BWrfj20hI3Uz5A.png 393w" sizes="393px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="b037" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In the frequentist perspective, the true value of a parameter is obtained by measuring the statistics of interest over an infinite number of experiments. In the case of the Bernoulli trial, if we repeat our single experiment an infinite number of times, record the results and average the number of positive outcomes we get the true parameter value of θ (in the above example, we get a positive result 30% of the time).</p><p id="59ee" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now, what if we want to count the number of positive results for not only a single Bernoulli trial but a series of n Bernoulli trials. That is the purpose of a Binomial trial. For example, flipping a coin 10 times, we want to measure the number of times that the coin landed on heads. This time, the output of the Binomial trial can be any discrete value between 0 and 10. The exact formulation of the probability mass function is :</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da lw"><div class="im s fk in"><div class="lx ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*9N1RaeMdYsT91AgdXPfqlQ.png?q=20" width="475" height="148"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="475" height="148"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/950/1*9N1RaeMdYsT91AgdXPfqlQ.png" width="475" height="148" srcSet="https://miro.medium.com/max/552/1*9N1RaeMdYsT91AgdXPfqlQ.png 276w, https://miro.medium.com/max/950/1*9N1RaeMdYsT91AgdXPfqlQ.png 475w" sizes="475px"/></noscript></div></div></div></figure><p id="d235" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Let us see how we can derive this formula from the Bernoulli distribution. So let&#x27;s say for simplicity that we want to record the number of heads that we get out of two coin flips (i.e. two Bernoulli trials). What are the possibilities:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da lw"><div class="im s fk in"><div class="ly ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*4L76qbU59z2qJ_607qCBGw.png?q=20" width="475" height="186"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="475" height="186"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/950/1*4L76qbU59z2qJ_607qCBGw.png" width="475" height="186" srcSet="https://miro.medium.com/max/552/1*4L76qbU59z2qJ_607qCBGw.png 276w, https://miro.medium.com/max/950/1*4L76qbU59z2qJ_607qCBGw.png 475w" sizes="475px"/></noscript></div></div></div></figure><p id="0b39" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">From this enumeration, we get :</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da lz"><div class="im s fk in"><div class="ma ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*1j9610jkD--nOdPg-CMEmg.png?q=20" width="582" height="432"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="582" height="432"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1164/1*1j9610jkD--nOdPg-CMEmg.png" width="582" height="432" srcSet="https://miro.medium.com/max/552/1*1j9610jkD--nOdPg-CMEmg.png 276w, https://miro.medium.com/max/1104/1*1j9610jkD--nOdPg-CMEmg.png 552w, https://miro.medium.com/max/1164/1*1j9610jkD--nOdPg-CMEmg.png 582w" sizes="582px"/></noscript></div></div></div></figure><p id="90d1" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The binomial coefficient in the formula captures the fact that there are different ways of distributing <em class="jx">k</em> successes in a sequence of <em class="jx">n</em> trials. In the example above, there are 2 ways of distributing 1 success among 2 trials. If we increase the number of trials, the number of possible ways to obtain central values increases much more rapidly than the number of possible ways to get extreme values. That is why the distribution gets a nice bell shape.</p><p id="728c" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So the probability mass function can be pictured with the following bar chart in the case of a Binomial trial with 20 independent Bernoulli trials of probability θ = 0.3:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da mb"><div class="im s fk in"><div class="mc ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*3fVmjweboJz_J83IeOfYPw.png?q=20" width="407" height="284"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="407" height="284"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/814/1*3fVmjweboJz_J83IeOfYPw.png" width="407" height="284" srcSet="https://miro.medium.com/max/552/1*3fVmjweboJz_J83IeOfYPw.png 276w, https://miro.medium.com/max/814/1*3fVmjweboJz_J83IeOfYPw.png 407w" sizes="407px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="c806" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The most probable number of positive outcomes for a Binomial trial with 20 independent Bernoulli trials of probability 0.3 is 6. That is the mode of the above distribution.</p><p id="d850" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now how can we generalize this distribution one step further? Well, what if we consider a series of n trials but this time with more than two possible outcomes… For example, we have a bag with 3 different types of balls (blue, red, and yellow) and we want to measure for each color the number of balls that we get out of 2 draws (with replacement). Let&#x27;s enumerate the possibilities:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da md"><div class="im s fk in"><div class="me ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*Hz8XBML7kezZVrSCjV6TYA.png?q=20" width="697" height="364"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="697" height="364"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1394/1*Hz8XBML7kezZVrSCjV6TYA.png" width="697" height="364" srcSet="https://miro.medium.com/max/552/1*Hz8XBML7kezZVrSCjV6TYA.png 276w, https://miro.medium.com/max/1104/1*Hz8XBML7kezZVrSCjV6TYA.png 552w, https://miro.medium.com/max/1280/1*Hz8XBML7kezZVrSCjV6TYA.png 640w, https://miro.medium.com/max/1394/1*Hz8XBML7kezZVrSCjV6TYA.png 697w" sizes="697px"/></noscript></div></div></div></figure><p id="7072" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">From this enumeration, and given that we have at our disposal the proportions of blue, red, and yellow balls, respectively θ_1, θ_2 and θ_3, we can measure the probabilities :</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da mf"><div class="im s fk in"><div class="mg ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*SVJINzR9W-ggnw09N8DemA.png?q=20" width="725" height="353"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="725" height="353"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1450/1*SVJINzR9W-ggnw09N8DemA.png" width="725" height="353" srcSet="https://miro.medium.com/max/552/1*SVJINzR9W-ggnw09N8DemA.png 276w, https://miro.medium.com/max/1104/1*SVJINzR9W-ggnw09N8DemA.png 552w, https://miro.medium.com/max/1280/1*SVJINzR9W-ggnw09N8DemA.png 640w, https://miro.medium.com/max/1400/1*SVJINzR9W-ggnw09N8DemA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="66f1" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">And we can continue on, but I hope that you understand how we can derive the analytical formula for the probability mass function of the multinomial:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da mh"><div class="im s fk in"><div class="mi ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*Dyv6JYH-mI29VlqD_bcDkg.png?q=20" width="899" height="251"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="899" height="251"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1798/1*Dyv6JYH-mI29VlqD_bcDkg.png" width="899" height="251" srcSet="https://miro.medium.com/max/552/1*Dyv6JYH-mI29VlqD_bcDkg.png 276w, https://miro.medium.com/max/1104/1*Dyv6JYH-mI29VlqD_bcDkg.png 552w, https://miro.medium.com/max/1280/1*Dyv6JYH-mI29VlqD_bcDkg.png 640w, https://miro.medium.com/max/1400/1*Dyv6JYH-mI29VlqD_bcDkg.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><h2 id="460c" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">On the visualization of the Multinomial</h2><p id="95ac" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">Ok, so now, what if we want to draw the probability mass function using some sort of bar plot as we did above? Well, this time is going to be a little trickier.</p><blockquote class="ju jv jw"><p id="efb1" class="iy iz jx ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">This is kind of a disgression but it is important that you understand this representation of the multinomial as we will use it later.</p></blockquote><p id="bd6a" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In order to picture a distribution, we need a way to place the possible outcomes on the graph and, for each of them, be able to show their relative importance. That is the purpose of the bar plots we used for the Bernoulli and the Binomial distributions. On the x-axis, we put the ordered possible outcome values and on the y-axis the associated probabilities.</p><p id="ca3f" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now, what about the multinomial? Well, the issue here is that we can no longer use a single random variable to depict the different possibilities. In the Bernoulli and the Binomial, we use a single random variable X to count the number of successes. We don’t use a second random variable for the number of failures because it is obviously deduced from X. But in the case of the Multinomial, we need to introduce at least C-1 random variables for C possible outcomes of the single trial. Note that in the general we even use C random variables (X_1, X_2, …, X_C) like in the formula above for the PMF because it is less cumbersome to write (even if the last random variable value can be deduced).</p><p id="8c0c" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">We are only interested in picturing the distribution with at least 2 possible outcomes and more (otherwise we fall back to the Binomial). Let us consider the case of 3 possible outcomes first. As I said, we could use only two random variables X_1 and X_2 (X_3 can be deduced). We would then need 3 dimensions (for X_1, X_2, and the joint probability P(X_1, X_2)=P(X_1, X_2, X3)). Ok, we can use a 3-dimensional bar plot for that purpose:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da mj"><div class="im s fk in"><div class="mk ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*iIN4QSMr7wMlNXyBKSetjA.png?q=20" width="446" height="436"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="446" height="436"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/892/1*iIN4QSMr7wMlNXyBKSetjA.png" width="446" height="436" srcSet="https://miro.medium.com/max/552/1*iIN4QSMr7wMlNXyBKSetjA.png 276w, https://miro.medium.com/max/892/1*iIN4QSMr7wMlNXyBKSetjA.png 446w" sizes="446px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="9735" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Ok, so what is wrong with this visualization? Well, first of all, we don’t explicitly see the different values for X3. We can deduce them. For example, for the first bin with X1=0 and X2=0, we know that X3=20. But we don’t visualize it. Also, half of the dedicated space for this graph is useless. For example, when X2=20, we know for sure that X1 will never take any value other than 0. So the triangle for half of the bottom floor of this 3d histogram will never display any density because probabilities are null.</p><p id="ed63" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So how can do better? Well, first we can reduce the bottom floor of the histogram to a triangle and more precisely an equilateral triangle. We use an equilateral triangle so that the distances from the vertices to the barycenter are equal. The exact location of any point in this triangle determines the relative proportions of our 3 random variables. This is called a simplex and it is very useful to display a discrete probability vector of 3 values:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da ml"><div class="im s fk in"><div class="mm ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*mOKMWpYOxa1WVAMjBTx9zQ.png?q=20" width="516" height="416"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="516" height="416"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1032/1*mOKMWpYOxa1WVAMjBTx9zQ.png" width="516" height="416" srcSet="https://miro.medium.com/max/552/1*mOKMWpYOxa1WVAMjBTx9zQ.png 276w, https://miro.medium.com/max/1032/1*mOKMWpYOxa1WVAMjBTx9zQ.png 516w" sizes="516px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="cc44" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Also, if we draw every parallel of the triangle sides, that is we discretize the entire triangle space, each intersection can be used to picture the relative proportions of a 3 valued tuple. In the example below, we picture the multinomial with 16 draws and 3 possible values with probabilities 0.25, 0.5, and 0.25:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da mn"><div class="im s fk in"><div class="mo ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*e76ZuT_WZ5b7oii1Z6U2Hg.png?q=20" width="923" height="426"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="923" height="426"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1846/1*e76ZuT_WZ5b7oii1Z6U2Hg.png" width="923" height="426" srcSet="https://miro.medium.com/max/552/1*e76ZuT_WZ5b7oii1Z6U2Hg.png 276w, https://miro.medium.com/max/1104/1*e76ZuT_WZ5b7oii1Z6U2Hg.png 552w, https://miro.medium.com/max/1280/1*e76ZuT_WZ5b7oii1Z6U2Hg.png 640w, https://miro.medium.com/max/1400/1*e76ZuT_WZ5b7oii1Z6U2Hg.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="2f9b" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Finally, and I will stop this disgression here, it is not possible to extend this logic to additional dimensions to picture multinomials with degrees higher than 3. For example, we could try with a square for dimension 4 but it won’t work because a point in the square is only at the crossroad of 2 lines and we need the crossroad of 4 lines for this location to be the container of the proportions of 4 valued tuples.</p><h2 id="8770" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Back to the data</h2><p id="94e0" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">As I previously said, because we want to perform the clustering using a multinomial mixture model, we don’t consider the continuous variables. For the sake of this exercise, we are only going to consider the products, the households, and the baskets. So the columns to be considered are the following:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da mp"><div class="im s fk in"><div class="mq ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*uiHRj_gyEjXt2gfe1IM_-A.png?q=20" width="930" height="174"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="930" height="174"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1860/1*uiHRj_gyEjXt2gfe1IM_-A.png" width="930" height="174" srcSet="https://miro.medium.com/max/552/1*uiHRj_gyEjXt2gfe1IM_-A.png 276w, https://miro.medium.com/max/1104/1*uiHRj_gyEjXt2gfe1IM_-A.png 552w, https://miro.medium.com/max/1280/1*uiHRj_gyEjXt2gfe1IM_-A.png 640w, https://miro.medium.com/max/1400/1*uiHRj_gyEjXt2gfe1IM_-A.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="b557" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">There are 4 columns describing the product purchased in a specific transaction (PRODUCT_ID, DEPARTMENT, COMMODITY_DESC, and SUB_COMMODITY_DESC). We want to group the transactions and, for each group, count the number of products.</p><h2 id="a1af" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Model formulation</h2><p id="5b7b" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">So why do we want to count the number of products? Well, this will allow us to apply the following general model:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da mr"><div class="im s fk in"><div class="ms ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*BjKke6AR1e0GMboE7j_p9A.png?q=20" width="333" height="94"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="333" height="94"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/666/1*BjKke6AR1e0GMboE7j_p9A.png" width="333" height="94" srcSet="https://miro.medium.com/max/552/1*BjKke6AR1e0GMboE7j_p9A.png 276w, https://miro.medium.com/max/666/1*BjKke6AR1e0GMboE7j_p9A.png 333w" sizes="333px"/></noscript></div></div></div></div></figure><p id="05e4" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">This represents the joint probability of observing the full data set. It is the product of individual probabilities (because the observations are collected i.i.d). The probability of observing an observation x_i is a mixture of multinomial distributions. X represents a matrix of counts for the products that were bought. Each line of the matrix, x_i, corresponds to a specific basket (i.e. one shopper checking out from the supermarket). Each multinomial distribution represents the probability of obtaining the counts that we see in a specific basket given that it was generated by a specific cluster k:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da mt"><div class="im s fk in"><div class="mu ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*r_UDMlVDjs1mhmirQKzVww.png?q=20" width="760" height="167"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="760" height="167"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1520/1*r_UDMlVDjs1mhmirQKzVww.png" width="760" height="167" srcSet="https://miro.medium.com/max/552/1*r_UDMlVDjs1mhmirQKzVww.png 276w, https://miro.medium.com/max/1104/1*r_UDMlVDjs1mhmirQKzVww.png 552w, https://miro.medium.com/max/1280/1*r_UDMlVDjs1mhmirQKzVww.png 640w, https://miro.medium.com/max/1400/1*r_UDMlVDjs1mhmirQKzVww.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="5956" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In the above formula, n_i represents the total number of products bought in a given basket. C represents the total number of different products so there is one parameter β_kc by multinomial k and product c. This means that β is a matrix of parameters of dimension k times c and β_k a vector of dimension c. n_ic represents the count of a specific product c bought in a given basket i.</p><p id="dbd6" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Our model uses a mixture of multinomial distributions. It basically makes the assumption that there exists K clusters. It means that the probabilities of items being bought in any given basket are a combination of K typical baskets. The goal of this project is to extract those typical baskets.</p><h2 id="0f6e" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Back to the data</h2><p id="2b55" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">So we need to group the transactions by baskets, and for every basket, count the number of distinct products. But as we just saw, the number of parameters that we will use for this model highly depends on the number of distinct products. The more products we have, the higher the number of parameters. This means that if we have too many products, we might run into troubles during the optimization procedure to find the optimal values for the parameters or the number of clusters. But we are not obliged to count by distinct products (there are 92339 of them). We can count by the department stores (44), the category (308), or the sub-category (2383). This choice will determine the number C in the above formula.</p><p id="46b9" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Obviously, the ideal scenario would be to model the data all the way down to the product level. And in fact, I have tried to do so, and I ran short of memory on my laptop. Not to mention that with so many different components for the multinomial, the problems we might face to select the correct number of clusters are considerably increased (as we will see later). So, to make the distinction between products, we have to choose between the department store, the category, and the sub-category. Let’s see the repartitions of the number of transaction for each department:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da mv"><div class="im s fk in"><div class="mw ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*aVL6ZAyu5Sz8na5Ih_j9Xw.png?q=20" width="982" height="345"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="982" height="345"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1964/1*aVL6ZAyu5Sz8na5Ih_j9Xw.png" width="982" height="345" srcSet="https://miro.medium.com/max/552/1*aVL6ZAyu5Sz8na5Ih_j9Xw.png 276w, https://miro.medium.com/max/1104/1*aVL6ZAyu5Sz8na5Ih_j9Xw.png 552w, https://miro.medium.com/max/1280/1*aVL6ZAyu5Sz8na5Ih_j9Xw.png 640w, https://miro.medium.com/max/1400/1*aVL6ZAyu5Sz8na5Ih_j9Xw.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="8e0c" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So as we can see, the vast majority of the transactions were made in the grocery department. Because this is an exercise, I decide not to bother with the transactions outside the grocery department. Now let’s see how the transactions from the grocery store are spread among categories:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da mx"><div class="im s fk in"><div class="my ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/56/1*9bK3_8ze-b9VlnYOG_gDLg.png?q=20" width="325" height="349"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="325" height="349"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/650/1*9bK3_8ze-b9VlnYOG_gDLg.png" width="325" height="349" srcSet="https://miro.medium.com/max/552/1*9bK3_8ze-b9VlnYOG_gDLg.png 276w, https://miro.medium.com/max/650/1*9bK3_8ze-b9VlnYOG_gDLg.png 325w" sizes="325px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div></div><div class="hn aj"><figure class="mz na nb nc nd hn aj paragraph-image"><div class="ie if fk ig aj"><div class="im s fk in"><div class="ne ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*wuocbRF1SCcn4T9nWu1How.png?q=20" width="9116" height="2076"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="9116" height="2076"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/18232/1*wuocbRF1SCcn4T9nWu1How.png" width="9116" height="2076" srcSet="https://miro.medium.com/max/552/1*wuocbRF1SCcn4T9nWu1How.png 276w, https://miro.medium.com/max/1104/1*wuocbRF1SCcn4T9nWu1How.png 552w, https://miro.medium.com/max/1280/1*wuocbRF1SCcn4T9nWu1How.png 640w, https://miro.medium.com/max/1456/1*wuocbRF1SCcn4T9nWu1How.png 728w, https://miro.medium.com/max/1632/1*wuocbRF1SCcn4T9nWu1How.png 816w, https://miro.medium.com/max/1808/1*wuocbRF1SCcn4T9nWu1How.png 904w, https://miro.medium.com/max/1984/1*wuocbRF1SCcn4T9nWu1How.png 992w, https://miro.medium.com/max/2160/1*wuocbRF1SCcn4T9nWu1How.png 1080w, https://miro.medium.com/max/2700/1*wuocbRF1SCcn4T9nWu1How.png 1350w, https://miro.medium.com/max/3240/1*wuocbRF1SCcn4T9nWu1How.png 1620w, https://miro.medium.com/max/3780/1*wuocbRF1SCcn4T9nWu1How.png 1890w, https://miro.medium.com/max/4320/1*wuocbRF1SCcn4T9nWu1How.png 2160w, https://miro.medium.com/max/4800/1*wuocbRF1SCcn4T9nWu1How.png 2400w" sizes="100vw"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="657d" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">There are 94 categories and although the number of transactions among categories is not homogenous, the least provided category still has 51 transactions. Now let’s see what we have for the sub-categories:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da nf"><div class="im s fk in"><div class="ng ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*JuRaL9ctaDmtu2tp04z9Ow.png?q=20" width="396" height="346"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="396" height="346"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/792/1*JuRaL9ctaDmtu2tp04z9Ow.png" width="396" height="346" srcSet="https://miro.medium.com/max/552/1*JuRaL9ctaDmtu2tp04z9Ow.png 276w, https://miro.medium.com/max/792/1*JuRaL9ctaDmtu2tp04z9Ow.png 396w" sizes="396px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div></div><div class="hn aj"><figure class="mz na nb nc nd hn aj paragraph-image"><div class="ie if fk ig aj"><div class="im s fk in"><div class="nh ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*zH_VMTYEkW4S4bQV8otJwQ.png?q=20" width="11352" height="2090"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="11352" height="2090"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/22704/1*zH_VMTYEkW4S4bQV8otJwQ.png" width="11352" height="2090" srcSet="https://miro.medium.com/max/552/1*zH_VMTYEkW4S4bQV8otJwQ.png 276w, https://miro.medium.com/max/1104/1*zH_VMTYEkW4S4bQV8otJwQ.png 552w, https://miro.medium.com/max/1280/1*zH_VMTYEkW4S4bQV8otJwQ.png 640w, https://miro.medium.com/max/1456/1*zH_VMTYEkW4S4bQV8otJwQ.png 728w, https://miro.medium.com/max/1632/1*zH_VMTYEkW4S4bQV8otJwQ.png 816w, https://miro.medium.com/max/1808/1*zH_VMTYEkW4S4bQV8otJwQ.png 904w, https://miro.medium.com/max/1984/1*zH_VMTYEkW4S4bQV8otJwQ.png 992w, https://miro.medium.com/max/2160/1*zH_VMTYEkW4S4bQV8otJwQ.png 1080w, https://miro.medium.com/max/2700/1*zH_VMTYEkW4S4bQV8otJwQ.png 1350w, https://miro.medium.com/max/3240/1*zH_VMTYEkW4S4bQV8otJwQ.png 1620w, https://miro.medium.com/max/3780/1*zH_VMTYEkW4S4bQV8otJwQ.png 1890w, https://miro.medium.com/max/4320/1*zH_VMTYEkW4S4bQV8otJwQ.png 2160w, https://miro.medium.com/max/4800/1*zH_VMTYEkW4S4bQV8otJwQ.png 2400w" sizes="100vw"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="0781" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">We have the same decreasing pattern. But now there are so many sub-categories that the ones with the least transactions only have 1 transaction. A single transaction is clearly not enough for the parameters to be accurately estimated.</p><p id="48df" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So, we are going to distinct the product by categories (and not sub-categories) and produce the matrix of counts X that we will use to resolve the clustering problem. Let’s see what the first 10 rows look like:</p></div></div><div class="hn aj"><figure class="hx hy hz ia ib hn aj paragraph-image"><div class="im s fk in"><div class="ni ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*yAgm8mkXygh0xPOwn7ShIA.png?q=20" width="1665" height="384"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1665" height="384"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3330/1*yAgm8mkXygh0xPOwn7ShIA.png" width="1665" height="384" srcSet="https://miro.medium.com/max/552/1*yAgm8mkXygh0xPOwn7ShIA.png 276w, https://miro.medium.com/max/1104/1*yAgm8mkXygh0xPOwn7ShIA.png 552w, https://miro.medium.com/max/1280/1*yAgm8mkXygh0xPOwn7ShIA.png 640w, https://miro.medium.com/max/1456/1*yAgm8mkXygh0xPOwn7ShIA.png 728w, https://miro.medium.com/max/1632/1*yAgm8mkXygh0xPOwn7ShIA.png 816w, https://miro.medium.com/max/1808/1*yAgm8mkXygh0xPOwn7ShIA.png 904w, https://miro.medium.com/max/1984/1*yAgm8mkXygh0xPOwn7ShIA.png 992w, https://miro.medium.com/max/2160/1*yAgm8mkXygh0xPOwn7ShIA.png 1080w, https://miro.medium.com/max/2700/1*yAgm8mkXygh0xPOwn7ShIA.png 1350w, https://miro.medium.com/max/3240/1*yAgm8mkXygh0xPOwn7ShIA.png 1620w, https://miro.medium.com/max/3330/1*yAgm8mkXygh0xPOwn7ShIA.png 1665w" sizes="1665px"/></noscript></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="b1e7" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">As you can see, the matrix is very sparse. But this is not a problem for the multinomial mixture model.</p><h1 id="f17a" class="jz ka dp cg kb kc kd jc ke kf kg jf kh ki kj kk kl km kn ko kp kq kr ks kt ku em">Mathematical derivations</h1><p id="85bb" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">So as we said, the full likelihood of observing the data set is defined by:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da nj"><div class="im s fk in"><div class="nk ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*8ZS-s3MtE65XRe4UR2rTbA.png?q=20" width="335" height="99"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="335" height="99"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/670/1*8ZS-s3MtE65XRe4UR2rTbA.png" width="335" height="99" srcSet="https://miro.medium.com/max/552/1*8ZS-s3MtE65XRe4UR2rTbA.png 276w, https://miro.medium.com/max/670/1*8ZS-s3MtE65XRe4UR2rTbA.png 335w" sizes="335px"/></noscript></div></div></div></figure><p id="1c31" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In order to understand this part, you need to be familiar with the Expectation-Maximization algorithm (if not, I highly encouraged you to read <a class="cm ix" rel="noopener" href="/gaussian-mixture-models-and-expectation-maximization-a-full-explanation-50fa94111ddd">my article</a> on the matter). With EM, we first need to define a latent variable t, that describes an observation by defining from which cluster it was generated.</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da nl"><div class="im s fk in"><div class="nm ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*7Q3Tp8kkfg4KFadz91ZCMg.png?q=20" width="341" height="81"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="341" height="81"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/682/1*7Q3Tp8kkfg4KFadz91ZCMg.png" width="341" height="81" srcSet="https://miro.medium.com/max/552/1*7Q3Tp8kkfg4KFadz91ZCMg.png 276w, https://miro.medium.com/max/682/1*7Q3Tp8kkfg4KFadz91ZCMg.png 341w" sizes="341px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="d93d" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The latent variable t_i defines by which cluster the observation x_i was generated. Also, a variational distribution q is used to describe the posterior distribution of the latent variable taking the range of possible values (from 1 to K). So we can write:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da nn"><div class="im s fk in"><div class="no ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*6ROdmZrIrE555SpD9RbRFA.png?q=20" width="481" height="46"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="481" height="46"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/962/1*6ROdmZrIrE555SpD9RbRFA.png" width="481" height="46" srcSet="https://miro.medium.com/max/552/1*6ROdmZrIrE555SpD9RbRFA.png 276w, https://miro.medium.com/max/962/1*6ROdmZrIrE555SpD9RbRFA.png 481w" sizes="481px"/></noscript></div></div></div></figure><p id="0862" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Recall that the EM algorithm defines a lower bound for the log-likelihood:</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da np"><div class="im s fk in"><div class="nq ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*Ng1EmRt_d9C1V4vkFTAbPg.png?q=20" width="1306" height="125"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1306" height="125"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/2612/1*Ng1EmRt_d9C1V4vkFTAbPg.png" width="1306" height="125" srcSet="https://miro.medium.com/max/552/1*Ng1EmRt_d9C1V4vkFTAbPg.png 276w, https://miro.medium.com/max/1104/1*Ng1EmRt_d9C1V4vkFTAbPg.png 552w, https://miro.medium.com/max/1280/1*Ng1EmRt_d9C1V4vkFTAbPg.png 640w, https://miro.medium.com/max/1456/1*Ng1EmRt_d9C1V4vkFTAbPg.png 728w, https://miro.medium.com/max/1632/1*Ng1EmRt_d9C1V4vkFTAbPg.png 816w, https://miro.medium.com/max/1808/1*Ng1EmRt_d9C1V4vkFTAbPg.png 904w, https://miro.medium.com/max/1984/1*Ng1EmRt_d9C1V4vkFTAbPg.png 992w, https://miro.medium.com/max/2000/1*Ng1EmRt_d9C1V4vkFTAbPg.png 1000w" sizes="1000px"/></noscript></div></div></div></div></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="9f76" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The EM algorithm proceeds with the two following steps alternatively until convergence:</p><p id="7bb3" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em"><strong class="ja jy"><em class="jx">Expectation step:</em></strong></p><p id="0d73" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">We maximize the lower bound with respect to q to update the posterior distribution of the latent variables:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da nr"><div class="im s fk in"><div class="ns ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*I9KcNU4MyBHA8I-mY37WSA.png?q=20" width="444" height="125"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="444" height="125"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/888/1*I9KcNU4MyBHA8I-mY37WSA.png" width="444" height="125" srcSet="https://miro.medium.com/max/552/1*I9KcNU4MyBHA8I-mY37WSA.png 276w, https://miro.medium.com/max/888/1*I9KcNU4MyBHA8I-mY37WSA.png 444w" sizes="444px"/></noscript></div></div></div></figure><p id="973b" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">As you can see, the form of the expectation step remains the same as in the case of a mixture of Gaussians, except that the likelihood of an observation given the cluster k, that is P(x_i | β_k), now has a multinomial density:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da nt"><div class="im s fk in"><div class="nu ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*dEQwtsopQPMvOwWowZmkjw.png?q=20" width="239" height="93"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="239" height="93"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/478/1*dEQwtsopQPMvOwWowZmkjw.png" width="239" height="93"/></noscript></div></div></div></figure><p id="f8c5" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em"><strong class="ja jy"><em class="jx">Maximization step:</em></strong></p><p id="bf60" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">We maximize the lower bound with respect to α and β. We try to solve the following optimization problem:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da nv"><div class="im s fk in"><div class="nw ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*-4acIO34XcSMnAEaD57PBg.png?q=20" width="520" height="225"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="520" height="225"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1040/1*-4acIO34XcSMnAEaD57PBg.png" width="520" height="225" srcSet="https://miro.medium.com/max/552/1*-4acIO34XcSMnAEaD57PBg.png 276w, https://miro.medium.com/max/1040/1*-4acIO34XcSMnAEaD57PBg.png 520w" sizes="520px"/></noscript></div></div></div></figure><p id="db0d" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The lower bound is defined as:</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da nx"><div class="im s fk in"><div class="ny ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*jM-bLyiuT9sPTldAv2Cdkg.png?q=20" width="1398" height="235"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1398" height="235"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/2796/1*jM-bLyiuT9sPTldAv2Cdkg.png" width="1398" height="235" srcSet="https://miro.medium.com/max/552/1*jM-bLyiuT9sPTldAv2Cdkg.png 276w, https://miro.medium.com/max/1104/1*jM-bLyiuT9sPTldAv2Cdkg.png 552w, https://miro.medium.com/max/1280/1*jM-bLyiuT9sPTldAv2Cdkg.png 640w, https://miro.medium.com/max/1456/1*jM-bLyiuT9sPTldAv2Cdkg.png 728w, https://miro.medium.com/max/1632/1*jM-bLyiuT9sPTldAv2Cdkg.png 816w, https://miro.medium.com/max/1808/1*jM-bLyiuT9sPTldAv2Cdkg.png 904w, https://miro.medium.com/max/1984/1*jM-bLyiuT9sPTldAv2Cdkg.png 992w, https://miro.medium.com/max/2000/1*jM-bLyiuT9sPTldAv2Cdkg.png 1000w" sizes="1000px"/></noscript></div></div></div></div></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="3fa5" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In order to resolve this optimization problem, we are going to set the partial derivatives to 0 and solve the equations. Notice that the second term in the subtraction above does not depend on α or β, so we can replace it with a constant. Also, we will make us of <a href="https://en.wikipedia.org/wiki/Lagrange_multiplier" class="cm ix" rel="noopener nofollow">Lagrangian multipliers</a> to get rid of the constraints. So we need to resolve the following system of equations:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da nz"><div class="im s fk in"><div class="oa ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/44/1*3e1Kujclq4go-NUPHLJggw.png?q=20" width="125" height="167"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="125" height="167"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/250/1*3e1Kujclq4go-NUPHLJggw.png" width="125" height="167"/></noscript></div></div></div></figure><p id="c72f" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">With :</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da ob"><div class="im s fk in"><div class="oc ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*HtSNcvLj1ZsE7vZBK-ywLQ.png?q=20" width="1449" height="140"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1449" height="140"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/2898/1*HtSNcvLj1ZsE7vZBK-ywLQ.png" width="1449" height="140" srcSet="https://miro.medium.com/max/552/1*HtSNcvLj1ZsE7vZBK-ywLQ.png 276w, https://miro.medium.com/max/1104/1*HtSNcvLj1ZsE7vZBK-ywLQ.png 552w, https://miro.medium.com/max/1280/1*HtSNcvLj1ZsE7vZBK-ywLQ.png 640w, https://miro.medium.com/max/1456/1*HtSNcvLj1ZsE7vZBK-ywLQ.png 728w, https://miro.medium.com/max/1632/1*HtSNcvLj1ZsE7vZBK-ywLQ.png 816w, https://miro.medium.com/max/1808/1*HtSNcvLj1ZsE7vZBK-ywLQ.png 904w, https://miro.medium.com/max/1984/1*HtSNcvLj1ZsE7vZBK-ywLQ.png 992w, https://miro.medium.com/max/2000/1*HtSNcvLj1ZsE7vZBK-ywLQ.png 1000w" sizes="1000px"/></noscript></div></div></div></div></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="9aa6" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Let’s start with the multinomial parameters β_kc:</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da od"><div class="im s fk in"><div class="oe ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*pJJt_QfgW_TjgiQwgjEFRg.png?q=20" width="1607" height="1371"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1607" height="1371"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3214/1*pJJt_QfgW_TjgiQwgjEFRg.png" width="1607" height="1371" srcSet="https://miro.medium.com/max/552/1*pJJt_QfgW_TjgiQwgjEFRg.png 276w, https://miro.medium.com/max/1104/1*pJJt_QfgW_TjgiQwgjEFRg.png 552w, https://miro.medium.com/max/1280/1*pJJt_QfgW_TjgiQwgjEFRg.png 640w, https://miro.medium.com/max/1456/1*pJJt_QfgW_TjgiQwgjEFRg.png 728w, https://miro.medium.com/max/1632/1*pJJt_QfgW_TjgiQwgjEFRg.png 816w, https://miro.medium.com/max/1808/1*pJJt_QfgW_TjgiQwgjEFRg.png 904w, https://miro.medium.com/max/1984/1*pJJt_QfgW_TjgiQwgjEFRg.png 992w, https://miro.medium.com/max/2000/1*pJJt_QfgW_TjgiQwgjEFRg.png 1000w" sizes="1000px"/></noscript></div></div></div></div></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="cb30" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now the mixture weights α_k:</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da of"><div class="im s fk in"><div class="og ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*rfyc876v-QFXu1hwpdKQTw.png?q=20" width="1602" height="1021"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1602" height="1021"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3204/1*rfyc876v-QFXu1hwpdKQTw.png" width="1602" height="1021" srcSet="https://miro.medium.com/max/552/1*rfyc876v-QFXu1hwpdKQTw.png 276w, https://miro.medium.com/max/1104/1*rfyc876v-QFXu1hwpdKQTw.png 552w, https://miro.medium.com/max/1280/1*rfyc876v-QFXu1hwpdKQTw.png 640w, https://miro.medium.com/max/1456/1*rfyc876v-QFXu1hwpdKQTw.png 728w, https://miro.medium.com/max/1632/1*rfyc876v-QFXu1hwpdKQTw.png 816w, https://miro.medium.com/max/1808/1*rfyc876v-QFXu1hwpdKQTw.png 904w, https://miro.medium.com/max/1984/1*rfyc876v-QFXu1hwpdKQTw.png 992w, https://miro.medium.com/max/2000/1*rfyc876v-QFXu1hwpdKQTw.png 1000w" sizes="1000px"/></noscript></div></div></div></div></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="126c" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Ok, so we now have the update rules for the variational distribution during the E-step and for the parameters during the M-step. Let’s get to the concrete materials.</p><h1 id="850a" class="jz ka dp cg kb kc kd jc ke kf kg jf kh ki kj kk kl km kn ko kp kq kr ks kt ku em">Implementation</h1><p id="960e" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">The expectation-maximization algorithm does not give us any guarantee of whether we will find the global maximum of the likelihood function on first run. In order to increase our chances, it is recommended to start the algorithm several times with different random initializations. Each time, we shall compare our maximum with the previous one and keep the parameters associated with the best loss. Let’s implement this routine:</p><figure class="hx hy hz ia ib hn"><div class="im s fk"><div class="oh ip s"></div></div></figure><p id="3291" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So I created a class for this model that needs to be instantiated with the number of clusters that we want to try out. I also added some parameters:</p><ul class=""><li id="ce56" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt oi lb lc em">rtol: will be used when comparing the current loss with the previous one to decide whether we should stop the algorithm (the improvement from one cycle to the next gets to small so there is no need to continue further)</li><li id="fb72" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">max_iter: in order to ensure that the algorithm does not run forever, we can tell it to stop after a certain number of iterations</li><li id="7e16" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">restarts: the number of times we want to restart the full EM procedure with a different initialization</li></ul><p id="8d3f" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Next, we need to implement the <em class="jx">_train_once</em> method that, as its name suggests, will run one full cycle of iterations for the EM algorithm.</p><figure class="hx hy hz ia ib hn"><div class="im s fk"><div class="oh ip s"></div></div></figure><p id="455a" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The shape of the algorithm is no big surprise. We start by initializing the parameters randomly. We iterate up to max_iter iterations and each time we alternate between the e-step to compute the posterior distributions of the latent variable t (gamma) and the m-step to update the parameters of the mixture (alpha and beta).</p><p id="8327" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Notice that the beta parameters are initialized using the <a href="https://en.wikipedia.org/wiki/Dirichlet_distribution" class="cm ix" rel="noopener nofollow">Dirichlet distribution</a> which is conjugate to the multinomial distribution. I won’t get into the details here but you just need to know that the Dirichlet will produce a set of parameters that sum up to 1 (for every cluster) as required.</p><p id="687c" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now there is also one thing that we did not talk about yet. It is the loss. Remember that at each iteration the EM algorithm is trying to maximize the lower bound. So the loss function that we will use track the convergence of the algorithm is the lower bound:</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da nx"><div class="im s fk in"><div class="ny ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*jM-bLyiuT9sPTldAv2Cdkg.png?q=20" width="1398" height="235"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1398" height="235"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/2796/1*jM-bLyiuT9sPTldAv2Cdkg.png" width="1398" height="235" srcSet="https://miro.medium.com/max/552/1*jM-bLyiuT9sPTldAv2Cdkg.png 276w, https://miro.medium.com/max/1104/1*jM-bLyiuT9sPTldAv2Cdkg.png 552w, https://miro.medium.com/max/1280/1*jM-bLyiuT9sPTldAv2Cdkg.png 640w, https://miro.medium.com/max/1456/1*jM-bLyiuT9sPTldAv2Cdkg.png 728w, https://miro.medium.com/max/1632/1*jM-bLyiuT9sPTldAv2Cdkg.png 816w, https://miro.medium.com/max/1808/1*jM-bLyiuT9sPTldAv2Cdkg.png 904w, https://miro.medium.com/max/1984/1*jM-bLyiuT9sPTldAv2Cdkg.png 992w, https://miro.medium.com/max/2000/1*jM-bLyiuT9sPTldAv2Cdkg.png 1000w" sizes="1000px"/></noscript></div></div></div></div></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="4fa2" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">This gives us the following implementation:</p><figure class="hx hy hz ia ib hn"><div class="im s fk"><div class="oh ip s"></div></div></figure><p id="372a" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Notice that the computation is not fully vectorized. We still iterate through the different K clusters. This is because we use the implementation of the multinomial from scipy.stats. This implementation accepts a matrix of observations for the counts but not for the parameters. So you can compute the multinomial probabilities for all the observations but only for a specific cluster and not all of them at once.</p><p id="24fd" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now the e-step:</p><figure class="hx hy hz ia ib hn"><div class="im s fk"><div class="oh ip s"></div></div></figure><p id="d6f6" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So this is just the vectorized implementation of the update rule we derived mathematically in the previous section. One thing to notice though is that when computing the multinomial probabilities of observing the count vectors (i.e. the likelihood), the probabilities are sometimes so close to 0 that we get numerical underflows and values are floored to 0. This is no good because we have to normalize the values to get back the posterior probabilities. In order to avoid division by 0, we replace the null values with the minimal floating-point value allowed in Python.</p><p id="09d6" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now the m-step:</p><figure class="hx hy hz ia ib hn"><div class="im s fk"><div class="oh ip s"></div></div></figure><p id="383d" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">No big surprise. Those are vectorized implementation of the update rules we derived mathematically.</p><h2 id="951e" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Runs on a simulated dataset</h2><p id="0d6f" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">We are going to run the algorithm and see how it performs for various values ok K. A nice thing to do is first to use a simulated data set so that we control the data generation process. We can then see how the algorithm performs when we modify the true values for the parameters (i.e. the number of clusters, the mixture weights, the multinomial parameters, and the size of the dataset). The data set is generated with the following routine:</p><figure class="hx hy hz ia ib hn"><div class="im s fk"><div class="oh ip s"></div></div></figure><p id="1349" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So we are first going to perform a simple test. The data set is generated as a mixture of 10000 observations coming from 3 very well separated multinomials that can take up to 16 different values. Also, we split the generated data set into 80 % for training and 20 % for testing. Then we compute the likelihood on the test data:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da oj"><div class="im s fk in"><div class="ok ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*0ievWD0wxc_b3JMQMjfiYg.png?q=20" width="684" height="123"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="684" height="123"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1368/1*0ievWD0wxc_b3JMQMjfiYg.png" width="684" height="123" srcSet="https://miro.medium.com/max/552/1*0ievWD0wxc_b3JMQMjfiYg.png 276w, https://miro.medium.com/max/1104/1*0ievWD0wxc_b3JMQMjfiYg.png 552w, https://miro.medium.com/max/1280/1*0ievWD0wxc_b3JMQMjfiYg.png 640w, https://miro.medium.com/max/1368/1*0ievWD0wxc_b3JMQMjfiYg.png 684w" sizes="684px"/></noscript></div></div></div></figure><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da ol"><div class="im s fk in"><div class="om ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*X4CdRc1i5NptX-wm-8VMEw.png?q=20" width="921" height="447"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="921" height="447"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1842/1*X4CdRc1i5NptX-wm-8VMEw.png" width="921" height="447" srcSet="https://miro.medium.com/max/552/1*X4CdRc1i5NptX-wm-8VMEw.png 276w, https://miro.medium.com/max/1104/1*X4CdRc1i5NptX-wm-8VMEw.png 552w, https://miro.medium.com/max/1280/1*X4CdRc1i5NptX-wm-8VMEw.png 640w, https://miro.medium.com/max/1400/1*X4CdRc1i5NptX-wm-8VMEw.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da on"><div class="im s fk in"><div class="oo ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*9AQTAvJLmVA6vD3V696xeQ.png?q=20" width="950" height="128"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="950" height="128"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1900/1*9AQTAvJLmVA6vD3V696xeQ.png" width="950" height="128" srcSet="https://miro.medium.com/max/552/1*9AQTAvJLmVA6vD3V696xeQ.png 276w, https://miro.medium.com/max/1104/1*9AQTAvJLmVA6vD3V696xeQ.png 552w, https://miro.medium.com/max/1280/1*9AQTAvJLmVA6vD3V696xeQ.png 640w, https://miro.medium.com/max/1400/1*9AQTAvJLmVA6vD3V696xeQ.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="9f01" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">As we can see, the estimated parameters are very close to real ones. Also, now we see the value of our work regarding the visualization of the multinomial. It is very apparent, from the above plot, that the clusters are very well separated. So the algorithm should clearly have no problem in estimating the true number of clusters. And if we look at the likelihood evolution when we increase the number of clusters, we can clearly see the <a href="https://en.wikipedia.org/wiki/Elbow_method_(clustering)" class="cm ix" rel="noopener nofollow">elbow pattern</a>. When we go from 2 clusters to 3, the fit is much more likely. But as soon as we reach 3 clusters, the likelihood hits a plateau. This clearly suggests that the best number of clusters is 3. Why? Well, because when we increase the number of clusters, we increase the complexity of the model with no additional benefits on the likelihood.</p><p id="66ed" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now what happens when we modify the mixture weights:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da op"><div class="im s fk in"><div class="oq ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*NeD3pmWGI8K40XU8ea94Vw.png?q=20" width="689" height="129"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="689" height="129"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1378/1*NeD3pmWGI8K40XU8ea94Vw.png" width="689" height="129" srcSet="https://miro.medium.com/max/552/1*NeD3pmWGI8K40XU8ea94Vw.png 276w, https://miro.medium.com/max/1104/1*NeD3pmWGI8K40XU8ea94Vw.png 552w, https://miro.medium.com/max/1280/1*NeD3pmWGI8K40XU8ea94Vw.png 640w, https://miro.medium.com/max/1378/1*NeD3pmWGI8K40XU8ea94Vw.png 689w" sizes="689px"/></noscript></div></div></div></figure><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da ol"><div class="im s fk in"><div class="om ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*k7rZdMsG5KSwy9vyg2yOzQ.png?q=20" width="921" height="447"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="921" height="447"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1842/1*k7rZdMsG5KSwy9vyg2yOzQ.png" width="921" height="447" srcSet="https://miro.medium.com/max/552/1*k7rZdMsG5KSwy9vyg2yOzQ.png 276w, https://miro.medium.com/max/1104/1*k7rZdMsG5KSwy9vyg2yOzQ.png 552w, https://miro.medium.com/max/1280/1*k7rZdMsG5KSwy9vyg2yOzQ.png 640w, https://miro.medium.com/max/1400/1*k7rZdMsG5KSwy9vyg2yOzQ.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da or"><div class="im s fk in"><div class="os ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*qCKPXPIzeYf0pZXsSJscqQ.png?q=20" width="948" height="121"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="948" height="121"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1896/1*qCKPXPIzeYf0pZXsSJscqQ.png" width="948" height="121" srcSet="https://miro.medium.com/max/552/1*qCKPXPIzeYf0pZXsSJscqQ.png 276w, https://miro.medium.com/max/1104/1*qCKPXPIzeYf0pZXsSJscqQ.png 552w, https://miro.medium.com/max/1280/1*qCKPXPIzeYf0pZXsSJscqQ.png 640w, https://miro.medium.com/max/1400/1*qCKPXPIzeYf0pZXsSJscqQ.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="fa1d" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Once again, the mixture weights are very well estimated which confirms the update rules are correct.</p><p id="7ab9" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now, what happens when the clusters are not very well separated? Let’s see:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da oj"><div class="im s fk in"><div class="ot ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*ANHVk81RIsUgJKmlPmTlBg.png?q=20" width="684" height="125"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="684" height="125"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1368/1*ANHVk81RIsUgJKmlPmTlBg.png" width="684" height="125" srcSet="https://miro.medium.com/max/552/1*ANHVk81RIsUgJKmlPmTlBg.png 276w, https://miro.medium.com/max/1104/1*ANHVk81RIsUgJKmlPmTlBg.png 552w, https://miro.medium.com/max/1280/1*ANHVk81RIsUgJKmlPmTlBg.png 640w, https://miro.medium.com/max/1368/1*ANHVk81RIsUgJKmlPmTlBg.png 684w" sizes="684px"/></noscript></div></div></div></figure><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da ol"><div class="im s fk in"><div class="om ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*iIJ2D17afFbAMf0nN_7G9Q.png?q=20" width="921" height="447"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="921" height="447"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1842/1*iIJ2D17afFbAMf0nN_7G9Q.png" width="921" height="447" srcSet="https://miro.medium.com/max/552/1*iIJ2D17afFbAMf0nN_7G9Q.png 276w, https://miro.medium.com/max/1104/1*iIJ2D17afFbAMf0nN_7G9Q.png 552w, https://miro.medium.com/max/1280/1*iIJ2D17afFbAMf0nN_7G9Q.png 640w, https://miro.medium.com/max/1400/1*iIJ2D17afFbAMf0nN_7G9Q.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da ou"><div class="im s fk in"><div class="ov ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*ftkh7KPq6ZmqTEU42iswvQ.png?q=20" width="957" height="128"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="957" height="128"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1914/1*ftkh7KPq6ZmqTEU42iswvQ.png" width="957" height="128" srcSet="https://miro.medium.com/max/552/1*ftkh7KPq6ZmqTEU42iswvQ.png 276w, https://miro.medium.com/max/1104/1*ftkh7KPq6ZmqTEU42iswvQ.png 552w, https://miro.medium.com/max/1280/1*ftkh7KPq6ZmqTEU42iswvQ.png 640w, https://miro.medium.com/max/1400/1*ftkh7KPq6ZmqTEU42iswvQ.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="4e12" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Ok so this time, the mixture weights are a bit less correctly inferred. The multinomial component weights are better though. Also, we still see an elbow pattern in the likelihood values, but they are a bit more noisily distributed. From the distribution of the likelihoods, we can clearly see that the jump from 2 to 3 clusters is the one that gets out the most value in terms of goodness of fit. So we still choose 3 clusters.</p><p id="dcb4" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now, what if we pack the parameter space even more with 10 different multinomials?</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da ol"><div class="im s fk in"><div class="om ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*3YFJ9xogkbMG32jeS2gGnw.png?q=20" width="921" height="447"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="921" height="447"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1842/1*3YFJ9xogkbMG32jeS2gGnw.png" width="921" height="447" srcSet="https://miro.medium.com/max/552/1*3YFJ9xogkbMG32jeS2gGnw.png 276w, https://miro.medium.com/max/1104/1*3YFJ9xogkbMG32jeS2gGnw.png 552w, https://miro.medium.com/max/1280/1*3YFJ9xogkbMG32jeS2gGnw.png 640w, https://miro.medium.com/max/1400/1*3YFJ9xogkbMG32jeS2gGnw.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="acaf" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Ok so this time, selecting the best number of clusters based solely on the improvement on the likelihood is much more tricky. It might be 3 clusters or maybe 7… which clearly is not right. Ok, so how can we do better? Well, we are going to use another selection criterion. It is called the <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion" class="cm ix" rel="noopener nofollow">Bayesian Information Criterion</a> (or BIC in short). It is computed with the following formula:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da ow"><div class="im s fk in"><div class="ox ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*LSdF8y3iwM_wCyYt4YnEOw.png?q=20" width="324" height="65"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="324" height="65"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/648/1*LSdF8y3iwM_wCyYt4YnEOw.png" width="324" height="65" srcSet="https://miro.medium.com/max/552/1*LSdF8y3iwM_wCyYt4YnEOw.png 276w, https://miro.medium.com/max/648/1*LSdF8y3iwM_wCyYt4YnEOw.png 324w" sizes="324px"/></noscript></div></div></div></figure><p id="5678" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">D represents the number of parameters to be estimated by the model, N the total number of observations, and L_hat the likelihood of the model. It introduces a penalty proportional to the number of observations and the number of parameters. What we want to do is minimize the BIC value, so that the likelihood is maximized but at the same time keeping the number of parameters as low as possible. In the case of the mixture of multinomials, with K multinomials of C components, D, the number of parameters, is equal to (K-1)+K*(C-1). Knowing that the mixture weights and the component weights both sum up to 1, we can deduce the last parameters.</p><p id="aff3" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Applying this new selection criterion to the generated data set with 10 multinomials, we get:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da oy"><div class="im s fk in"><div class="oz ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*h0_SR1oMDYwMKPEaCeeXoQ.png?q=20" width="968" height="296"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="968" height="296"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1936/1*h0_SR1oMDYwMKPEaCeeXoQ.png" width="968" height="296" srcSet="https://miro.medium.com/max/552/1*h0_SR1oMDYwMKPEaCeeXoQ.png 276w, https://miro.medium.com/max/1104/1*h0_SR1oMDYwMKPEaCeeXoQ.png 552w, https://miro.medium.com/max/1280/1*h0_SR1oMDYwMKPEaCeeXoQ.png 640w, https://miro.medium.com/max/1400/1*h0_SR1oMDYwMKPEaCeeXoQ.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="1bef" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The optimal number of 10 clusters is correctly selected by the BIC criterion. But we see that it was a very close match. And in fact, running the same procedure again, we might get a different number of clusters. It shows that selecting the correct number is very hard and there is no silver bullet. In the end, nothing beats the judgment call of the business analyst. So it is a good thing to review the clusters and try to see if some of them should be merged (because they are very closed to each other and have very similar properties).</p><h2 id="b93f" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Fitting on the grocery department store data set</h2><p id="4c42" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">Ok so now we have the ingredients to perform the clustering of the grocery store transaction data set. Recall that we have prepared a matrix for the transaction counts of distinct product categories grouped by basket:</p></div></div><div class="hn aj"><figure class="hx hy hz ia ib hn aj paragraph-image"><div class="im s fk in"><div class="ni ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*yAgm8mkXygh0xPOwn7ShIA.png?q=20" width="1665" height="384"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1665" height="384"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3330/1*yAgm8mkXygh0xPOwn7ShIA.png" width="1665" height="384" srcSet="https://miro.medium.com/max/552/1*yAgm8mkXygh0xPOwn7ShIA.png 276w, https://miro.medium.com/max/1104/1*yAgm8mkXygh0xPOwn7ShIA.png 552w, https://miro.medium.com/max/1280/1*yAgm8mkXygh0xPOwn7ShIA.png 640w, https://miro.medium.com/max/1456/1*yAgm8mkXygh0xPOwn7ShIA.png 728w, https://miro.medium.com/max/1632/1*yAgm8mkXygh0xPOwn7ShIA.png 816w, https://miro.medium.com/max/1808/1*yAgm8mkXygh0xPOwn7ShIA.png 904w, https://miro.medium.com/max/1984/1*yAgm8mkXygh0xPOwn7ShIA.png 992w, https://miro.medium.com/max/2160/1*yAgm8mkXygh0xPOwn7ShIA.png 1080w, https://miro.medium.com/max/2700/1*yAgm8mkXygh0xPOwn7ShIA.png 1350w, https://miro.medium.com/max/3240/1*yAgm8mkXygh0xPOwn7ShIA.png 1620w, https://miro.medium.com/max/3330/1*yAgm8mkXygh0xPOwn7ShIA.png 1665w" sizes="1665px"/></noscript></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="c052" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">After splitting this matrix on a 80/20 rule (ordered by basket transaction times), we fit the model to the training data and record the likelihood and BIC values on the test data for a set of possible cluster values from 2 to 100. We get the following result:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da pa"><div class="im s fk in"><div class="pb ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*DFLIs6R3NnOVSi78Jzc7HA.png?q=20" width="960" height="319"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="960" height="319"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1920/1*DFLIs6R3NnOVSi78Jzc7HA.png" width="960" height="319" srcSet="https://miro.medium.com/max/552/1*DFLIs6R3NnOVSi78Jzc7HA.png 276w, https://miro.medium.com/max/1104/1*DFLIs6R3NnOVSi78Jzc7HA.png 552w, https://miro.medium.com/max/1280/1*DFLIs6R3NnOVSi78Jzc7HA.png 640w, https://miro.medium.com/max/1400/1*DFLIs6R3NnOVSi78Jzc7HA.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="a003" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">From the above plot, we understand why with real-world data sets, selecting the optimal number of clusters based solely on the likelihood is not very reliable and why we need to penalize on the complexity of the model. And that comes from the fact that clusters are, most frequently, not very well separated. Using the Bayesian Information Criterion, we select 30 clusters.</p><h1 id="3dbc" class="jz ka dp cg kb kc kd jc ke kf kg jf kh ki kj kk kl km kn ko kp kq kr ks kt ku em">Results</h1><h2 id="09d2" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Clusters analysis</h2><p id="a1e6" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">First of all, we can visualize the clusters in terms of probability distributions of product categories. We plot the 6 first clusters :</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da pc"><div class="im s fk in"><div class="pd ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*znI_CjZ2QUgyMWrvq2Ax-g.png?q=20" width="4600" height="3448"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="4600" height="3448"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/9200/1*znI_CjZ2QUgyMWrvq2Ax-g.png" width="4600" height="3448" srcSet="https://miro.medium.com/max/552/1*znI_CjZ2QUgyMWrvq2Ax-g.png 276w, https://miro.medium.com/max/1104/1*znI_CjZ2QUgyMWrvq2Ax-g.png 552w, https://miro.medium.com/max/1280/1*znI_CjZ2QUgyMWrvq2Ax-g.png 640w, https://miro.medium.com/max/1456/1*znI_CjZ2QUgyMWrvq2Ax-g.png 728w, https://miro.medium.com/max/1632/1*znI_CjZ2QUgyMWrvq2Ax-g.png 816w, https://miro.medium.com/max/1808/1*znI_CjZ2QUgyMWrvq2Ax-g.png 904w, https://miro.medium.com/max/1984/1*znI_CjZ2QUgyMWrvq2Ax-g.png 992w, https://miro.medium.com/max/2000/1*znI_CjZ2QUgyMWrvq2Ax-g.png 1000w" sizes="1000px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="e976" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">What is important to understand is that the distributions above represent the typical baskets. They can help us with the forecast for product purchases.</p><p id="bc03" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Also, we can notice that some typical baskets are dominated by one or a low number of categories whereas some other typical baskets are made of a more diverse set of categories. This highlights shopping behaviors. Sometimes a person will make a quick visit to the store and buy the ingredients for a specific occasion (Saturday brunch, Sunday supper, a drink with friends,…) or it might be a longer visit for the weekly shopping.</p><p id="dd20" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Next, we would like to assess the clustering quality by visualizing their relative distances. Considering that there are 30 clusters, it is not evident to see that they are pretty well separated from one another. In order to visualize the distances between them, the ideal scenario would be to build up a 30-dimensional space in which we could place the observations. Of course, this not feasible so we are going to rely on a dimensionality reduction technique. The technique we use is called <a href="https://en.wikipedia.org/wiki/Multidimensional_scaling" class="cm ix" rel="noopener nofollow">multidimensional scaling</a>. Like the PCA, it relies on the eigendecomposition of the input matrix. But this time, the input matrix will be the pairwise distance matrix of the cluster parameters (using the <a href="https://en.wikipedia.org/wiki/Taxicab_geometry" class="cm ix" rel="noopener nofollow">Manhattan distance)</a>. We get the following result:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da pe"><div class="im s fk in"><div class="pf ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*gXShQC60jaZPXphKqFjfzA.png?q=20" width="738" height="706"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="738" height="706"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1476/1*gXShQC60jaZPXphKqFjfzA.png" width="738" height="706" srcSet="https://miro.medium.com/max/552/1*gXShQC60jaZPXphKqFjfzA.png 276w, https://miro.medium.com/max/1104/1*gXShQC60jaZPXphKqFjfzA.png 552w, https://miro.medium.com/max/1280/1*gXShQC60jaZPXphKqFjfzA.png 640w, https://miro.medium.com/max/1400/1*gXShQC60jaZPXphKqFjfzA.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="a663" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The cluster sizes are synchronized on the mixture weights which highlights their inequalities. Although some information is lost due to the dimensionality reduction technique, we can still conclude that the clusters are pretty well separated.</p><h2 id="eca1" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">High lift items</h2><p id="5018" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">A good way to describe the clusters is by computing the lift ratio for the highly bought individual products. The lift ratio for a product and a cluster is defined as the ratio between the purchase probability conditioned on a cluster over the total purchase probability. So first we need to compute the purchase probabilities of each individual products, which can be defined as:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da pg"><div class="im s fk in"><div class="ph ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*qFx44mBDqEUmgBpGD3kJJA.png?q=20" width="729" height="251"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="729" height="251"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1458/1*qFx44mBDqEUmgBpGD3kJJA.png" width="729" height="251" srcSet="https://miro.medium.com/max/552/1*qFx44mBDqEUmgBpGD3kJJA.png 276w, https://miro.medium.com/max/1104/1*qFx44mBDqEUmgBpGD3kJJA.png 552w, https://miro.medium.com/max/1280/1*qFx44mBDqEUmgBpGD3kJJA.png 640w, https://miro.medium.com/max/1400/1*qFx44mBDqEUmgBpGD3kJJA.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="5f98" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">It is the ratio between the total quantities for a specific product over the total quantities of all the products. It can be defined as the probability of finding a product in a basket randomly chosen among all the baskets of the data set. Let’s see the distribution of those probabilities for all the products:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da pi"><div class="im s fk in"><div class="pj ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*otujZVICnoFx2gI1JNjDtg.png?q=20" width="870" height="387"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="870" height="387"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1740/1*otujZVICnoFx2gI1JNjDtg.png" width="870" height="387" srcSet="https://miro.medium.com/max/552/1*otujZVICnoFx2gI1JNjDtg.png 276w, https://miro.medium.com/max/1104/1*otujZVICnoFx2gI1JNjDtg.png 552w, https://miro.medium.com/max/1280/1*otujZVICnoFx2gI1JNjDtg.png 640w, https://miro.medium.com/max/1400/1*otujZVICnoFx2gI1JNjDtg.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="e71a" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">As you can see, there is a high concentration of very low values. An also, a good proportion of probabilities are so low that their computation suffered from numerical underflow (which basically resulted in a 0 probability). We want to consider only items that are frequently bought because they are the most characteristics. So we will restrict this analysis to products with purchase probabilities higher than 0.0001 (2019 products).</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da pk"><div class="im s fk in"><div class="pl ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*uGFfYlNpqS_1pNYDvtTIMA.png?q=20" width="640" height="381"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="640" height="381"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1280/1*uGFfYlNpqS_1pNYDvtTIMA.png" width="640" height="381" srcSet="https://miro.medium.com/max/552/1*uGFfYlNpqS_1pNYDvtTIMA.png 276w, https://miro.medium.com/max/1104/1*uGFfYlNpqS_1pNYDvtTIMA.png 552w, https://miro.medium.com/max/1280/1*uGFfYlNpqS_1pNYDvtTIMA.png 640w" sizes="640px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="8243" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Next, in order to compute the lift ratio, we need to compute the purchase probabilities of those items but for specific clusters. It means that we want to get the probabilities of finding a product in a basket randomly chosen among the baskets of a specific cluster k (and not among all the baskets):</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da pm"><div class="im s fk in"><div class="pn ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*1drRDGZ6kMFqfEfKMeMtew.png?q=20" width="301" height="183"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="301" height="183"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/602/1*1drRDGZ6kMFqfEfKMeMtew.png" width="301" height="183" srcSet="https://miro.medium.com/max/552/1*1drRDGZ6kMFqfEfKMeMtew.png 276w, https://miro.medium.com/max/602/1*1drRDGZ6kMFqfEfKMeMtew.png 301w" sizes="301px"/></noscript></div></div></div></figure><p id="f17e" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The issue with this computation is that talking about the basket <strong class="ja jy">of</strong> a cluster is not, strictly speaking, correct. Indeed, with the current modelization, a basket belongs to several clusters at the same time. Remember that we are performing soft clustering as defined by the posterior probability distribution of the latent variable over the parameters, that is P(t_i|x_i,α,β). For example, let’s visualize the posterior distributions of the latent variable for the 6 first baskets:</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da po"><div class="im s fk in"><div class="pp ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*V6uk8AfFggBvRQC6xwKUfw.png?q=20" width="1829" height="1027"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1829" height="1027"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3658/1*V6uk8AfFggBvRQC6xwKUfw.png" width="1829" height="1027" srcSet="https://miro.medium.com/max/552/1*V6uk8AfFggBvRQC6xwKUfw.png 276w, https://miro.medium.com/max/1104/1*V6uk8AfFggBvRQC6xwKUfw.png 552w, https://miro.medium.com/max/1280/1*V6uk8AfFggBvRQC6xwKUfw.png 640w, https://miro.medium.com/max/1456/1*V6uk8AfFggBvRQC6xwKUfw.png 728w, https://miro.medium.com/max/1632/1*V6uk8AfFggBvRQC6xwKUfw.png 816w, https://miro.medium.com/max/1808/1*V6uk8AfFggBvRQC6xwKUfw.png 904w, https://miro.medium.com/max/1984/1*V6uk8AfFggBvRQC6xwKUfw.png 992w, https://miro.medium.com/max/2000/1*V6uk8AfFggBvRQC6xwKUfw.png 1000w" sizes="1000px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="9ee9" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The goal of the clustering process is to extract the most typical baskets by grouping them together. Some baskets will be located at the core of a cluster (in assignments probability space). The distribution then exhibits a single high value for a specific cluster (like for the top left basket above). But some baskets will be located in regions where the assignments are a bit fuzzier. So in order to be accurate in the computation of purchase probabilities conditioned on a cluster, we are first going to distribute the counts of basket products among the different clusters. So we compute a new floating-points matrix of size N times K times C with the following rules:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da pq"><div class="im s fk in"><div class="pr ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*-LMoVrAevErSe74z7VdOyw.png?q=20" width="1062" height="336"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1062" height="336"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/2124/1*-LMoVrAevErSe74z7VdOyw.png" width="1062" height="336" srcSet="https://miro.medium.com/max/552/1*-LMoVrAevErSe74z7VdOyw.png 276w, https://miro.medium.com/max/1104/1*-LMoVrAevErSe74z7VdOyw.png 552w, https://miro.medium.com/max/1280/1*-LMoVrAevErSe74z7VdOyw.png 640w, https://miro.medium.com/max/1400/1*-LMoVrAevErSe74z7VdOyw.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="e581" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Finally, we can compute the lift ratio which is:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da ps"><div class="im s fk in"><div class="pt ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*tyumD7G7rDOxLscRyXAGuA.png?q=20" width="241" height="94"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="241" height="94"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/482/1*tyumD7G7rDOxLscRyXAGuA.png" width="241" height="94"/></noscript></div></div></div></figure><p id="8ea1" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Showing the items with a lift ratio greater than 10, we can start to describe the clusters with specific products. For example, the high lift items for the first cluster are the following:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da pg"><div class="im s fk in"><div class="pu ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*5LXPWsJCbYAKlt5X8Fe8ow.png?q=20" width="729" height="377"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="729" height="377"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1458/1*5LXPWsJCbYAKlt5X8Fe8ow.png" width="729" height="377" srcSet="https://miro.medium.com/max/552/1*5LXPWsJCbYAKlt5X8Fe8ow.png 276w, https://miro.medium.com/max/1104/1*5LXPWsJCbYAKlt5X8Fe8ow.png 552w, https://miro.medium.com/max/1280/1*5LXPWsJCbYAKlt5X8Fe8ow.png 640w, https://miro.medium.com/max/1400/1*5LXPWsJCbYAKlt5X8Fe8ow.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="692a" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The items with the highest lift of the first cluster are canned beans and tomatoes.</p><p id="f7b4" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Also, in order to describe the clusters a bit more visually, we can make word clouds based on the categories of high lift items (taking into account purchase frequencies too). Let’s see what we get for the 6 first clusters:</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da pv"><div class="im s fk in"><div class="pw ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*Ur17gnm5gLR_UXVr7RNkcA.png?q=20" width="1755" height="1348"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1755" height="1348"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3510/1*Ur17gnm5gLR_UXVr7RNkcA.png" width="1755" height="1348" srcSet="https://miro.medium.com/max/552/1*Ur17gnm5gLR_UXVr7RNkcA.png 276w, https://miro.medium.com/max/1104/1*Ur17gnm5gLR_UXVr7RNkcA.png 552w, https://miro.medium.com/max/1280/1*Ur17gnm5gLR_UXVr7RNkcA.png 640w, https://miro.medium.com/max/1456/1*Ur17gnm5gLR_UXVr7RNkcA.png 728w, https://miro.medium.com/max/1632/1*Ur17gnm5gLR_UXVr7RNkcA.png 816w, https://miro.medium.com/max/1808/1*Ur17gnm5gLR_UXVr7RNkcA.png 904w, https://miro.medium.com/max/1984/1*Ur17gnm5gLR_UXVr7RNkcA.png 992w, https://miro.medium.com/max/2000/1*Ur17gnm5gLR_UXVr7RNkcA.png 1000w" sizes="1000px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="ea20" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">From the word clouds above we can describe the clusters. This first cluster is a good mix although the main topic is vegetables. The second and third clusters are dominated by bakery items, the fourth by products relating to dinner, the fifth by snacks, and the sixth by dairy products.</p><h2 id="bb45" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Products associations</h2><p id="4021" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">Now the high lift items analysis can be pushed one step further by computing the high lift pairs of items. The computation of probabilities is the same except that this time we compute it for pairs of items. For example, one is 17.2 times more likely to find both “VARIETY BEANS — KIDNEY PINTO” and “TOMATO SAUCE” from a random basket of cluster 1 than from a general random basket.</p><p id="9660" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">By first narrowing down the dataset to transactions from a specific cluster and then checking for purchase probabilities for pairs of products we enveil associations that would otherwise not be relevant!</p><h1 id="8d4b" class="jz ka dp cg kb kc kd jc ke kf kg jf kh ki kj kk kl km kn ko kp kq kr ks kt ku em">Individual predictive profiles</h1><p id="49dd" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">So far, the model we have been working with describes the likelihood of an observation as a mixture of multinomial distributions:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da px"><div class="im s fk in"><div class="py ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*YSh55lFuFEf0gPTWAEWjmg.png?q=20" width="750" height="114"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="750" height="114"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1500/1*YSh55lFuFEf0gPTWAEWjmg.png" width="750" height="114" srcSet="https://miro.medium.com/max/552/1*YSh55lFuFEf0gPTWAEWjmg.png 276w, https://miro.medium.com/max/1104/1*YSh55lFuFEf0gPTWAEWjmg.png 552w, https://miro.medium.com/max/1280/1*YSh55lFuFEf0gPTWAEWjmg.png 640w, https://miro.medium.com/max/1400/1*YSh55lFuFEf0gPTWAEWjmg.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="dc73" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The full data likelihood is written as:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da pz"><div class="im s fk in"><div class="qa ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*6UoHeOYd3AZi4sDjpoo_oA.png?q=20" width="387" height="95"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="387" height="95"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/774/1*6UoHeOYd3AZi4sDjpoo_oA.png" width="387" height="95" srcSet="https://miro.medium.com/max/552/1*6UoHeOYd3AZi4sDjpoo_oA.png 276w, https://miro.medium.com/max/774/1*6UoHeOYd3AZi4sDjpoo_oA.png 387w" sizes="387px"/></noscript></div></div></div></figure><p id="5023" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now as I previously said, this model considers each basket independently and there is no distinction for the baskets of different individuals. We consider every individual in the same regard which means that they have the same predictive profile, resulting from the estimation of the model parameters. In our case, this gives us the following general profile (simulated by sampling):</p></div></div><div class="hn"><div class="n p"><div class="ho hp hq hr hs ht af hu ag hv ai aj"><figure class="hx hy hz ia ib hn ic id paragraph-image"><div class="ie if fk ig aj"><div class="cz da qb"><div class="im s fk in"><div class="qc ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*v--WQdUV1T5lkEIA7nduRg.png?q=20" width="1852" height="409"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1852" height="409"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3704/1*v--WQdUV1T5lkEIA7nduRg.png" width="1852" height="409" srcSet="https://miro.medium.com/max/552/1*v--WQdUV1T5lkEIA7nduRg.png 276w, https://miro.medium.com/max/1104/1*v--WQdUV1T5lkEIA7nduRg.png 552w, https://miro.medium.com/max/1280/1*v--WQdUV1T5lkEIA7nduRg.png 640w, https://miro.medium.com/max/1456/1*v--WQdUV1T5lkEIA7nduRg.png 728w, https://miro.medium.com/max/1632/1*v--WQdUV1T5lkEIA7nduRg.png 816w, https://miro.medium.com/max/1808/1*v--WQdUV1T5lkEIA7nduRg.png 904w, https://miro.medium.com/max/1984/1*v--WQdUV1T5lkEIA7nduRg.png 992w, https://miro.medium.com/max/2000/1*v--WQdUV1T5lkEIA7nduRg.png 1000w" sizes="1000px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure></div></div></div><div class="n p"><div class="ab ac ae af ag dm ai aj"><p id="765c" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">This profile, is on average the one that describes with the better accuracy the purchase probabilities. Now it might suit some individuals pretty well, but in most cases, it makes a poor predictor. So how can we do better? Well, first of all we are going to introduce the distinction between the baskets of individuals by rewriting the full data likelihood:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da qd"><div class="im s fk in"><div class="qe ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*xEmCBFXmKraDfyBYIhOvMQ.png?q=20" width="912" height="121"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="912" height="121"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1824/1*xEmCBFXmKraDfyBYIhOvMQ.png" width="912" height="121" srcSet="https://miro.medium.com/max/552/1*xEmCBFXmKraDfyBYIhOvMQ.png 276w, https://miro.medium.com/max/1104/1*xEmCBFXmKraDfyBYIhOvMQ.png 552w, https://miro.medium.com/max/1280/1*xEmCBFXmKraDfyBYIhOvMQ.png 640w, https://miro.medium.com/max/1400/1*xEmCBFXmKraDfyBYIhOvMQ.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="942e" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now the index i, refers to a specific individual. The index j refers to the current basket for that individual (from 1 to the total number of baskets n_i). We didn’t change anything to the model. This model above is already what we have implemented. We just introduced the distinction between the baskets of individuals. Now remember that we are working with a latent variable model. Each instance of latent variable describes the probability that the basket j from individual i was generated by a cluster k. So instead of the likelihood, we could consider the classification likelihood which is the complete-data likelihood within the EM framework for mixture models:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da qf"><div class="im s fk in"><div class="qg ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*xqg_YR66YOAc2iSxwfwDgg.png?q=20" width="712" height="386"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="712" height="386"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1424/1*xqg_YR66YOAc2iSxwfwDgg.png" width="712" height="386" srcSet="https://miro.medium.com/max/552/1*xqg_YR66YOAc2iSxwfwDgg.png 276w, https://miro.medium.com/max/1104/1*xqg_YR66YOAc2iSxwfwDgg.png 552w, https://miro.medium.com/max/1280/1*xqg_YR66YOAc2iSxwfwDgg.png 640w, https://miro.medium.com/max/1400/1*xqg_YR66YOAc2iSxwfwDgg.png 700w" sizes="700px"/></noscript></div></div></div></div></figure><p id="6352" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So for a specific individual, the complete-data likelihood is computed as:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da qh"><div class="im s fk in"><div class="qi ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*CkTyI1pWbXQVdo4hTK6bAw.png?q=20" width="678" height="116"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="678" height="116"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1356/1*CkTyI1pWbXQVdo4hTK6bAw.png" width="678" height="116" srcSet="https://miro.medium.com/max/552/1*CkTyI1pWbXQVdo4hTK6bAw.png 276w, https://miro.medium.com/max/1104/1*CkTyI1pWbXQVdo4hTK6bAw.png 552w, https://miro.medium.com/max/1280/1*CkTyI1pWbXQVdo4hTK6bAw.png 640w, https://miro.medium.com/max/1356/1*CkTyI1pWbXQVdo4hTK6bAw.png 678w" sizes="678px"/></noscript></div></div></div></figure><p id="2448" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Now, what we can do, is check this implementation for specific individuals by confronting their purchases from the test set and the predictions obtained by sampling from the predictive distribution above.</p><p id="5dba" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In order to build the predictive distribution for a given individual, we iterate through all baskets from the train set for that individual, for every basket, we iterate through every mixture component k and each time we sample from the corresponding multinomial. The sample is then weighted with the mixture weight and the latent probability of the observation belonging to the cluster. In the end, all the samples are summed up and we normalize by the total count to get back a proper probability distribution. Also, in order to score the prediction, we compute the L1-distance between the prediction and the normalized purchases counts from the test set. Here are a two examples:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da qb"><div class="im s fk in"><div class="qj ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*cJemSVHEKwgsolEewhuM5g.png?q=20" width="1852" height="897"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1852" height="897"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3704/1*cJemSVHEKwgsolEewhuM5g.png" width="1852" height="897" srcSet="https://miro.medium.com/max/552/1*cJemSVHEKwgsolEewhuM5g.png 276w, https://miro.medium.com/max/1104/1*cJemSVHEKwgsolEewhuM5g.png 552w, https://miro.medium.com/max/1280/1*cJemSVHEKwgsolEewhuM5g.png 640w, https://miro.medium.com/max/1400/1*cJemSVHEKwgsolEewhuM5g.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da qb"><div class="im s fk in"><div class="qj ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*aNpWWUrHsR1PKi3Fb1p1Kw.png?q=20" width="1852" height="897"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1852" height="897"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3704/1*aNpWWUrHsR1PKi3Fb1p1Kw.png" width="1852" height="897" srcSet="https://miro.medium.com/max/552/1*aNpWWUrHsR1PKi3Fb1p1Kw.png 276w, https://miro.medium.com/max/1104/1*aNpWWUrHsR1PKi3Fb1p1Kw.png 552w, https://miro.medium.com/max/1280/1*aNpWWUrHsR1PKi3Fb1p1Kw.png 640w, https://miro.medium.com/max/1400/1*aNpWWUrHsR1PKi3Fb1p1Kw.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="d2f5" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">We can see that the result is not always as good for every individual. The prediction is obviously better for frequent shoppers than rare ones.</p><h2 id="53af" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Individual weights</h2><p id="080a" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">Ok so is there a way to do even better? The answer is yes and to be found in the research paper that I mentioned at the beginning of this document: “<a href="http://www.datalab.uci.edu/papers/profiles.pdf" class="cm ix" rel="noopener nofollow"><strong class="ja jy">Predictive Profiles for Transaction Data using Finite Mixture Models</strong></a>”.</p><p id="8c15" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">The idea is to replace the global mixture weights by individualized ones. The full data likelihood then becomes:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da qk"><div class="im s fk in"><div class="ql ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*R1RG3jt08tAT1wzm-w8pvg.png?q=20" width="454" height="112"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="454" height="112"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/908/1*R1RG3jt08tAT1wzm-w8pvg.png" width="454" height="112" srcSet="https://miro.medium.com/max/552/1*R1RG3jt08tAT1wzm-w8pvg.png 276w, https://miro.medium.com/max/908/1*R1RG3jt08tAT1wzm-w8pvg.png 454w" sizes="454px"/></noscript></div></div></div></figure><p id="2800" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">This time, I won’t get into the mathematical derivations of the update rules. The only thing you need to know is that they remain the same except for the update of the mixture weight during the m-step that becomes:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da qm"><div class="im s fk in"><div class="qn ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*KkO5iljTJfOAEBI8Y_U6Pw.png?q=20" width="289" height="203"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="289" height="203"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/578/1*KkO5iljTJfOAEBI8Y_U6Pw.png" width="289" height="203" srcSet="https://miro.medium.com/max/552/1*KkO5iljTJfOAEBI8Y_U6Pw.png 276w, https://miro.medium.com/max/578/1*KkO5iljTJfOAEBI8Y_U6Pw.png 289w" sizes="289px"/></noscript></div></div></div></figure><p id="c353" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">If we compare with the previous update rule with the global model, the difference is that now we only use the posterior distribution of the latent variable for the baskets of the individual instead of all the baskets.</p><p id="e949" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">After training of this model, we can compare the new training results (in terms of likelihood and BIC value) with previous ones:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da pa"><div class="im s fk in"><div class="qo ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*rxUwb6IusG9HXqLUEzQWvA.png?q=20" width="960" height="333"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="960" height="333"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1920/1*rxUwb6IusG9HXqLUEzQWvA.png" width="960" height="333" srcSet="https://miro.medium.com/max/552/1*rxUwb6IusG9HXqLUEzQWvA.png 276w, https://miro.medium.com/max/1104/1*rxUwb6IusG9HXqLUEzQWvA.png 552w, https://miro.medium.com/max/1280/1*rxUwb6IusG9HXqLUEzQWvA.png 640w, https://miro.medium.com/max/1400/1*rxUwb6IusG9HXqLUEzQWvA.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="db77" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">We see that, with this new model, the likelihood on the test set is better for any number of clusters which means that the fit is more likely. The issue that we now have though is that the BIC criterion proposes to select only 2 clusters. That seems really inappropriate given the nature of the data. And this is where we touch the limits of the BIC criterion. In this modelization, we replaced the K global mixture weights by K times N individualized mixture weights. This means that the penalization of the number of parameters now weighs a lot more in the formula.</p><p id="8f3c" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">There exists a vast quantity of different criterions for assessing the number of clusters to be selected. Here are the ones that I found:</p><ul class=""><li id="2c61" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt oi lb lc em">Likelihood Ratio Test</li><li id="2fc5" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Akaike’s Information Criterion</li><li id="66ff" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Bootstrapped-Based Information Criterion</li><li id="c13c" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Cross-Validation-Based Information Criterion</li><li id="cf4b" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Minimum Information Ratio Criterion</li><li id="b71b" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Informational Complexity Criterion</li><li id="1a37" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Laplace’s Method of Approximation</li><li id="3bcc" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Bayesian Information Criterion (the one that we used)</li><li id="f75d" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Laplace-Metropolis Criterion</li><li id="73dc" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Laplace-Empirical Criterion</li><li id="4b17" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Reversible Jump Method</li><li id="3f1e" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Miminimum Message Length Principle</li><li id="4a23" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Classification Likelihood Criterion</li><li id="e2d0" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Normalized Entropy Criterion</li><li id="d70a" class="iy iz dp ja b eo ld jc jd er le jf jg jh lf jj jk jl lg jn jo jp lh jr js jt oi lb lc em">Integrated Classification Criterion</li></ul><p id="f7d7" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">I am sure that there other criterions out there and it is still an active research subject. New ways of selecting the best number of clusters are still emerging. So we see the breadth and complexity of the subject. But as I previously said, nothing beats the judgment call of a domain expert.</p><p id="aec0" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Anyhow with this new modelization, we get the following results for the 2 individuals selected in the previous section:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da qb"><div class="im s fk in"><div class="qj ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*iPqLaNdgr-mLZmjRXTQhRg.png?q=20" width="1852" height="897"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1852" height="897"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3704/1*iPqLaNdgr-mLZmjRXTQhRg.png" width="1852" height="897" srcSet="https://miro.medium.com/max/552/1*iPqLaNdgr-mLZmjRXTQhRg.png 276w, https://miro.medium.com/max/1104/1*iPqLaNdgr-mLZmjRXTQhRg.png 552w, https://miro.medium.com/max/1280/1*iPqLaNdgr-mLZmjRXTQhRg.png 640w, https://miro.medium.com/max/1400/1*iPqLaNdgr-mLZmjRXTQhRg.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="ie if fk ig aj"><div class="cz da qb"><div class="im s fk in"><div class="qj ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*DsUVBjPxelX47EEzZL7VQA.png?q=20" width="1852" height="897"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="1852" height="897"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/3704/1*DsUVBjPxelX47EEzZL7VQA.png" width="1852" height="897" srcSet="https://miro.medium.com/max/552/1*DsUVBjPxelX47EEzZL7VQA.png 276w, https://miro.medium.com/max/1104/1*DsUVBjPxelX47EEzZL7VQA.png 552w, https://miro.medium.com/max/1280/1*DsUVBjPxelX47EEzZL7VQA.png 640w, https://miro.medium.com/max/1400/1*DsUVBjPxelX47EEzZL7VQA.png 700w" sizes="700px"/></noscript></div></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="7c3d" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">We went from 1.625 to 1.564 in L1-distance for household 892 and from 0.647 to 0.530 for household 72. Now performing the same exercise for every household, we can record the obtained distances and confront them on a scatter plot:</p><figure class="hx hy hz ia ib hn cz da paragraph-image"><div class="cz da qp"><div class="im s fk in"><div class="qq ip s"><div class="ih ii t u v ij aj bm ik il"><img alt="Image for post" class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*VZyxi-Lujf_iUllFoBJdYA.png?q=20" width="615" height="589"/></div><img alt="Image for post" class="ih ii t u v ij aj c" width="615" height="589"/><noscript><img alt="Image for post" class="t u v ij aj" src="https://miro.medium.com/max/1230/1*VZyxi-Lujf_iUllFoBJdYA.png" width="615" height="589" srcSet="https://miro.medium.com/max/552/1*VZyxi-Lujf_iUllFoBJdYA.png 276w, https://miro.medium.com/max/1104/1*VZyxi-Lujf_iUllFoBJdYA.png 552w, https://miro.medium.com/max/1230/1*VZyxi-Lujf_iUllFoBJdYA.png 615w" sizes="615px"/></noscript></div></div></div><figcaption class="it iu db cz da iv iw cg b fw ci fe">Image by author</figcaption></figure><p id="3d95" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Every point below the diagonal corresponds to a household for which the prediction distance was smaller with the individualized model. It is not necessarily obvious from the above plot, but we performed a better prediction for 61.57% of the households.</p><p id="6fd7" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">So in the end, we consider that the second modelization with individual mixture weights is a better model because it gives a better predictive performance on the test set. We just did not found, yet, a way to correctly assess the number of clusters (although I would probably select 30 clusters as we did with the global model) and I leave that as an exercise for the interested reader.</p><p id="36f6" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">Regarding this last point, you can reproduce all the results using the code on my github (along with the notebooks for data exploration, model selection and results analysis) =&gt; <a href="https://github.com/biarne-a/MNMM" class="cm ix" rel="noopener nofollow">https://github.com/biarne-a/MNMM</a></p><h2 id="57ce" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Final thoughts on the model</h2><p id="5d32" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">This model allows to predicts which products an individual is likely to purchase, but not how many or when they will be purchased. The multinomial distribution gives counts of purchased items but requires the total number of purchased items in a basket as input. So ideally we would need another model to predict the total number of items an individual would purchase on a given day. Also in order to model the rate of visits to the store we could have used a <a href="https://en.wikipedia.org/wiki/Poisson_point_process" class="cm ix" rel="noopener nofollow">Poisson process</a> and we would have had to take care of seasonality patterns.</p><p id="6cdd" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">One important point is that in the paper that inspired this article, the authors use the EM algorithm to find the <a href="https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation" class="cm ix" rel="noopener nofollow">Maximum A Posteriori</a> (MAP) estimates of the model parameters, whereas we found the MLE estimates. This is more in line with the Bayesian philosophy. It means that they declared priors on the parameters α and β of the model (both Dirchlet priors). This approach is better because it allows among other things to regularize the model. We can see it as, starting from plausible guesses for the parameters, we refine the values according to the amount of data we have at our disposal. For the individualized model we start with the global estimates of the model. If we don’t have much data about an individual, then its estimates will stay close to the global ones. I didn’t want to take this approach for the sake of this article because it would have complicated things even more (and I would also have had to introduce the Dirichlet distribution among other things).</p><h2 id="da12" class="lj ka dp cg kb lk ll eq ke lm ln et kh eu lo ew kl ex lp ez kp fa lq fc kt lr em">Final words</h2><p id="3ed2" class="iy iz dp ja b eo kv jc jd er kw jf jg jh kx jj jk jl ky jn jo jp kz jr js jt dh em">This has been quite a journey! If you read up to this point, it probably means that you have found this interesting and maybe you learned a few things along the way (at least I hope).</p><p id="f5b2" class="iy iz dp ja b eo jb jc jd er je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt dh em">In any case, take care of your selves and loved ones!</p></div></div></section></div></article><div class="ih dg qs qr aj qy qw qz" data-test-id="post-sidebar"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="ra n rb"><div class="dg"><div><div class="rd re s"><a href="https://towardsdatascience.com/?source=post_sidebar--------------------------post_sidebar-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener"><h2 class="cg kb rc ci do em dh">Towards Data Science</h2></a><div class="rf rg s"><h4 class="cg b fw ci bm rh ga gb ri gd ge fe">A Medium publication sharing concepts, ideas, and codes.</h4></div><div class="gx" aria-hidden="false"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=--------------------------follow_card-----------" class="cg b fw ci at rj gk au rk bd be rl bc gp gq rm rn ro gu gv gw dc gx gy" rel="noopener"><div class="n fo">Follow</div></a></span></div></div><div class="rp rq rr n"><div class="n o"><div class="s fk rs rt ru rv rw"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=post_sidebar-----268974d905da---------------------clap_sidebar-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener"><div class="ba rx ry rz sa sb sc sd r se sf"><svg width="29" height="29" aria-label="clap"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s sg sh si sj sk sl sm"><div class="sn"><h4 class="cg b fw ci fe"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh">40<!-- --> </button></h4></div></div></div></div><div class="rq s"><button class="sa ry ba"><div class="sq n o fo"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg><div class="s fk sr ss st su sv sw sx sy"></div></div></button></div><div class="hk"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=post_sidebar-----268974d905da---------------------bookmark_sidebar-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div></div><div class="ih dg qr qs qt fs qu qv qw qx"></div><div><div class="sz hn n rb p"><div class="n p"><div class="ab ac ae af ag dm ai aj"><div class="ta tb tc td te tf"><h2 class="cg kb lk eq ke lm et kh eu ew kl ex ez kp fa fc kt em">Sign up for The Daily Pick</h2><div class="tg s"><h3 class="cg b ch ci em">By Towards Data Science</h3></div><div class="th ti s"><p class="cg b tj tk tl tm tn to tp tq tr ts em">Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.<!-- --> <a href="https://medium.com/towards-data-science/newsletters/the-daily-pick?source=newsletter_v3_promo--------------------------newsletter_v3_promo-----------" class="cm cn av aw ax ay az ba bb bc bf gg gh ix" rel="noopener">Take a look</a></p></div><div class="n tt"><div class="n bw rb tu"><div id="g-recaptcha"></div><div class="tv"><div class="tw n o fg tx ty tz ua"><div class="ub s uc"><div class=""><div class="uu uo n o rb us"><div class="fk"><div class="uv s"><h4 class="cg b rc uw fe"><input type="text" aria-label="email" class="ud ue uf ug uh ui uj uk ul um un uo up uq ur us em ut" pattern=".*" placeholder="Your email" value=""/></h4></div></div></div></div></div><div class="ux cc s hd uy"><div><button class="cg b rc uw uz va vb vc rk vd rl bc gp gq ve ro gu gv gw dc gx gy"><span class="hl" aria-hidden="true"><svg width="20" height="16" viewBox="0 0 20 16"><path d="M0 .35v15.3h20V.35H0zm6.95 9.38l3.05 2.5 3.05-2.5 4.88 4.73H2.07l4.88-4.73zM1.2 13.64V5.02l4.82 3.94-4.82 4.68zm12.78-4.68l4.82-3.94v8.62l-4.82-4.68zm4.82-7.42v1.94l-8.8 7.2-8.8-7.2V1.54h17.6z"></path></svg></span>Get this newsletter</button></div></div></div><div class="vf it s uc"><h4 class="cg b vg vh fe">By signing up, you will create a <!-- -->Medium<!-- --> account if you don’t already have one. Review our<!-- --> <a href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=newsletter_v3_promo--------------------------newsletter_v3_promo-----------" class="cm cn av aw ax ay az ba bb bc bf gg gh ix" target="_blank" rel="noopener">Privacy Policy</a> <!-- -->for more information about our privacy practices.</h4></div></div><div class="vi vj vk"><h4 class="cg b fw ci em"><b>Check your inbox</b><br/>Medium<!-- --> sent you an email at <!-- --> to complete your subscription.</h4></div></div></div></div><div class="n tt"></div><div class="n o tt"></div><div class="vl s"><ul class="ba bb"><li class="gx bs hl vm"><a href="/tagged/bayesian-statistics" class="cg b ch vn fe vo vp gy s vq">Bayesian Statistics</a></li><li class="gx bs hl vm"><a href="/tagged/marketing" class="cg b ch vn fe vo vp gy s vq">Marketing</a></li><li class="gx bs hl vm"><a href="/tagged/statistics" class="cg b ch vn fe vo vp gy s vq">Statistics</a></li><li class="gx bs hl vm"><a href="/tagged/machine-learning" class="cg b ch vn fe vo vp gy s vq">Machine Learning</a></li><li class="gx bs hl vm"><a href="/tagged/mixture-models" class="cg b ch vn fe vo vp gy s vq">Mixture Models</a></li></ul></div><div class="vl n fg z"><div class="n fo"><div class="vr s"><span class="s vs vt vu e d"><div class="n o"><div class="s fk rs rt ru rv rw"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=post_actions_footer-----268974d905da---------------------clap_footer-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener"><div class="ba rx ry rz sa sb sc sd r se sf"><svg width="25" height="25" viewBox="0 0 25 25" aria-label="clap"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></div></a></span></div><div class="s sg sh si sj sk sl sm"><div class="fk vv sn"><h4 class="cg b fw ci em"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh">40<span class="s h g f vw vx"> <!-- -->claps</span></button><span class="s h g f vw vx"></span></h4></div></div></div></span><span class="s h g f vw vx"><div class="n bw"><div class="s fk rs rt"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fvote%2Ftowards-data-science%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=post_actions_footer-----268974d905da---------------------clap_footer-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener"><div class="ba rx ry rz sa sb sc sd r se sf"><svg width="33" height="33" viewBox="0 0 33 33" aria-label="clap"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></div></a></span></div><div class="s sg sh si sj vy vz wa wb wc wd"><div class="fk vv sn"><h4 class="cg b fw ci em"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh">40<span class="s h g f vw vx"> <!-- -->claps</span></button><span class="s h g f vw vx"></span></h4></div></div></div></span></div><div class="s we wf wg wh wi"></div><button class="sa ry ba"><div class="sq n o fo"><span class="wj s h g f vw vx"><svg width="33" height="33" viewBox="0 0 33 33" fill="none" class="r" aria-label="responses"><path clip-rule="evenodd" d="M24.28 25.5l.32-.29c2.11-1.94 3.4-4.61 3.4-7.56C28 11.83 22.92 7 16.5 7S5 11.83 5 17.65s5.08 10.66 11.5 10.66c1.22 0 2.4-.18 3.5-.5l.5-.15.41.33a8.86 8.86 0 0 0 4.68 2.1 7.34 7.34 0 0 1-1.3-4.15v-.43zm1 .45c0 1.5.46 2.62 1.69 4.44.22.32.01.75-.38.75a9.69 9.69 0 0 1-6.31-2.37c-1.2.35-2.46.54-3.78.54C9.6 29.3 4 24.09 4 17.65 4 11.22 9.6 6 16.5 6S29 11.22 29 17.65c0 3.25-1.42 6.18-3.72 8.3z"></path></svg></span><span class="wk s vs vt vu e d"><svg width="25" height="25" class="r" aria-label="responses"><path d="M19.07 21.12a6.33 6.33 0 0 1-3.53-1.1 7.8 7.8 0 0 1-.7-.52c-.77.21-1.57.32-2.38.32-4.67 0-8.46-3.5-8.46-7.8C4 7.7 7.79 4.2 12.46 4.2c4.66 0 8.46 3.5 8.46 7.8 0 2.06-.85 3.99-2.4 5.45a6.28 6.28 0 0 0 1.14 2.59c.15.21.17.48.06.7a.69.69 0 0 1-.62.38h-.03zm0-1v.5l.03-.5h-.03zm-3.92-1.64l.21.2a6.09 6.09 0 0 0 3.24 1.54 7.14 7.14 0 0 1-.83-1.84 5.15 5.15 0 0 1-.16-.75 2.4 2.4 0 0 1-.02-.29v-.23l.18-.15a6.6 6.6 0 0 0 2.3-4.96c0-3.82-3.4-6.93-7.6-6.93-4.19 0-7.6 3.11-7.6 6.93 0 3.83 3.41 6.94 7.6 6.94.83 0 1.64-.12 2.41-.35l.28-.08z" fill-rule="evenodd"></path></svg></span><div class="s fk wl ss wm su wn sw wo wp wq wr"></div></div></button></div><div class="n o"><div class="hh s aq"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" aria-label="Share on twitter"><svg width="29" height="29" class="hk"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></button></div><div class="hh s aq"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" aria-label="Share on linkedin"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="hk"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="hh s aq"><button class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" aria-label="Share on facebook"><svg width="29" height="29" class="hk"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></button></div><div class="ws s aq"><div class="hk"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fbookmark%2Fp%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=post_actions_footer--------------------------bookmark_footer-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></a></span></div></div></div></div></div></div><div><div class="n p"><div class="ab ac ae af ag dm ai aj"><div class="wt wu td vl s wv z"><div class="s g"><div class="ww wx s fk"><span class="s wy am wz"><div class="s t xa xb"><a href="/@biarnes.adrien?source=follow_footer--------------------------follow_footer-----------" rel="noopener"><div class="fk xc bz"><div class="fn n fo o p t fp fq fr fs ft dg"><svg width="91" height="91" viewBox="0 0 91 91"><path fill-rule="evenodd" clip-rule="evenodd" d="M45.5 1.4c-17.14 0-32 9.95-39.25 24.5L5 25.28C12.47 10.28 27.8 0 45.5 0S78.53 10.29 86 25.28l-1.25.62C77.5 11.35 62.65 1.4 45.5 1.4zM6.25 65.1c7.25 14.55 22.1 24.5 39.25 24.5 17.14 0 32-9.95 39.25-24.5l1.25.62C78.53 80.72 63.2 91 45.5 91S12.47 80.71 5 65.72l1.25-.62z"></path></svg></div><img alt="Adrien Biarnes" class="s fu bz xc" src="https://miro.medium.com/fit/c/160/160/0*WCSvEV6fU3deUzGB." width="80" height="80"/></div></a></div><span class="s"><div class="xd s xe"><p class="cg b ch xf xg fe ck">Written by</p></div><div class="xd xh n xe"><div class="aj n o fg"><h2 class="cg kb xi xj do em"><a href="/@biarnes.adrien?source=follow_footer--------------------------follow_footer-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener">Adrien Biarnes</a></h2><div class="s g"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fuser%2F151fca431deb%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=follow_footer-151fca431deb-------------------------follow_footer-----------" class="cg b fw ci at rj gk au rk bd be rl bc gp gq rm rn ro gu gv gw dc gx gy" rel="noopener">Follow</a></span></div></div></div></span></span><div class="xd xk s xe bk"><div class="xl s"><h4 class="cg b rc uw fe">I am data scientist / machine learning engineer. I love to learn and share my passion for data science — https://www.linkedin.com/in/adrien-biarnes-81975717</h4></div><div class="vk xm bk"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fuser%2F151fca431deb%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=follow_footer-151fca431deb-------------------------follow_footer-----------" class="cg b fw ci at rj gk au rk bd be rl bc gp gq rm rn ro gu gv gw dc gx gy" rel="noopener">Follow</a></span></div></div></div><div class="wt s"></div><div class="ww wx s fk"><span class="s wy am wz"><div class="s t xa xb"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-----------" rel="noopener"><img alt="Towards Data Science" class="gu xc bz" src="https://miro.medium.com/fit/c/160/160/1*hVxgUA6kP-PgL5TJjuyePg.png" width="80" height="80"/></a></div><span class="s"><div class="xd xh n xe"><div class="aj n o fg"><h2 class="cg kb xi xj do em"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener">Towards Data Science</a></h2><div class="s g"><div class="gx" aria-hidden="false"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=--------------------------follow_card-----------" class="cg b fw ci at rj gk au rk bd be rl bc gp gq rm rn ro gu gv gw dc gx gy" rel="noopener"><div class="n fo">Follow</div></a></span></div></div></div></div></span></span><div class="xd xn s xe bk"><div class="xl s"><h4 class="cg b rc uw fe">A Medium publication sharing concepts, ideas, and codes.</h4></div><div class="vk xm bk"><div class="gx" aria-hidden="false"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=--------------------------follow_card-----------" class="cg b fw ci at rj gk au rk bd be rl bc gp gq rm rn ro gu gv gw dc gx gy" rel="noopener"><div class="n fo">Follow</div></a></span></div></div></div></div></div><div class="vk bk"><div class="xo s"><div class="n fo"><div class="vj s"><a href="/@biarnes.adrien?source=follow_footer--------------------------follow_footer-----------" rel="noopener"><div class="fk xp xq"><div class="fn n fo o p t fp fq fr fs ft dg"><svg width="49" height="49" viewBox="0 0 49 49"><path fill-rule="evenodd" clip-rule="evenodd" d="M24.5 1.1c-9.39 0-17.53 5.55-21.51 13.66L2 14.28C6.15 5.82 14.66 0 24.5 0S42.85 5.82 47 14.28l-.99.48C42.03 6.65 33.9 1.1 24.5 1.1zM2.99 34.24C6.97 42.35 15.1 47.9 24.5 47.9c9.39 0 17.53-5.55 21.51-13.66l.99.48C42.85 43.18 34.34 49 24.5 49S6.15 43.18 2 34.72l.99-.48z"></path></svg></div><img alt="Adrien Biarnes" class="s fu xq xp" src="https://miro.medium.com/fit/c/80/80/0*WCSvEV6fU3deUzGB." width="40" height="40"/></div></a></div><div class="fv s"><p class="cg b xr vh xs fe ck">Written by</p><div class="n fo"><h2 class="cg kb rc ci do em"><a href="/@biarnes.adrien?source=follow_footer--------------------------follow_footer-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener">Adrien Biarnes</a></h2><div class="fv s"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fuser%2F151fca431deb%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=follow_footer-151fca431deb-------------------------follow_footer-----------" class="cg b ch ci at gj gk au rk bd be rl bc gp gq rm rn ro gu gv gw dc gx gy" rel="noopener">Follow</a></span></div></div><div class="ti s"><h4 class="cg b fw ci fe">I am data scientist / machine learning engineer. I love to learn and share my passion for data science — https://www.linkedin.com/in/adrien-biarnes-81975717</h4></div></div></div><div class="xo s"><div class="n fo"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-----------" rel="noopener"><img alt="Towards Data Science" class="gu xp xq" src="https://miro.medium.com/fit/c/80/80/1*hVxgUA6kP-PgL5TJjuyePg.png" width="40" height="40"/></a><div class="fv s"><div class="n fo"><h2 class="cg kb rc ci do em"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-----------" class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh" rel="noopener">Towards Data Science</a></h2><div class="fv s"><div class="gx" aria-hidden="false"><span><a href="https://medium.com/m/signin?actionUrl=%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2F268974d905da&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da&amp;source=--------------------------follow_card-----------" class="cg b fw ci at rj gk au rk bd be rl bc gp gq rm rn ro gu gv gw dc gx gy" rel="noopener"><div class="n fo">Follow</div></a></span></div></div></div><div class="ti s"><h4 class="cg b fw ci fe">A Medium publication sharing concepts, ideas, and codes.</h4></div></div></div></div></div></div></div><div class="xt wu s wv xu z"></div></div></div><div class="s xv z"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="xw xx s"><div class="xy re xz xx s ya yb"><h2 class="cg kb lk eq ke lm et kh eu ew kl ex ez kp fa fc kt em">More From Medium</h2></div><div class="bw n fo tt yc yd ye yf yg yh yi yj yk yl ym yn yo yp yq"><div class="yr ys yt hp yu yv yw hr yx yy yz za zb zc zd ze zf zg zh zi zj"><div class="zk zl s"><div class="aj ij"><div class="n fg"><div class="s br zm zn zo"><div class="zp s"><h2 class="cg kb zq tk ke zr tm kh tn zs kl tp zt kp tr zu kt em"><a rel="noopener" href="/its-time-to-say-goodbye-to-docker-5cfec8eff833?source=post_internal_links---------0----------------------------">You Don’t Have to Use Docker Anymore</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="cs n o fy"><span class="cg b ch ci em"><a href="/@martin.heinz?source=post_internal_links---------0----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Martin Heinz</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------0----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="fv hl s zv zw"><a class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh s" rel="noopener" href="/its-time-to-say-goodbye-to-docker-5cfec8eff833?source=post_internal_links---------0----------------------------"><div class="im s fk in"><div class="zx ip s"><div class="ih ii t u v ij aj bm ik il"><img class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*t8Ls5sYb8pQtEVHVhk-GOA.jpeg?q=20" width="70" height="70" role="presentation"/></div><img class="ih ii zy zz aba abb abc abd abe abf abg abh c" width="70" height="70" role="presentation"/><noscript><img class="zy zz aba abb abc abd abe abf abg abh" src="https://miro.medium.com/fit/c/140/140/1*t8Ls5sYb8pQtEVHVhk-GOA.jpeg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*t8Ls5sYb8pQtEVHVhk-GOA.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*t8Ls5sYb8pQtEVHVhk-GOA.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="yr ys yt hp yu yv yw hr yx yy yz za zb zc zd ze zf zg zh zi zj"><div class="zk zl s"><div class="aj ij"><div class="n fg"><div class="s br zm zn zo"><div class="zp s"><h2 class="cg kb zq tk ke zr tm kh tn zs kl tp zt kp tr zu kt em"><a rel="noopener" href="/python-is-slowly-losing-its-charm-9ca652726492?source=post_internal_links---------1----------------------------">Python is Slowly Losing its Charm</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="cs n o fy"><span class="cg b ch ci em"><a href="/@jasmcaus?source=post_internal_links---------1----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Jason Dsouza</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------1----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="fv hl s zv zw"><a class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh s" rel="noopener" href="/python-is-slowly-losing-its-charm-9ca652726492?source=post_internal_links---------1----------------------------"><div class="im s fk in"><div class="zx ip s"><div class="ih ii t u v ij aj bm ik il"><img class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/0*5Q1joBvY2S01IeMz?q=20" width="70" height="70" role="presentation"/></div><img class="ih ii zy zz aba abb abc abd abe abf abg abh c" width="70" height="70" role="presentation"/><noscript><img class="zy zz aba abb abc abd abe abf abg abh" src="https://miro.medium.com/fit/c/140/140/0*5Q1joBvY2S01IeMz" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*5Q1joBvY2S01IeMz 48w, https://miro.medium.com/fit/c/140/140/0*5Q1joBvY2S01IeMz 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="yr ys yt hp yu yv yw hr yx yy yz za zb zc zd ze zf zg zh zi zj"><div class="zk zl s"><div class="aj ij"><div class="n fg"><div class="s br zm zn zo"><div class="zp s"><h2 class="cg kb zq tk ke zr tm kh tn zs kl tp zt kp tr zu kt em"><a rel="noopener" href="/golang-ai-programming-language-for-the-20s-71890baa8c47?source=post_internal_links---------2----------------------------">Go Programming Language for Artificial Intelligence and Data Science of the 20s</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="cs n o fy"><span class="cg b ch ci em"><a href="https://skdasaradh.medium.com/?source=post_internal_links---------2----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Dasaradh S K</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------2----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="fv hl s zv zw"><a class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh s" rel="noopener" href="/golang-ai-programming-language-for-the-20s-71890baa8c47?source=post_internal_links---------2----------------------------"><div class="im s fk in"><div class="zx ip s"><div class="ih ii t u v ij aj bm ik il"><img class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/0*pNloJM4kaHbQx19G?q=20" width="70" height="70" role="presentation"/></div><img class="ih ii zy zz aba abb abc abd abe abf abg abh c" width="70" height="70" role="presentation"/><noscript><img class="zy zz aba abb abc abd abe abf abg abh" src="https://miro.medium.com/fit/c/140/140/0*pNloJM4kaHbQx19G" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*pNloJM4kaHbQx19G 48w, https://miro.medium.com/fit/c/140/140/0*pNloJM4kaHbQx19G 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="yr ys yt hp yu yv yw hr yx yy yz za zb zc zd ze zf zg zh zi zj"><div class="zk zl s"><div class="aj ij"><div class="n fg"><div class="s br zm zn zo"><div class="zp s"><h2 class="cg kb zq tk ke zr tm kh tn zs kl tp zt kp tr zu kt em"><a rel="noopener" href="/how-to-spot-a-data-charlatan-85785c991433?source=post_internal_links---------3----------------------------">How to spot a data charlatan</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="cs n o fy"><span class="cg b ch ci em"><a href="/@kozyrkov?source=post_internal_links---------3----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Cassie Kozyrkov</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------3----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="fv hl s zv zw"><a class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh s" rel="noopener" href="/how-to-spot-a-data-charlatan-85785c991433?source=post_internal_links---------3----------------------------"><div class="im s fk in"><div class="zx ip s"><div class="ih ii t u v ij aj bm ik il"><img class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*0dbUWoessUtJHUsO4qkpJQ.png?q=20" width="70" height="70" role="presentation"/></div><img class="ih ii zy zz aba abb abc abd abe abf abg abh c" width="70" height="70" role="presentation"/><noscript><img class="zy zz aba abb abc abd abe abf abg abh" src="https://miro.medium.com/fit/c/140/140/1*0dbUWoessUtJHUsO4qkpJQ.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*0dbUWoessUtJHUsO4qkpJQ.png 48w, https://miro.medium.com/fit/c/140/140/1*0dbUWoessUtJHUsO4qkpJQ.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="yr ys yt hp yu yv yw hr yx yy yz za zb zc zd ze zf zg zh zi zj"><div class="zk zl s"><div class="aj ij"><div class="n fg"><div class="s br zm zn zo"><div class="zp s"><h2 class="cg kb zq tk ke zr tm kh tn zs kl tp zt kp tr zu kt em"><a rel="noopener" href="/10-awesome-python-3-9-features-b8c27f5eba5c?source=post_internal_links---------4----------------------------">10 Awesome Python 3.9 Features</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="cs n o fy"><span class="cg b ch ci em"><a href="/@farhadmalik?source=post_internal_links---------4----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Farhad Malik</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------4----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="fv hl s zv zw"><a class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh s" rel="noopener" href="/10-awesome-python-3-9-features-b8c27f5eba5c?source=post_internal_links---------4----------------------------"><div class="im s fk in"><div class="zx ip s"><div class="ih ii t u v ij aj bm ik il"><img class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*49w_B1vpnCgQx8C2TA7CUw.png?q=20" width="70" height="70" role="presentation"/></div><img class="ih ii zy zz aba abb abc abd abe abf abg abh c" width="70" height="70" role="presentation"/><noscript><img class="zy zz aba abb abc abd abe abf abg abh" src="https://miro.medium.com/fit/c/140/140/1*49w_B1vpnCgQx8C2TA7CUw.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*49w_B1vpnCgQx8C2TA7CUw.png 48w, https://miro.medium.com/fit/c/140/140/1*49w_B1vpnCgQx8C2TA7CUw.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="yr ys yt hp yu yv yw hr yx yy yz za zb zc zd ze zf zg zh zi zj"><div class="zk zl s"><div class="aj ij"><div class="n fg"><div class="s br zm zn zo"><div class="zp s"><h2 class="cg kb zq tk ke zr tm kh tn zs kl tp zt kp tr zu kt em"><a rel="noopener" href="/10-underrated-python-skills-dfdff5741fdf?source=post_internal_links---------5----------------------------">10 Underrated Python Skills</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="cs n o fy"><span class="cg b ch ci em"><a href="/@nicolejaneway?source=post_internal_links---------5----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Nicole Janeway Bills</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------5----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="fv hl s zv zw"><a class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh s" rel="noopener" href="/10-underrated-python-skills-dfdff5741fdf?source=post_internal_links---------5----------------------------"><div class="im s fk in"><div class="zx ip s"><div class="ih ii t u v ij aj bm ik il"><img class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*rhWS22PAJaqMJQYJDL0y-A.jpeg?q=20" width="70" height="70" role="presentation"/></div><img class="ih ii zy zz aba abb abc abd abe abf abg abh c" width="70" height="70" role="presentation"/><noscript><img class="zy zz aba abb abc abd abe abf abg abh" src="https://miro.medium.com/fit/c/140/140/1*rhWS22PAJaqMJQYJDL0y-A.jpeg" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*rhWS22PAJaqMJQYJDL0y-A.jpeg 48w, https://miro.medium.com/fit/c/140/140/1*rhWS22PAJaqMJQYJDL0y-A.jpeg 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="yr ys yt hp yu yv yw hr yx yy yz za zb zc zd ze zf zg zh zi zj"><div class="zk zl s"><div class="aj ij"><div class="n fg"><div class="s br zm zn zo"><div class="zp s"><h2 class="cg kb zq tk ke zr tm kh tn zs kl tp zt kp tr zu kt em"><a rel="noopener" href="/python-3-9-9c2ce1332eb4?source=post_internal_links---------6----------------------------">Python 3.9</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="cs n o fy"><span class="cg b ch ci em"><a href="https://jamescalam.medium.com/?source=post_internal_links---------6----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">James Calam</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------6----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="fv hl s zv zw"><a class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh s" rel="noopener" href="/python-3-9-9c2ce1332eb4?source=post_internal_links---------6----------------------------"><div class="im s fk in"><div class="zx ip s"><div class="ih ii t u v ij aj bm ik il"><img class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/0*lG7s6Lf_SiRpxtti?q=20" width="70" height="70" role="presentation"/></div><img class="ih ii zy zz aba abb abc abd abe abf abg abh c" width="70" height="70" role="presentation"/><noscript><img class="zy zz aba abb abc abd abe abf abg abh" src="https://miro.medium.com/fit/c/140/140/0*lG7s6Lf_SiRpxtti" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/0*lG7s6Lf_SiRpxtti 48w, https://miro.medium.com/fit/c/140/140/0*lG7s6Lf_SiRpxtti 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div><div class="yr ys yt hp yu yv yw hr yx yy yz za zb zc zd ze zf zg zh zi zj"><div class="zk zl s"><div class="aj ij"><div class="n fg"><div class="s br zm zn zo"><div class="zp s"><h2 class="cg kb zq tk ke zr tm kh tn zs kl tp zt kp tr zu kt em"><a rel="noopener" href="/tiny-machine-learning-the-next-ai-revolution-495c26463868?source=post_internal_links---------7----------------------------">Tiny Machine Learning: The Next AI Revolution</a></h2></div><div class="o n"><div></div><div class="aj s"><div class="n"><div style="flex:1"><span class="cg b fw ci em"><div class="cs n o fy"><span class="cg b ch ci em"><a href="/@matthew_stewart?source=post_internal_links---------7----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Matthew Stewart, PhD Researcher</a><span> <!-- -->in<!-- --> <a href="https://towardsdatascience.com/?source=post_internal_links---------7----------------------------" class="cm cn av aw ax ay az ba bb bc gf bf gg gh" rel="noopener">Towards Data Science</a></span></span></div></span></div></div></div></div></div><div class="fv hl s zv zw"><a class="cm cn av aw ax ay az ba bb bc hi hj bf gg gh s" rel="noopener" href="/tiny-machine-learning-the-next-ai-revolution-495c26463868?source=post_internal_links---------7----------------------------"><div class="im s fk in"><div class="zx ip s"><div class="ih ii t u v ij aj bm ik il"><img class="t u v ij aj iq ir is" src="https://miro.medium.com/max/60/1*ofX7aZroN2tkwOjJhECmNQ.png?q=20" width="70" height="70" role="presentation"/></div><img class="ih ii zy zz aba abb abc abd abe abf abg abh c" width="70" height="70" role="presentation"/><noscript><img class="zy zz aba abb abc abd abe abf abg abh" src="https://miro.medium.com/fit/c/140/140/1*ofX7aZroN2tkwOjJhECmNQ.png" width="70" height="70" srcSet="https://miro.medium.com/fit/c/96/140/1*ofX7aZroN2tkwOjJhECmNQ.png 48w, https://miro.medium.com/fit/c/140/140/1*ofX7aZroN2tkwOjJhECmNQ.png 70w" sizes="70px" role="presentation"/></noscript></div></div></a></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="abi s abj abk"><div class="n p"><div class="ab ac ae af ag ah ai aj"><div class="abl abm ww n fg g"><div class="abn n fg"><div class="abo s abp"><div class="zp s"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc abq abr bf abs abt" rel="noopener"><h2 class="cg kb abu uw do abv">Learn more.</h2></a></div><h4 class="cg b fw ci abw">Medium is an open platform where 170 million readers come to find insightful and dynamic thinking.
                        Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. <a href="https://medium.com/about?autoplay=1&amp;source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc bf abs abt ix" rel="noopener">Learn more</a></h4></div><div class="abo s abp"><div class="zp s"><a href="https://medium.com/topics?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc abq abr bf abs abt" rel="noopener"><h2 class="cg kb abu uw do abv">Make <!-- -->Medium<!-- --> yours<!-- -->.</h2></a></div><h4 class="cg b fw ci abw">Follow the writers, publications, and topics that matter to you, and you’ll see them on your homepage and in your inbox. <a href="https://medium.com/topics?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc bf abs abt ix" rel="noopener">Explore</a></h4></div><div class="abo s abp"><div class="zp s"><a href="https://about.medium.com/creators/?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc abq abr bf abs abt" rel="noopener"><h2 class="cg kb abu uw do abv">Share your thinking.</h2></a></div><h4 class="cg b fw ci abw">If you have a story to tell, knowledge to share, or a perspective to offer — welcome home.
        It’s easy and free to post your thinking on any topic. <a href="https://about.medium.com/creators/?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc bf abs abt ix" rel="noopener">Write on Medium</a></h4></div></div></div><div class="n rb"><div class="n o fg"><a href="https://medium.com/?source=post_page-----268974d905da--------------------------------" aria-label="Go to homepage" class="cm cn av aw ax ay az ba bb bc abq abr bf abs abt" rel="noopener"><svg viewBox="0 0 3940 610" class="vb abx"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><h4 class="cg b fw ci abw"><div class="ti aby n fg abz am"><h4 class="cg b rc uw abv"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc gf bf abs abt" rel="noopener">About</a></h4><h4 class="cg b rc uw abv"><a href="https://help.medium.com/hc/en-us?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc gf bf abs abt" rel="noopener">Help</a></h4><h4 class="cg b rc uw abv"><a href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc gf bf abs abt" rel="noopener">Legal</a></h4></div></h4></div><div class="vk aca acb am"><h4 class="cg b rc uw abw">Get the Medium app</h4></div><div class="vk aca acc am acd"><div class="ace s"><a href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc abq abr bf abs abt" rel="noopener nofollow"><img alt="A button that says &#x27;Download on the App Store&#x27;, and if clicked it will lead you to the iOS App store" class="" src="https://miro.medium.com/max/270/1*Crl55Tm6yDNMoucPo1tvDg.png" width="135" height="41"/></a></div><div class="s"><a href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----268974d905da--------------------------------" class="cm cn av aw ax ay az ba bb bc abq abr bf abs abt" rel="noopener nofollow"><img alt="A button that says &#x27;Get it on, Google Play&#x27;, and if clicked it will lead you to the Google Play store" class="" src="https://miro.medium.com/max/270/1*W_RAPQ62h0em559zluJLdQ.png" width="135" height="41"/></a></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__ = "main-20201016-200229-6444e2d97a"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"auroraPage":{"isAuroraPageEnabled":false},"config":{"nodeEnv":"production","version":"main-20201016-200229-6444e2d97a","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"main-20201016-200229-6444e2d97a"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","context":{"deployment":{"target":"production","tag":"main-20201016-200229-6444e2d97a","commit":"6444e2d97a765554b77c08bd6f4823d2bc2eaf03"}},"datacenter":"us"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e","9dc80918cc93","8a9336e5bb4","cef6983b292","54c98c43354d","193b68bd4fba","b7e45b22fec3"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*3sela1OADrJr7dJk_CXaEQ.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"performanceTags":[],"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":["pandemic","epidemic","coronavirus","covid19","co-vid-19","containment","self-care","flatten-the-curve","public-health","virus","public-health-crisis","quarantine","self-quarantine","zika","corona","disease-prevention","wuhan","chinavirus","outbreak","influenza","socialdistancing","social-distance","flu","vaccines","healthcare","medicine","conspiracy-theories","conspiracy","virality","epidemia","pandemia","salud","corona-e-virus","coronavirus-covid19","covid-19","covid-19-symptoms","covid-19-crisis","covid-19-testing","covid-19-treatment","coronavirus-update","coronavirus-diaries"],"COVID_APPLICABLE_TOPIC_NAMES":["coronavirus"],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":["coronavirus","health"],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Check your U.S. voter registration status or register to vote here.","markups":[{"start":62,"end":66,"href":"https:\u002F\u002Fwww.vote.org\u002F"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v"},"debug":{"requestId":"99e7d037-a984-4cd0-9c54-cf8e6e2493b2","originalSpanCarrier":{"ot-tracer-spanid":"561ec2c3596702d4","ot-tracer-traceid":"53d1f3f6d580d0ef","ot-tracer-sampled":"true"}},"session":{"user":{"id":"lo_c503b509ebdb"},"xsrf":"","isSpoofed":false},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da","host":"towardsdatascience.com","hostname":"towardsdatascience.com","susiModal":{"step":null,"operation":"register"},"postRead":false},"client":{"isBot":false,"isEu":true,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"inAppBrowserName":"","routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"supportsWebp":false},"multiVote":{"clapsPerPost":{}},"tracing":{}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","variantFlags":[{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"assign_default_topic_to_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"bane_add_user","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"bane_verify_domain","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"branch_seo_metadata","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"default_seo_post_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_android_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_resume_reading_toast","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_ios_subscription_activity_carousel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_mobile_featured_chunk","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_post_recommended_from_friends_provider","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_about_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_add_membership_lock","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_admin_mark_as_paid","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_local_currency","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_crossgrading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_renewal_failure","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook_renewal_status","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_about_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_general_admission","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profile_about_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profile_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_profiles_for_all","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_tag_page_routing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_forfeit_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automated_mission_control_triggers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_avatar_component_in_newsletterv3_settings_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_text_me_the_app","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branding_fonts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cleansweep_double_writes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_confirm_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creators_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cta_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_curation_priority_queue_experiment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_dedicated_series_tab_api_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_detailed_billing_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_different_grid","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_feature_logging","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_disregard_trunc_state_for_footer","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_earn_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_edit_alt_text","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_address_sharing_setting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_embedding_based_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_end_of_post_cleanup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_evhead_com_to_ev_medium_com_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_expanded_feature_chunk_pool","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_by_resend_rules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_filter_expire_processor","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_first_name_on_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_free_corona_topic","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_global_susi_modal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_highlander_member_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import_export_newsletter_audience","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_post_stats","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_janky_spam_rules","valueType":{"__typename":"VariantFlagString","value":"users,posts"}},{"__typename":"VariantFlag","name":"enable_json_logs_trained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_app_highlights","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_kbfd_rex_daily_digest","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_about_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_lo_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_notifications","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pay_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_cd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_highlights","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_post_highlights_view_only","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_profile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pub_header_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_pub_homepage_for_selected_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_stories","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_topics","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_unread_notification_count_mutation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lo_open_in_app","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_login_code_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_media_resource_try_catch","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_membership_redirect","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_membership_remove_section_a","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_meta_header_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_miro_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_more_on_coronavirus","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mute","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_collaborative_filtering_data","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_suspended_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_three_dot_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_new_user_onboarding_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_open_in_app_regwall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_optimizely","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_parsely","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_patronus_on_kubernetes","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_popularity_feature","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_page_nav_stickiness_removal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_seo_settings_screen","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_settings_screen","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_post_table_of_contents","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_primary_topic_for_mobile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_page_seo_titles","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_profile_subdomains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_all","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_edit_and_delete","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_responses_moderation","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rtr_channel","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_save_to_medium","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sohne","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace_ranker_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipalti_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_topic_lifecycle_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trending_posts_diversification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trial_upsell","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_trumpland_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_unbound","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"filter_stripe_invoice_line_items","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_embed_commands","valueType":{"__typename":"VariantFlagString","value":"control"}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound"}},{"__typename":"VariantFlag","name":"google_sign_in_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_generic_home_modules","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_iceland_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_pub_follow_email_opt_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"is_not_medium_subscriber","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_fastrak","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"kill_stripe_express","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"make_nav_sticky","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"new_transition_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"pub_sidebar","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"remove_post_post_similarity","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"retrained_ranker","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"sign_up_with_email_button","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"use_new_admin_topic_backend","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"vote_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"xgboost_auto_suspend","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"meterPost({\"postId\":\"268974d905da\",\"postMeteringOptions\":{}})":{"__ref":"MeteringInfo:{}"},"postResult({\"id\":\"268974d905da\"})":{"__ref":"Post:268974d905da"},"viewer":null},"MeteringInfo:{}":{"__typename":"MeteringInfo","postIds":["268974d905da"],"maxUnlockCount":3,"unlocksRemaining":2},"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png":{"id":"1*ChFMdf--f5jbm-AYv6VdYA@2x.png","__typename":"ImageMetadata"},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","__typename":"ImageMetadata","originalWidth":337,"originalHeight":122},"User:895063a310f4":{"id":"895063a310f4","__typename":"User"},"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png":{"id":"1*hVxgUA6kP-PgL5TJjuyePg.png","__typename":"ImageMetadata"},"NewsletterV3:d6fe9076899":{"id":"d6fe9076899","__typename":"NewsletterV3","slug":"the-daily-pick","isSubscribed":false,"showPromo":true,"name":"The Daily Pick","description":"Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.","collection":{"__ref":"Collection:7f60cf5620c9"}},"Collection:7f60cf5620c9":{"id":"7f60cf5620c9","__typename":"Collection","domain":"towardsdatascience.com","googleAnalyticsId":null,"slug":"towards-data-science","colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","isAuroraVisible":false,"favicon":{"__ref":"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png"},"name":"Towards Data Science","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"customStyleSheet":null,"description":"A Medium publication sharing concepts, ideas, and codes.","shortDescription":"A Medium publication sharing concepts, ideas, and codes.","tagline":"A Medium publication sharing concepts, ideas, and codes.","isAuroraEligible":true,"viewerIsEditor":false,"logo":{"__ref":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"},"navItems":[{"__typename":"NavItem","title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Video","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fvideo\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"★","url":"https:\u002F\u002Ftowardsdatascience.com\u002Feditors-picks\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"About","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fabout-us\u002Fhome","type":"TOPIC_PAGE"},{"__typename":"NavItem","title":"Contribute","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome","type":"EXTERNAL_LINK_NAV_ITEM"}],"creator":{"__ref":"User:895063a310f4"},"subscriberCount":486237,"avatar":{"__ref":"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png"},"isEnrolledInHightower":false,"newsletterV3":{"__ref":"NewsletterV3:d6fe9076899"},"viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"canToggleEmail":true,"isUserSubscribedToCollectionEmails":false,"viewerIsMuting":false,"viewerCanEditOwnPosts":false,"viewerCanEditPosts":false,"ampEnabled":false,"twitterUsername":"TDataScience","facebookPageId":null},"User:151fca431deb":{"id":"151fca431deb","__typename":"User","isSuspended":false,"name":"Adrien Biarnes","username":"biarnes.adrien","bio":"I am data scientist \u002F machine learning engineer. I love to learn and share my passion for data science — https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fadrien-biarnes-81975717","hasDomain":false,"customStyleSheet":null,"isAuroraVisible":true,"socialStats":{"__typename":"SocialStats","followerCount":38},"isBlocking":false,"imageId":"0*WCSvEV6fU3deUzGB.","mediumMemberAt":1574515247000,"isMuting":false,"isFollowing":false,"allowNotes":true,"twitterScreenName":"","isPartnerProgramEnrolled":false},"Paragraph:1730e030f188_0":{"id":"1730e030f188_0","__typename":"Paragraph","name":"b3ba","text":"Multinomial Mixture Model for Supermarket Shoppers Segmentation","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_1":{"id":"1730e030f188_1","__typename":"Paragraph","name":"5d70","text":"A complete tutorial","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_2":{"id":"1730e030f188_2","__typename":"Paragraph","name":"6abe","text":"Photo by Peter Bond on Unsplash","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:0*x_whGwu1M7rsjHAM"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":9,"end":19,"type":"A","href":"https:\u002F\u002Funsplash.com\u002F@pvsbond?utm_source=medium&utm_medium=referral","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":23,"end":31,"type":"A","href":"https:\u002F\u002Funsplash.com?utm_source=medium&utm_medium=referral","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_3":{"id":"1730e030f188_3","__typename":"Paragraph","name":"2482","text":"In my last article, I wrote a detailed explanation of the Gaussian Mixture Model (GMM) and the way it is trained using the Expectation-Maximization (EM) algorithm. This time, I wanted to show that a mixture model is not necessarily a mixture of Gaussian densities. It can be a mixture of any distribution. In this example, we are going to use a mixture of multinomial distributions.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":3,"end":18,"type":"A","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fgaussian-mixture-models-and-expectation-maximization-a-full-explanation-50fa94111ddd","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_4":{"id":"1730e030f188_4","__typename":"Paragraph","name":"d5d8","text":"Also, the idea is, for once, not to solely focus on the mathematical and computer science aspects of a data science project but on the business side too. Therefore we are going to use a real-world data set with a concrete application in the marketing domain. It will hopefully allow the reader to get a better vision of why we do the things we do :-). Additionally, we will introduce a bit of data visualization on the matter of picturing the multinomial distribution.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_5":{"id":"1730e030f188_5","__typename":"Paragraph","name":"6fc1","text":"This work has been majorly inspired by a research paper from Cadez et al. entitled “Predictive Profiles for Transaction Data using Finite Mixture Models”. A big part of the credit goes to them.","type":"BQ","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":84,"end":152,"type":"A","href":"http:\u002F\u002Fwww.datalab.uci.edu\u002Fpapers\u002Fprofiles.pdf","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":19,"end":35,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":84,"end":152,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_6":{"id":"1730e030f188_6","__typename":"Paragraph","name":"65a3","text":"Framing the business context","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_7":{"id":"1730e030f188_7","__typename":"Paragraph","name":"a0df","text":"In this era of supercomputers, machine learning, and data science, almost every business out there is collecting data about the different facets of its activities and try to use it for its own benefit. The food industry and in particular supermarkets are no exception to that rule. Supermarkets collect purchasing data or what is most commonly known as transaction data. It can be mined in order to extract insights and improve the efficiency of overall operations.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_8":{"id":"1730e030f188_8","__typename":"Paragraph","name":"000a","text":"One way to extract relevant patterns is to start by a clustering process. The idea is to group similar items together. It can be thought of as splitting the data set into clusters in such a way that data points inside a cluster have high similarity and points outside that cluster a low similarity.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_9":{"id":"1730e030f188_9","__typename":"Paragraph","name":"d53b","text":"In traditional marketing applications, the most important usage of such a clustering procedure is exploratory data analysis. We want to split the observations into a small number of clusters in order to better describe, interpret, and study them independently. The common usage is to proceed with customer segmentation. Each segment will have its own set of characteristics. For example, an output segment, for an online e-commerce website, could be described as “price-sensitive customers under 30, engaged primarily through digital channels”. Such projects are among the most frequently performed in marketing analytics because of their strategic importance. It allows building corporate marketing strategies around customer segments and their typical needs and properties.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":464,"end":543,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_10":{"id":"1730e030f188_10","__typename":"Paragraph","name":"10d1","text":"The goal of this project is to perform the clustering of a supermarket transaction data set in order to build predictive profiles of individuals. Such profiles support many different types of further analysis. Among them we find building customer segments for targeted marketing strategies, extracting somewhat hidden product associations, forecasting individual purchasing behaviors, change detection, cross-selling, personalization, and more…","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_11":{"id":"1730e030f188_11","__typename":"Paragraph","name":"990c","text":"In this article, we are going to:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_12":{"id":"1730e030f188_12","__typename":"Paragraph","name":"f835","text":"Quickly explore the data set","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_13":{"id":"1730e030f188_13","__typename":"Paragraph","name":"2b02","text":"Explain the modelization using a mixture of multinomial random variables","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_14":{"id":"1730e030f188_14","__typename":"Paragraph","name":"efe2","text":"Derive the mathematical update rules for the Expectation-Maximization","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_15":{"id":"1730e030f188_15","__typename":"Paragraph","name":"bebf","text":"Describe the way to select the optimal number of clusters","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_16":{"id":"1730e030f188_16","__typename":"Paragraph","name":"c65b","text":"Implement everything in plain Python","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_17":{"id":"1730e030f188_17","__typename":"Paragraph","name":"6f13","text":"Analyze the results and derive some insights","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_18":{"id":"1730e030f188_18","__typename":"Paragraph","name":"db20","text":"Explore a second formulation of the problem to better characterize individuals","type":"OLI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_19":{"id":"1730e030f188_19","__typename":"Paragraph","name":"3a33","text":"Dataset exploration","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_20":{"id":"1730e030f188_20","__typename":"Paragraph","name":"4ca5","text":"The dataset for this project was found on Kaggle: “Dunnhumby — The Complete Journey”. Quoting Kaggle, it: “contains household level transactions over two years from a group of 2,500 households who are frequent shoppers at a retailer. For certain households, demographic information, as well as direct marketing contact history, are included”.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":51,"end":83,"type":"A","href":"https:\u002F\u002Fwww.kaggle.com\u002Ffrtgnn\u002Fdunnhumby-the-complete-journey","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":107,"end":342,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_21":{"id":"1730e030f188_21","__typename":"Paragraph","name":"3caf","text":"In this work, we are going to focus on the transaction data and the associated products. So let's see what the first few transactions look like:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_22":{"id":"1730e030f188_22","__typename":"Paragraph","name":"cfbf","text":"Image by author","type":"IMG","href":null,"layout":"FULL_WIDTH","metadata":{"__ref":"ImageMetadata:1*KuxiYUlTWosoktgnntET8g.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_23":{"id":"1730e030f188_23","__typename":"Paragraph","name":"a22d","text":"Every line corresponds to a certain quantity of a product being bought in a specific basket (one basket corresponds to one specific checkout) by a given household. This dataset contains 2595732 transactions made among 276484 baskets. The transactions were performed by 2500 households for 92339 different products in 44 department stores among 308 categories and 2383 subcategories.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_24":{"id":"1730e030f188_24","__typename":"Paragraph","name":"b819","text":"There is a lot of useful information but we are not interested in using everything. This exercise is about the unsupervised clustering of the transaction data set using a multinomial mixture model. As we will see, multinomial mixture models are to be used with categorical data only. Therefore, we will not consider continuously valued predictors like price or retail discount.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":214,"end":283,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_25":{"id":"1730e030f188_25","__typename":"Paragraph","name":"e112","text":"Now in order to understand the data selection and preparation process that we are about to perform, we need to make sure that you properly understand the multinomial distribution (if you are already well versed with the multinomial, you can skip this section).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_26":{"id":"1730e030f188_26","__typename":"Paragraph","name":"6611","text":"Disgression on the multinomial distribution","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_27":{"id":"1730e030f188_27","__typename":"Paragraph","name":"0fc9","text":"The Multinomial distribution is a generalization of the Binomial distribution which itself is a generalization of the Bernoulli distribution. So let's start with the Bernoulli.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":4,"end":28,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FMultinomial_distribution","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":56,"end":77,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FBinomial_distribution","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":118,"end":140,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FBernoulli_distribution","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_28":{"id":"1730e030f188_28","__typename":"Paragraph","name":"7b75","text":"A Bernoulli random variable X depicts the result of a single trial with 2 possible outcomes, 1 or 0, with respective probabilities θ and 1-θ.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_29":{"id":"1730e030f188_29","__typename":"Paragraph","name":"d7c3","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*2y0kEIeo48sps6uL3m15eQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_30":{"id":"1730e030f188_30","__typename":"Paragraph","name":"8426","text":"For example, we could picture the probability mass function of Ber(0.3):","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_31":{"id":"1730e030f188_31","__typename":"Paragraph","name":"38bf","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*6iWUsgm_BWrfj20hI3Uz5A.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_32":{"id":"1730e030f188_32","__typename":"Paragraph","name":"b037","text":"In the frequentist perspective, the true value of a parameter is obtained by measuring the statistics of interest over an infinite number of experiments. In the case of the Bernoulli trial, if we repeat our single experiment an infinite number of times, record the results and average the number of positive outcomes we get the true parameter value of θ (in the above example, we get a positive result 30% of the time).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_33":{"id":"1730e030f188_33","__typename":"Paragraph","name":"59ee","text":"Now, what if we want to count the number of positive results for not only a single Bernoulli trial but a series of n Bernoulli trials. That is the purpose of a Binomial trial. For example, flipping a coin 10 times, we want to measure the number of times that the coin landed on heads. This time, the output of the Binomial trial can be any discrete value between 0 and 10. The exact formulation of the probability mass function is :","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_34":{"id":"1730e030f188_34","__typename":"Paragraph","name":"e178","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*9N1RaeMdYsT91AgdXPfqlQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_35":{"id":"1730e030f188_35","__typename":"Paragraph","name":"d235","text":"Let us see how we can derive this formula from the Bernoulli distribution. So let's say for simplicity that we want to record the number of heads that we get out of two coin flips (i.e. two Bernoulli trials). What are the possibilities:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_36":{"id":"1730e030f188_36","__typename":"Paragraph","name":"263d","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*4L76qbU59z2qJ_607qCBGw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_37":{"id":"1730e030f188_37","__typename":"Paragraph","name":"0b39","text":"From this enumeration, we get :","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_38":{"id":"1730e030f188_38","__typename":"Paragraph","name":"4d5e","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*1j9610jkD--nOdPg-CMEmg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_39":{"id":"1730e030f188_39","__typename":"Paragraph","name":"90d1","text":"The binomial coefficient in the formula captures the fact that there are different ways of distributing k successes in a sequence of n trials. In the example above, there are 2 ways of distributing 1 success among 2 trials. If we increase the number of trials, the number of possible ways to obtain central values increases much more rapidly than the number of possible ways to get extreme values. That is why the distribution gets a nice bell shape.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":104,"end":105,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":133,"end":134,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_40":{"id":"1730e030f188_40","__typename":"Paragraph","name":"728c","text":"So the probability mass function can be pictured with the following bar chart in the case of a Binomial trial with 20 independent Bernoulli trials of probability θ = 0.3:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_41":{"id":"1730e030f188_41","__typename":"Paragraph","name":"6522","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*3fVmjweboJz_J83IeOfYPw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_42":{"id":"1730e030f188_42","__typename":"Paragraph","name":"c806","text":"The most probable number of positive outcomes for a Binomial trial with 20 independent Bernoulli trials of probability 0.3 is 6. That is the mode of the above distribution.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_43":{"id":"1730e030f188_43","__typename":"Paragraph","name":"d850","text":"Now how can we generalize this distribution one step further? Well, what if we consider a series of n trials but this time with more than two possible outcomes… For example, we have a bag with 3 different types of balls (blue, red, and yellow) and we want to measure for each color the number of balls that we get out of 2 draws (with replacement). Let's enumerate the possibilities:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_44":{"id":"1730e030f188_44","__typename":"Paragraph","name":"486b","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*Hz8XBML7kezZVrSCjV6TYA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_45":{"id":"1730e030f188_45","__typename":"Paragraph","name":"7072","text":"From this enumeration, and given that we have at our disposal the proportions of blue, red, and yellow balls, respectively θ_1, θ_2 and θ_3, we can measure the probabilities :","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_46":{"id":"1730e030f188_46","__typename":"Paragraph","name":"3855","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*SVJINzR9W-ggnw09N8DemA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_47":{"id":"1730e030f188_47","__typename":"Paragraph","name":"66f1","text":"And we can continue on, but I hope that you understand how we can derive the analytical formula for the probability mass function of the multinomial:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_48":{"id":"1730e030f188_48","__typename":"Paragraph","name":"f9ed","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*Dyv6JYH-mI29VlqD_bcDkg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_49":{"id":"1730e030f188_49","__typename":"Paragraph","name":"460c","text":"On the visualization of the Multinomial","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_50":{"id":"1730e030f188_50","__typename":"Paragraph","name":"95ac","text":"Ok, so now, what if we want to draw the probability mass function using some sort of bar plot as we did above? Well, this time is going to be a little trickier.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_51":{"id":"1730e030f188_51","__typename":"Paragraph","name":"efb1","text":"This is kind of a disgression but it is important that you understand this representation of the multinomial as we will use it later.","type":"BQ","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_52":{"id":"1730e030f188_52","__typename":"Paragraph","name":"bd6a","text":"In order to picture a distribution, we need a way to place the possible outcomes on the graph and, for each of them, be able to show their relative importance. That is the purpose of the bar plots we used for the Bernoulli and the Binomial distributions. On the x-axis, we put the ordered possible outcome values and on the y-axis the associated probabilities.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_53":{"id":"1730e030f188_53","__typename":"Paragraph","name":"ca3f","text":"Now, what about the multinomial? Well, the issue here is that we can no longer use a single random variable to depict the different possibilities. In the Bernoulli and the Binomial, we use a single random variable X to count the number of successes. We don’t use a second random variable for the number of failures because it is obviously deduced from X. But in the case of the Multinomial, we need to introduce at least C-1 random variables for C possible outcomes of the single trial. Note that in the general we even use C random variables (X_1, X_2, …, X_C) like in the formula above for the PMF because it is less cumbersome to write (even if the last random variable value can be deduced).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_54":{"id":"1730e030f188_54","__typename":"Paragraph","name":"8c0c","text":"We are only interested in picturing the distribution with at least 2 possible outcomes and more (otherwise we fall back to the Binomial). Let us consider the case of 3 possible outcomes first. As I said, we could use only two random variables X_1 and X_2 (X_3 can be deduced). We would then need 3 dimensions (for X_1, X_2, and the joint probability P(X_1, X_2)=P(X_1, X_2, X3)). Ok, we can use a 3-dimensional bar plot for that purpose:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_55":{"id":"1730e030f188_55","__typename":"Paragraph","name":"9b95","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*iIN4QSMr7wMlNXyBKSetjA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_56":{"id":"1730e030f188_56","__typename":"Paragraph","name":"9735","text":"Ok, so what is wrong with this visualization? Well, first of all, we don’t explicitly see the different values for X3. We can deduce them. For example, for the first bin with X1=0 and X2=0, we know that X3=20. But we don’t visualize it. Also, half of the dedicated space for this graph is useless. For example, when X2=20, we know for sure that X1 will never take any value other than 0. So the triangle for half of the bottom floor of this 3d histogram will never display any density because probabilities are null.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_57":{"id":"1730e030f188_57","__typename":"Paragraph","name":"ed63","text":"So how can do better? Well, first we can reduce the bottom floor of the histogram to a triangle and more precisely an equilateral triangle. We use an equilateral triangle so that the distances from the vertices to the barycenter are equal. The exact location of any point in this triangle determines the relative proportions of our 3 random variables. This is called a simplex and it is very useful to display a discrete probability vector of 3 values:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_58":{"id":"1730e030f188_58","__typename":"Paragraph","name":"549d","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*mOKMWpYOxa1WVAMjBTx9zQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_59":{"id":"1730e030f188_59","__typename":"Paragraph","name":"cc44","text":"Also, if we draw every parallel of the triangle sides, that is we discretize the entire triangle space, each intersection can be used to picture the relative proportions of a 3 valued tuple. In the example below, we picture the multinomial with 16 draws and 3 possible values with probabilities 0.25, 0.5, and 0.25:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_60":{"id":"1730e030f188_60","__typename":"Paragraph","name":"9215","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*e76ZuT_WZ5b7oii1Z6U2Hg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_61":{"id":"1730e030f188_61","__typename":"Paragraph","name":"2f9b","text":"Finally, and I will stop this disgression here, it is not possible to extend this logic to additional dimensions to picture multinomials with degrees higher than 3. For example, we could try with a square for dimension 4 but it won’t work because a point in the square is only at the crossroad of 2 lines and we need the crossroad of 4 lines for this location to be the container of the proportions of 4 valued tuples.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_62":{"id":"1730e030f188_62","__typename":"Paragraph","name":"8770","text":"Back to the data","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_63":{"id":"1730e030f188_63","__typename":"Paragraph","name":"94e0","text":"As I previously said, because we want to perform the clustering using a multinomial mixture model, we don’t consider the continuous variables. For the sake of this exercise, we are only going to consider the products, the households, and the baskets. So the columns to be considered are the following:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_64":{"id":"1730e030f188_64","__typename":"Paragraph","name":"6bdb","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*uiHRj_gyEjXt2gfe1IM_-A.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_65":{"id":"1730e030f188_65","__typename":"Paragraph","name":"b557","text":"There are 4 columns describing the product purchased in a specific transaction (PRODUCT_ID, DEPARTMENT, COMMODITY_DESC, and SUB_COMMODITY_DESC). We want to group the transactions and, for each group, count the number of products.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_66":{"id":"1730e030f188_66","__typename":"Paragraph","name":"a1af","text":"Model formulation","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_67":{"id":"1730e030f188_67","__typename":"Paragraph","name":"5b7b","text":"So why do we want to count the number of products? Well, this will allow us to apply the following general model:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_68":{"id":"1730e030f188_68","__typename":"Paragraph","name":"e6d4","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*BjKke6AR1e0GMboE7j_p9A.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_69":{"id":"1730e030f188_69","__typename":"Paragraph","name":"05e4","text":"This represents the joint probability of observing the full data set. It is the product of individual probabilities (because the observations are collected i.i.d). The probability of observing an observation x_i is a mixture of multinomial distributions. X represents a matrix of counts for the products that were bought. Each line of the matrix, x_i, corresponds to a specific basket (i.e. one shopper checking out from the supermarket). Each multinomial distribution represents the probability of obtaining the counts that we see in a specific basket given that it was generated by a specific cluster k:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_70":{"id":"1730e030f188_70","__typename":"Paragraph","name":"e55c","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*r_UDMlVDjs1mhmirQKzVww.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_71":{"id":"1730e030f188_71","__typename":"Paragraph","name":"5956","text":"In the above formula, n_i represents the total number of products bought in a given basket. C represents the total number of different products so there is one parameter β_kc by multinomial k and product c. This means that β is a matrix of parameters of dimension k times c and β_k a vector of dimension c. n_ic represents the count of a specific product c bought in a given basket i.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_72":{"id":"1730e030f188_72","__typename":"Paragraph","name":"dbd6","text":"Our model uses a mixture of multinomial distributions. It basically makes the assumption that there exists K clusters. It means that the probabilities of items being bought in any given basket are a combination of K typical baskets. The goal of this project is to extract those typical baskets.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_73":{"id":"1730e030f188_73","__typename":"Paragraph","name":"0f6e","text":"Back to the data","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_74":{"id":"1730e030f188_74","__typename":"Paragraph","name":"2b55","text":"So we need to group the transactions by baskets, and for every basket, count the number of distinct products. But as we just saw, the number of parameters that we will use for this model highly depends on the number of distinct products. The more products we have, the higher the number of parameters. This means that if we have too many products, we might run into troubles during the optimization procedure to find the optimal values for the parameters or the number of clusters. But we are not obliged to count by distinct products (there are 92339 of them). We can count by the department stores (44), the category (308), or the sub-category (2383). This choice will determine the number C in the above formula.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_75":{"id":"1730e030f188_75","__typename":"Paragraph","name":"46b9","text":"Obviously, the ideal scenario would be to model the data all the way down to the product level. And in fact, I have tried to do so, and I ran short of memory on my laptop. Not to mention that with so many different components for the multinomial, the problems we might face to select the correct number of clusters are considerably increased (as we will see later). So, to make the distinction between products, we have to choose between the department store, the category, and the sub-category. Let’s see the repartitions of the number of transaction for each department:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_76":{"id":"1730e030f188_76","__typename":"Paragraph","name":"df88","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*aVL6ZAyu5Sz8na5Ih_j9Xw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_77":{"id":"1730e030f188_77","__typename":"Paragraph","name":"8e0c","text":"So as we can see, the vast majority of the transactions were made in the grocery department. Because this is an exercise, I decide not to bother with the transactions outside the grocery department. Now let’s see how the transactions from the grocery store are spread among categories:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_78":{"id":"1730e030f188_78","__typename":"Paragraph","name":"6cc1","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*9bK3_8ze-b9VlnYOG_gDLg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_79":{"id":"1730e030f188_79","__typename":"Paragraph","name":"f4f6","text":"Image by author","type":"IMG","href":null,"layout":"FULL_WIDTH","metadata":{"__ref":"ImageMetadata:1*wuocbRF1SCcn4T9nWu1How.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_80":{"id":"1730e030f188_80","__typename":"Paragraph","name":"657d","text":"There are 94 categories and although the number of transactions among categories is not homogenous, the least provided category still has 51 transactions. Now let’s see what we have for the sub-categories:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_81":{"id":"1730e030f188_81","__typename":"Paragraph","name":"3c52","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*JuRaL9ctaDmtu2tp04z9Ow.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_82":{"id":"1730e030f188_82","__typename":"Paragraph","name":"bf5a","text":"Image by author","type":"IMG","href":null,"layout":"FULL_WIDTH","metadata":{"__ref":"ImageMetadata:1*zH_VMTYEkW4S4bQV8otJwQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_83":{"id":"1730e030f188_83","__typename":"Paragraph","name":"0781","text":"We have the same decreasing pattern. But now there are so many sub-categories that the ones with the least transactions only have 1 transaction. A single transaction is clearly not enough for the parameters to be accurately estimated.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_84":{"id":"1730e030f188_84","__typename":"Paragraph","name":"48df","text":"So, we are going to distinct the product by categories (and not sub-categories) and produce the matrix of counts X that we will use to resolve the clustering problem. Let’s see what the first 10 rows look like:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_85":{"id":"1730e030f188_85","__typename":"Paragraph","name":"bf11","text":"Image by author","type":"IMG","href":null,"layout":"FULL_WIDTH","metadata":{"__ref":"ImageMetadata:1*yAgm8mkXygh0xPOwn7ShIA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_86":{"id":"1730e030f188_86","__typename":"Paragraph","name":"b1e7","text":"As you can see, the matrix is very sparse. But this is not a problem for the multinomial mixture model.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_87":{"id":"1730e030f188_87","__typename":"Paragraph","name":"f17a","text":"Mathematical derivations","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_88":{"id":"1730e030f188_88","__typename":"Paragraph","name":"85bb","text":"So as we said, the full likelihood of observing the data set is defined by:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_89":{"id":"1730e030f188_89","__typename":"Paragraph","name":"05f7","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*8ZS-s3MtE65XRe4UR2rTbA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_90":{"id":"1730e030f188_90","__typename":"Paragraph","name":"1c31","text":"In order to understand this part, you need to be familiar with the Expectation-Maximization algorithm (if not, I highly encouraged you to read my article on the matter). With EM, we first need to define a latent variable t, that describes an observation by defining from which cluster it was generated.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":143,"end":153,"type":"A","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fgaussian-mixture-models-and-expectation-maximization-a-full-explanation-50fa94111ddd","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_91":{"id":"1730e030f188_91","__typename":"Paragraph","name":"d69c","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*7Q3Tp8kkfg4KFadz91ZCMg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_92":{"id":"1730e030f188_92","__typename":"Paragraph","name":"d93d","text":"The latent variable t_i defines by which cluster the observation x_i was generated. Also, a variational distribution q is used to describe the posterior distribution of the latent variable taking the range of possible values (from 1 to K). So we can write:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_93":{"id":"1730e030f188_93","__typename":"Paragraph","name":"03cf","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*6ROdmZrIrE555SpD9RbRFA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_94":{"id":"1730e030f188_94","__typename":"Paragraph","name":"0862","text":"Recall that the EM algorithm defines a lower bound for the log-likelihood:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_95":{"id":"1730e030f188_95","__typename":"Paragraph","name":"61fb","text":"","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*Ng1EmRt_d9C1V4vkFTAbPg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_96":{"id":"1730e030f188_96","__typename":"Paragraph","name":"9f76","text":"The EM algorithm proceeds with the two following steps alternatively until convergence:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_97":{"id":"1730e030f188_97","__typename":"Paragraph","name":"7bb3","text":"Expectation step:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":17,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":17,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_98":{"id":"1730e030f188_98","__typename":"Paragraph","name":"0d73","text":"We maximize the lower bound with respect to q to update the posterior distribution of the latent variables:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_99":{"id":"1730e030f188_99","__typename":"Paragraph","name":"f6b1","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*I9KcNU4MyBHA8I-mY37WSA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_100":{"id":"1730e030f188_100","__typename":"Paragraph","name":"973b","text":"As you can see, the form of the expectation step remains the same as in the case of a mixture of Gaussians, except that the likelihood of an observation given the cluster k, that is P(x_i | β_k), now has a multinomial density:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_101":{"id":"1730e030f188_101","__typename":"Paragraph","name":"dfa9","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*dEQwtsopQPMvOwWowZmkjw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_102":{"id":"1730e030f188_102","__typename":"Paragraph","name":"f8c5","text":"Maximization step:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":0,"end":18,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","start":0,"end":18,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_103":{"id":"1730e030f188_103","__typename":"Paragraph","name":"bf60","text":"We maximize the lower bound with respect to α and β. We try to solve the following optimization problem:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_104":{"id":"1730e030f188_104","__typename":"Paragraph","name":"8669","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*-4acIO34XcSMnAEaD57PBg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_105":{"id":"1730e030f188_105","__typename":"Paragraph","name":"db0d","text":"The lower bound is defined as:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_106":{"id":"1730e030f188_106","__typename":"Paragraph","name":"dd58","text":"","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*jM-bLyiuT9sPTldAv2Cdkg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_107":{"id":"1730e030f188_107","__typename":"Paragraph","name":"3fa5","text":"In order to resolve this optimization problem, we are going to set the partial derivatives to 0 and solve the equations. Notice that the second term in the subtraction above does not depend on α or β, so we can replace it with a constant. Also, we will make us of Lagrangian multipliers to get rid of the constraints. So we need to resolve the following system of equations:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":264,"end":286,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FLagrange_multiplier","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_108":{"id":"1730e030f188_108","__typename":"Paragraph","name":"142a","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*3e1Kujclq4go-NUPHLJggw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_109":{"id":"1730e030f188_109","__typename":"Paragraph","name":"c72f","text":"With :","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_110":{"id":"1730e030f188_110","__typename":"Paragraph","name":"6f18","text":"","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*HtSNcvLj1ZsE7vZBK-ywLQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_111":{"id":"1730e030f188_111","__typename":"Paragraph","name":"9aa6","text":"Let’s start with the multinomial parameters β_kc:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_112":{"id":"1730e030f188_112","__typename":"Paragraph","name":"61ab","text":"","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*pJJt_QfgW_TjgiQwgjEFRg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_113":{"id":"1730e030f188_113","__typename":"Paragraph","name":"cb30","text":"Now the mixture weights α_k:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_114":{"id":"1730e030f188_114","__typename":"Paragraph","name":"adf2","text":"","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*rfyc876v-QFXu1hwpdKQTw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_115":{"id":"1730e030f188_115","__typename":"Paragraph","name":"126c","text":"Ok, so we now have the update rules for the variational distribution during the E-step and for the parameters during the M-step. Let’s get to the concrete materials.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_116":{"id":"1730e030f188_116","__typename":"Paragraph","name":"850a","text":"Implementation","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_117":{"id":"1730e030f188_117","__typename":"Paragraph","name":"960e","text":"The expectation-maximization algorithm does not give us any guarantee of whether we will find the global maximum of the likelihood function on first run. In order to increase our chances, it is recommended to start the algorithm several times with different random initializations. Each time, we shall compare our maximum with the previous one and keep the parameters associated with the best loss. Let’s implement this routine:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_118":{"id":"1730e030f188_118","__typename":"Paragraph","name":"2c08","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:3f6cc7d3df30cdefef92c512b2b6a59d"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_119":{"id":"1730e030f188_119","__typename":"Paragraph","name":"3291","text":"So I created a class for this model that needs to be instantiated with the number of clusters that we want to try out. I also added some parameters:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_120":{"id":"1730e030f188_120","__typename":"Paragraph","name":"ce56","text":"rtol: will be used when comparing the current loss with the previous one to decide whether we should stop the algorithm (the improvement from one cycle to the next gets to small so there is no need to continue further)","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_121":{"id":"1730e030f188_121","__typename":"Paragraph","name":"fb72","text":"max_iter: in order to ensure that the algorithm does not run forever, we can tell it to stop after a certain number of iterations","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_122":{"id":"1730e030f188_122","__typename":"Paragraph","name":"7e16","text":"restarts: the number of times we want to restart the full EM procedure with a different initialization","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_123":{"id":"1730e030f188_123","__typename":"Paragraph","name":"8d3f","text":"Next, we need to implement the _train_once method that, as its name suggests, will run one full cycle of iterations for the EM algorithm.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":31,"end":42,"type":"EM","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_124":{"id":"1730e030f188_124","__typename":"Paragraph","name":"7fd3","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:6fdd37fa6e1a8c8def59f05f907f0904"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_125":{"id":"1730e030f188_125","__typename":"Paragraph","name":"455a","text":"The shape of the algorithm is no big surprise. We start by initializing the parameters randomly. We iterate up to max_iter iterations and each time we alternate between the e-step to compute the posterior distributions of the latent variable t (gamma) and the m-step to update the parameters of the mixture (alpha and beta).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_126":{"id":"1730e030f188_126","__typename":"Paragraph","name":"8327","text":"Notice that the beta parameters are initialized using the Dirichlet distribution which is conjugate to the multinomial distribution. I won’t get into the details here but you just need to know that the Dirichlet will produce a set of parameters that sum up to 1 (for every cluster) as required.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":58,"end":80,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FDirichlet_distribution","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_127":{"id":"1730e030f188_127","__typename":"Paragraph","name":"687c","text":"Now there is also one thing that we did not talk about yet. It is the loss. Remember that at each iteration the EM algorithm is trying to maximize the lower bound. So the loss function that we will use track the convergence of the algorithm is the lower bound:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_128":{"id":"1730e030f188_128","__typename":"Paragraph","name":"8c18","text":"","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*jM-bLyiuT9sPTldAv2Cdkg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_129":{"id":"1730e030f188_129","__typename":"Paragraph","name":"4fa2","text":"This gives us the following implementation:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_130":{"id":"1730e030f188_130","__typename":"Paragraph","name":"9d82","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:5a98cf6bf4f43ef39ec9ccbe343ed1c7"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_131":{"id":"1730e030f188_131","__typename":"Paragraph","name":"372a","text":"Notice that the computation is not fully vectorized. We still iterate through the different K clusters. This is because we use the implementation of the multinomial from scipy.stats. This implementation accepts a matrix of observations for the counts but not for the parameters. So you can compute the multinomial probabilities for all the observations but only for a specific cluster and not all of them at once.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_132":{"id":"1730e030f188_132","__typename":"Paragraph","name":"24fd","text":"Now the e-step:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_133":{"id":"1730e030f188_133","__typename":"Paragraph","name":"0eab","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:6298f6ad491788bc853498dc6769a678"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_134":{"id":"1730e030f188_134","__typename":"Paragraph","name":"d6f6","text":"So this is just the vectorized implementation of the update rule we derived mathematically in the previous section. One thing to notice though is that when computing the multinomial probabilities of observing the count vectors (i.e. the likelihood), the probabilities are sometimes so close to 0 that we get numerical underflows and values are floored to 0. This is no good because we have to normalize the values to get back the posterior probabilities. In order to avoid division by 0, we replace the null values with the minimal floating-point value allowed in Python.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_135":{"id":"1730e030f188_135","__typename":"Paragraph","name":"09d6","text":"Now the m-step:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_136":{"id":"1730e030f188_136","__typename":"Paragraph","name":"e636","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:0615710f8cabb6398c9e04d420f9f4a3"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_137":{"id":"1730e030f188_137","__typename":"Paragraph","name":"383d","text":"No big surprise. Those are vectorized implementation of the update rules we derived mathematically.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_138":{"id":"1730e030f188_138","__typename":"Paragraph","name":"951e","text":"Runs on a simulated dataset","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_139":{"id":"1730e030f188_139","__typename":"Paragraph","name":"0d6f","text":"We are going to run the algorithm and see how it performs for various values ok K. A nice thing to do is first to use a simulated data set so that we control the data generation process. We can then see how the algorithm performs when we modify the true values for the parameters (i.e. the number of clusters, the mixture weights, the multinomial parameters, and the size of the dataset). The data set is generated with the following routine:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_140":{"id":"1730e030f188_140","__typename":"Paragraph","name":"a9cf","text":"","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"hasDropCap":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:7c76fd2c8cab46d9073b61667181ac79"}},"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_141":{"id":"1730e030f188_141","__typename":"Paragraph","name":"1349","text":"So we are first going to perform a simple test. The data set is generated as a mixture of 10000 observations coming from 3 very well separated multinomials that can take up to 16 different values. Also, we split the generated data set into 80 % for training and 20 % for testing. Then we compute the likelihood on the test data:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_142":{"id":"1730e030f188_142","__typename":"Paragraph","name":"1ef0","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*0ievWD0wxc_b3JMQMjfiYg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_143":{"id":"1730e030f188_143","__typename":"Paragraph","name":"e553","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*X4CdRc1i5NptX-wm-8VMEw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_144":{"id":"1730e030f188_144","__typename":"Paragraph","name":"916c","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*9AQTAvJLmVA6vD3V696xeQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_145":{"id":"1730e030f188_145","__typename":"Paragraph","name":"9f01","text":"As we can see, the estimated parameters are very close to real ones. Also, now we see the value of our work regarding the visualization of the multinomial. It is very apparent, from the above plot, that the clusters are very well separated. So the algorithm should clearly have no problem in estimating the true number of clusters. And if we look at the likelihood evolution when we increase the number of clusters, we can clearly see the elbow pattern. When we go from 2 clusters to 3, the fit is much more likely. But as soon as we reach 3 clusters, the likelihood hits a plateau. This clearly suggests that the best number of clusters is 3. Why? Well, because when we increase the number of clusters, we increase the complexity of the model with no additional benefits on the likelihood.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":439,"end":452,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FElbow_method_(clustering)","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_146":{"id":"1730e030f188_146","__typename":"Paragraph","name":"66ed","text":"Now what happens when we modify the mixture weights:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_147":{"id":"1730e030f188_147","__typename":"Paragraph","name":"9d03","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*NeD3pmWGI8K40XU8ea94Vw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_148":{"id":"1730e030f188_148","__typename":"Paragraph","name":"5f58","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*k7rZdMsG5KSwy9vyg2yOzQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_149":{"id":"1730e030f188_149","__typename":"Paragraph","name":"2df9","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*qCKPXPIzeYf0pZXsSJscqQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_150":{"id":"1730e030f188_150","__typename":"Paragraph","name":"fa1d","text":"Once again, the mixture weights are very well estimated which confirms the update rules are correct.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_151":{"id":"1730e030f188_151","__typename":"Paragraph","name":"7ab9","text":"Now, what happens when the clusters are not very well separated? Let’s see:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_152":{"id":"1730e030f188_152","__typename":"Paragraph","name":"7c39","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ANHVk81RIsUgJKmlPmTlBg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_153":{"id":"1730e030f188_153","__typename":"Paragraph","name":"737d","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*iIJ2D17afFbAMf0nN_7G9Q.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_154":{"id":"1730e030f188_154","__typename":"Paragraph","name":"6c0f","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ftkh7KPq6ZmqTEU42iswvQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_155":{"id":"1730e030f188_155","__typename":"Paragraph","name":"4e12","text":"Ok so this time, the mixture weights are a bit less correctly inferred. The multinomial component weights are better though. Also, we still see an elbow pattern in the likelihood values, but they are a bit more noisily distributed. From the distribution of the likelihoods, we can clearly see that the jump from 2 to 3 clusters is the one that gets out the most value in terms of goodness of fit. So we still choose 3 clusters.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_156":{"id":"1730e030f188_156","__typename":"Paragraph","name":"dcb4","text":"Now, what if we pack the parameter space even more with 10 different multinomials?","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_157":{"id":"1730e030f188_157","__typename":"Paragraph","name":"5314","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*3YFJ9xogkbMG32jeS2gGnw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_158":{"id":"1730e030f188_158","__typename":"Paragraph","name":"acaf","text":"Ok so this time, selecting the best number of clusters based solely on the improvement on the likelihood is much more tricky. It might be 3 clusters or maybe 7… which clearly is not right. Ok, so how can we do better? Well, we are going to use another selection criterion. It is called the Bayesian Information Criterion (or BIC in short). It is computed with the following formula:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":290,"end":320,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FBayesian_information_criterion","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_159":{"id":"1730e030f188_159","__typename":"Paragraph","name":"7126","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*LSdF8y3iwM_wCyYt4YnEOw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_160":{"id":"1730e030f188_160","__typename":"Paragraph","name":"5678","text":"D represents the number of parameters to be estimated by the model, N the total number of observations, and L_hat the likelihood of the model. It introduces a penalty proportional to the number of observations and the number of parameters. What we want to do is minimize the BIC value, so that the likelihood is maximized but at the same time keeping the number of parameters as low as possible. In the case of the mixture of multinomials, with K multinomials of C components, D, the number of parameters, is equal to (K-1)+K*(C-1). Knowing that the mixture weights and the component weights both sum up to 1, we can deduce the last parameters.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_161":{"id":"1730e030f188_161","__typename":"Paragraph","name":"aff3","text":"Applying this new selection criterion to the generated data set with 10 multinomials, we get:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_162":{"id":"1730e030f188_162","__typename":"Paragraph","name":"5bf7","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*h0_SR1oMDYwMKPEaCeeXoQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_163":{"id":"1730e030f188_163","__typename":"Paragraph","name":"1bef","text":"The optimal number of 10 clusters is correctly selected by the BIC criterion. But we see that it was a very close match. And in fact, running the same procedure again, we might get a different number of clusters. It shows that selecting the correct number is very hard and there is no silver bullet. In the end, nothing beats the judgment call of the business analyst. So it is a good thing to review the clusters and try to see if some of them should be merged (because they are very closed to each other and have very similar properties).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_164":{"id":"1730e030f188_164","__typename":"Paragraph","name":"b93f","text":"Fitting on the grocery department store data set","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_165":{"id":"1730e030f188_165","__typename":"Paragraph","name":"4c42","text":"Ok so now we have the ingredients to perform the clustering of the grocery store transaction data set. Recall that we have prepared a matrix for the transaction counts of distinct product categories grouped by basket:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_166":{"id":"1730e030f188_166","__typename":"Paragraph","name":"c1c0","text":"Image by author","type":"IMG","href":null,"layout":"FULL_WIDTH","metadata":{"__ref":"ImageMetadata:1*yAgm8mkXygh0xPOwn7ShIA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_167":{"id":"1730e030f188_167","__typename":"Paragraph","name":"c052","text":"After splitting this matrix on a 80\u002F20 rule (ordered by basket transaction times), we fit the model to the training data and record the likelihood and BIC values on the test data for a set of possible cluster values from 2 to 100. We get the following result:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_168":{"id":"1730e030f188_168","__typename":"Paragraph","name":"11e9","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*DFLIs6R3NnOVSi78Jzc7HA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_169":{"id":"1730e030f188_169","__typename":"Paragraph","name":"a003","text":"From the above plot, we understand why with real-world data sets, selecting the optimal number of clusters based solely on the likelihood is not very reliable and why we need to penalize on the complexity of the model. And that comes from the fact that clusters are, most frequently, not very well separated. Using the Bayesian Information Criterion, we select 30 clusters.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_170":{"id":"1730e030f188_170","__typename":"Paragraph","name":"3dbc","text":"Results","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_171":{"id":"1730e030f188_171","__typename":"Paragraph","name":"09d2","text":"Clusters analysis","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_172":{"id":"1730e030f188_172","__typename":"Paragraph","name":"a1e6","text":"First of all, we can visualize the clusters in terms of probability distributions of product categories. We plot the 6 first clusters :","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_173":{"id":"1730e030f188_173","__typename":"Paragraph","name":"e6d3","text":"Image by author","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*znI_CjZ2QUgyMWrvq2Ax-g.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_174":{"id":"1730e030f188_174","__typename":"Paragraph","name":"e976","text":"What is important to understand is that the distributions above represent the typical baskets. They can help us with the forecast for product purchases.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_175":{"id":"1730e030f188_175","__typename":"Paragraph","name":"bc03","text":"Also, we can notice that some typical baskets are dominated by one or a low number of categories whereas some other typical baskets are made of a more diverse set of categories. This highlights shopping behaviors. Sometimes a person will make a quick visit to the store and buy the ingredients for a specific occasion (Saturday brunch, Sunday supper, a drink with friends,…) or it might be a longer visit for the weekly shopping.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_176":{"id":"1730e030f188_176","__typename":"Paragraph","name":"dd20","text":"Next, we would like to assess the clustering quality by visualizing their relative distances. Considering that there are 30 clusters, it is not evident to see that they are pretty well separated from one another. In order to visualize the distances between them, the ideal scenario would be to build up a 30-dimensional space in which we could place the observations. Of course, this not feasible so we are going to rely on a dimensionality reduction technique. The technique we use is called multidimensional scaling. Like the PCA, it relies on the eigendecomposition of the input matrix. But this time, the input matrix will be the pairwise distance matrix of the cluster parameters (using the Manhattan distance). We get the following result:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":493,"end":517,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FMultidimensional_scaling","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":696,"end":715,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FTaxicab_geometry","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_177":{"id":"1730e030f188_177","__typename":"Paragraph","name":"9ebc","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*gXShQC60jaZPXphKqFjfzA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_178":{"id":"1730e030f188_178","__typename":"Paragraph","name":"a663","text":"The cluster sizes are synchronized on the mixture weights which highlights their inequalities. Although some information is lost due to the dimensionality reduction technique, we can still conclude that the clusters are pretty well separated.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_179":{"id":"1730e030f188_179","__typename":"Paragraph","name":"eca1","text":"High lift items","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_180":{"id":"1730e030f188_180","__typename":"Paragraph","name":"5018","text":"A good way to describe the clusters is by computing the lift ratio for the highly bought individual products. The lift ratio for a product and a cluster is defined as the ratio between the purchase probability conditioned on a cluster over the total purchase probability. So first we need to compute the purchase probabilities of each individual products, which can be defined as:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_181":{"id":"1730e030f188_181","__typename":"Paragraph","name":"a779","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*qFx44mBDqEUmgBpGD3kJJA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_182":{"id":"1730e030f188_182","__typename":"Paragraph","name":"5f98","text":"It is the ratio between the total quantities for a specific product over the total quantities of all the products. It can be defined as the probability of finding a product in a basket randomly chosen among all the baskets of the data set. Let’s see the distribution of those probabilities for all the products:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_183":{"id":"1730e030f188_183","__typename":"Paragraph","name":"f598","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*otujZVICnoFx2gI1JNjDtg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_184":{"id":"1730e030f188_184","__typename":"Paragraph","name":"e71a","text":"As you can see, there is a high concentration of very low values. An also, a good proportion of probabilities are so low that their computation suffered from numerical underflow (which basically resulted in a 0 probability). We want to consider only items that are frequently bought because they are the most characteristics. So we will restrict this analysis to products with purchase probabilities higher than 0.0001 (2019 products).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_185":{"id":"1730e030f188_185","__typename":"Paragraph","name":"0263","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*uGFfYlNpqS_1pNYDvtTIMA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_186":{"id":"1730e030f188_186","__typename":"Paragraph","name":"8243","text":"Next, in order to compute the lift ratio, we need to compute the purchase probabilities of those items but for specific clusters. It means that we want to get the probabilities of finding a product in a basket randomly chosen among the baskets of a specific cluster k (and not among all the baskets):","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_187":{"id":"1730e030f188_187","__typename":"Paragraph","name":"3b5b","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*1drRDGZ6kMFqfEfKMeMtew.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_188":{"id":"1730e030f188_188","__typename":"Paragraph","name":"f17e","text":"The issue with this computation is that talking about the basket of a cluster is not, strictly speaking, correct. Indeed, with the current modelization, a basket belongs to several clusters at the same time. Remember that we are performing soft clustering as defined by the posterior probability distribution of the latent variable over the parameters, that is P(t_i|x_i,α,β). For example, let’s visualize the posterior distributions of the latent variable for the 6 first baskets:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":65,"end":67,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_189":{"id":"1730e030f188_189","__typename":"Paragraph","name":"bee7","text":"Image by author","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*V6uk8AfFggBvRQC6xwKUfw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_190":{"id":"1730e030f188_190","__typename":"Paragraph","name":"9ee9","text":"The goal of the clustering process is to extract the most typical baskets by grouping them together. Some baskets will be located at the core of a cluster (in assignments probability space). The distribution then exhibits a single high value for a specific cluster (like for the top left basket above). But some baskets will be located in regions where the assignments are a bit fuzzier. So in order to be accurate in the computation of purchase probabilities conditioned on a cluster, we are first going to distribute the counts of basket products among the different clusters. So we compute a new floating-points matrix of size N times K times C with the following rules:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_191":{"id":"1730e030f188_191","__typename":"Paragraph","name":"ac46","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*-LMoVrAevErSe74z7VdOyw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_192":{"id":"1730e030f188_192","__typename":"Paragraph","name":"e581","text":"Finally, we can compute the lift ratio which is:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_193":{"id":"1730e030f188_193","__typename":"Paragraph","name":"768d","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*tyumD7G7rDOxLscRyXAGuA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_194":{"id":"1730e030f188_194","__typename":"Paragraph","name":"8ea1","text":"Showing the items with a lift ratio greater than 10, we can start to describe the clusters with specific products. For example, the high lift items for the first cluster are the following:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_195":{"id":"1730e030f188_195","__typename":"Paragraph","name":"e058","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*5LXPWsJCbYAKlt5X8Fe8ow.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_196":{"id":"1730e030f188_196","__typename":"Paragraph","name":"692a","text":"The items with the highest lift of the first cluster are canned beans and tomatoes.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_197":{"id":"1730e030f188_197","__typename":"Paragraph","name":"f7b4","text":"Also, in order to describe the clusters a bit more visually, we can make word clouds based on the categories of high lift items (taking into account purchase frequencies too). Let’s see what we get for the 6 first clusters:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_198":{"id":"1730e030f188_198","__typename":"Paragraph","name":"248a","text":"Image by author","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*Ur17gnm5gLR_UXVr7RNkcA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_199":{"id":"1730e030f188_199","__typename":"Paragraph","name":"ea20","text":"From the word clouds above we can describe the clusters. This first cluster is a good mix although the main topic is vegetables. The second and third clusters are dominated by bakery items, the fourth by products relating to dinner, the fifth by snacks, and the sixth by dairy products.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_200":{"id":"1730e030f188_200","__typename":"Paragraph","name":"bb45","text":"Products associations","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_201":{"id":"1730e030f188_201","__typename":"Paragraph","name":"4021","text":"Now the high lift items analysis can be pushed one step further by computing the high lift pairs of items. The computation of probabilities is the same except that this time we compute it for pairs of items. For example, one is 17.2 times more likely to find both “VARIETY BEANS — KIDNEY PINTO” and “TOMATO SAUCE” from a random basket of cluster 1 than from a general random basket.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_202":{"id":"1730e030f188_202","__typename":"Paragraph","name":"9660","text":"By first narrowing down the dataset to transactions from a specific cluster and then checking for purchase probabilities for pairs of products we enveil associations that would otherwise not be relevant!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_203":{"id":"1730e030f188_203","__typename":"Paragraph","name":"8d4b","text":"Individual predictive profiles","type":"H3","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_204":{"id":"1730e030f188_204","__typename":"Paragraph","name":"49dd","text":"So far, the model we have been working with describes the likelihood of an observation as a mixture of multinomial distributions:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_205":{"id":"1730e030f188_205","__typename":"Paragraph","name":"6bd0","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*YSh55lFuFEf0gPTWAEWjmg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_206":{"id":"1730e030f188_206","__typename":"Paragraph","name":"dc73","text":"The full data likelihood is written as:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_207":{"id":"1730e030f188_207","__typename":"Paragraph","name":"8da9","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*6UoHeOYd3AZi4sDjpoo_oA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_208":{"id":"1730e030f188_208","__typename":"Paragraph","name":"5023","text":"Now as I previously said, this model considers each basket independently and there is no distinction for the baskets of different individuals. We consider every individual in the same regard which means that they have the same predictive profile, resulting from the estimation of the model parameters. In our case, this gives us the following general profile (simulated by sampling):","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_209":{"id":"1730e030f188_209","__typename":"Paragraph","name":"13ce","text":"Image by author","type":"IMG","href":null,"layout":"OUTSET_CENTER","metadata":{"__ref":"ImageMetadata:1*v--WQdUV1T5lkEIA7nduRg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_210":{"id":"1730e030f188_210","__typename":"Paragraph","name":"765c","text":"This profile, is on average the one that describes with the better accuracy the purchase probabilities. Now it might suit some individuals pretty well, but in most cases, it makes a poor predictor. So how can we do better? Well, first of all we are going to introduce the distinction between the baskets of individuals by rewriting the full data likelihood:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_211":{"id":"1730e030f188_211","__typename":"Paragraph","name":"f4b0","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*xEmCBFXmKraDfyBYIhOvMQ.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_212":{"id":"1730e030f188_212","__typename":"Paragraph","name":"942e","text":"Now the index i, refers to a specific individual. The index j refers to the current basket for that individual (from 1 to the total number of baskets n_i). We didn’t change anything to the model. This model above is already what we have implemented. We just introduced the distinction between the baskets of individuals. Now remember that we are working with a latent variable model. Each instance of latent variable describes the probability that the basket j from individual i was generated by a cluster k. So instead of the likelihood, we could consider the classification likelihood which is the complete-data likelihood within the EM framework for mixture models:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_213":{"id":"1730e030f188_213","__typename":"Paragraph","name":"1617","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*xqg_YR66YOAc2iSxwfwDgg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_214":{"id":"1730e030f188_214","__typename":"Paragraph","name":"6352","text":"So for a specific individual, the complete-data likelihood is computed as:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_215":{"id":"1730e030f188_215","__typename":"Paragraph","name":"1ab8","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*CkTyI1pWbXQVdo4hTK6bAw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_216":{"id":"1730e030f188_216","__typename":"Paragraph","name":"2448","text":"Now, what we can do, is check this implementation for specific individuals by confronting their purchases from the test set and the predictions obtained by sampling from the predictive distribution above.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_217":{"id":"1730e030f188_217","__typename":"Paragraph","name":"5dba","text":"In order to build the predictive distribution for a given individual, we iterate through all baskets from the train set for that individual, for every basket, we iterate through every mixture component k and each time we sample from the corresponding multinomial. The sample is then weighted with the mixture weight and the latent probability of the observation belonging to the cluster. In the end, all the samples are summed up and we normalize by the total count to get back a proper probability distribution. Also, in order to score the prediction, we compute the L1-distance between the prediction and the normalized purchases counts from the test set. Here are a two examples:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_218":{"id":"1730e030f188_218","__typename":"Paragraph","name":"8183","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*cJemSVHEKwgsolEewhuM5g.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_219":{"id":"1730e030f188_219","__typename":"Paragraph","name":"9300","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*aNpWWUrHsR1PKi3Fb1p1Kw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_220":{"id":"1730e030f188_220","__typename":"Paragraph","name":"d2f5","text":"We can see that the result is not always as good for every individual. The prediction is obviously better for frequent shoppers than rare ones.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_221":{"id":"1730e030f188_221","__typename":"Paragraph","name":"53af","text":"Individual weights","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_222":{"id":"1730e030f188_222","__typename":"Paragraph","name":"080a","text":"Ok so is there a way to do even better? The answer is yes and to be found in the research paper that I mentioned at the beginning of this document: “Predictive Profiles for Transaction Data using Finite Mixture Models”.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":149,"end":217,"type":"A","href":"http:\u002F\u002Fwww.datalab.uci.edu\u002Fpapers\u002Fprofiles.pdf","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","start":149,"end":217,"type":"STRONG","href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_223":{"id":"1730e030f188_223","__typename":"Paragraph","name":"8c15","text":"The idea is to replace the global mixture weights by individualized ones. The full data likelihood then becomes:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_224":{"id":"1730e030f188_224","__typename":"Paragraph","name":"b7b1","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*R1RG3jt08tAT1wzm-w8pvg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_225":{"id":"1730e030f188_225","__typename":"Paragraph","name":"2800","text":"This time, I won’t get into the mathematical derivations of the update rules. The only thing you need to know is that they remain the same except for the update of the mixture weight during the m-step that becomes:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_226":{"id":"1730e030f188_226","__typename":"Paragraph","name":"56a2","text":"","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*KkO5iljTJfOAEBI8Y_U6Pw.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_227":{"id":"1730e030f188_227","__typename":"Paragraph","name":"c353","text":"If we compare with the previous update rule with the global model, the difference is that now we only use the posterior distribution of the latent variable for the baskets of the individual instead of all the baskets.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_228":{"id":"1730e030f188_228","__typename":"Paragraph","name":"e949","text":"After training of this model, we can compare the new training results (in terms of likelihood and BIC value) with previous ones:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_229":{"id":"1730e030f188_229","__typename":"Paragraph","name":"96b7","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*rxUwb6IusG9HXqLUEzQWvA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_230":{"id":"1730e030f188_230","__typename":"Paragraph","name":"db77","text":"We see that, with this new model, the likelihood on the test set is better for any number of clusters which means that the fit is more likely. The issue that we now have though is that the BIC criterion proposes to select only 2 clusters. That seems really inappropriate given the nature of the data. And this is where we touch the limits of the BIC criterion. In this modelization, we replaced the K global mixture weights by K times N individualized mixture weights. This means that the penalization of the number of parameters now weighs a lot more in the formula.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_231":{"id":"1730e030f188_231","__typename":"Paragraph","name":"8f3c","text":"There exists a vast quantity of different criterions for assessing the number of clusters to be selected. Here are the ones that I found:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_232":{"id":"1730e030f188_232","__typename":"Paragraph","name":"2c61","text":"Likelihood Ratio Test","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_233":{"id":"1730e030f188_233","__typename":"Paragraph","name":"2fc5","text":"Akaike’s Information Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_234":{"id":"1730e030f188_234","__typename":"Paragraph","name":"66ff","text":"Bootstrapped-Based Information Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_235":{"id":"1730e030f188_235","__typename":"Paragraph","name":"c13c","text":"Cross-Validation-Based Information Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_236":{"id":"1730e030f188_236","__typename":"Paragraph","name":"cf4b","text":"Minimum Information Ratio Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_237":{"id":"1730e030f188_237","__typename":"Paragraph","name":"b71b","text":"Informational Complexity Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_238":{"id":"1730e030f188_238","__typename":"Paragraph","name":"1a37","text":"Laplace’s Method of Approximation","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_239":{"id":"1730e030f188_239","__typename":"Paragraph","name":"3bcc","text":"Bayesian Information Criterion (the one that we used)","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_240":{"id":"1730e030f188_240","__typename":"Paragraph","name":"f75d","text":"Laplace-Metropolis Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_241":{"id":"1730e030f188_241","__typename":"Paragraph","name":"73dc","text":"Laplace-Empirical Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_242":{"id":"1730e030f188_242","__typename":"Paragraph","name":"4b17","text":"Reversible Jump Method","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_243":{"id":"1730e030f188_243","__typename":"Paragraph","name":"3f1e","text":"Miminimum Message Length Principle","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_244":{"id":"1730e030f188_244","__typename":"Paragraph","name":"4a23","text":"Classification Likelihood Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_245":{"id":"1730e030f188_245","__typename":"Paragraph","name":"e2d0","text":"Normalized Entropy Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_246":{"id":"1730e030f188_246","__typename":"Paragraph","name":"d70a","text":"Integrated Classification Criterion","type":"ULI","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_247":{"id":"1730e030f188_247","__typename":"Paragraph","name":"f7d7","text":"I am sure that there other criterions out there and it is still an active research subject. New ways of selecting the best number of clusters are still emerging. So we see the breadth and complexity of the subject. But as I previously said, nothing beats the judgment call of a domain expert.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_248":{"id":"1730e030f188_248","__typename":"Paragraph","name":"aec0","text":"Anyhow with this new modelization, we get the following results for the 2 individuals selected in the previous section:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_249":{"id":"1730e030f188_249","__typename":"Paragraph","name":"05fb","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*iPqLaNdgr-mLZmjRXTQhRg.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_250":{"id":"1730e030f188_250","__typename":"Paragraph","name":"0a42","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*DsUVBjPxelX47EEzZL7VQA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_251":{"id":"1730e030f188_251","__typename":"Paragraph","name":"7c3d","text":"We went from 1.625 to 1.564 in L1-distance for household 892 and from 0.647 to 0.530 for household 72. Now performing the same exercise for every household, we can record the obtained distances and confront them on a scatter plot:","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_252":{"id":"1730e030f188_252","__typename":"Paragraph","name":"d29e","text":"Image by author","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*VZyxi-Lujf_iUllFoBJdYA.png"},"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_253":{"id":"1730e030f188_253","__typename":"Paragraph","name":"3d95","text":"Every point below the diagonal corresponds to a household for which the prediction distance was smaller with the individualized model. It is not necessarily obvious from the above plot, but we performed a better prediction for 61.57% of the households.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_254":{"id":"1730e030f188_254","__typename":"Paragraph","name":"6fd7","text":"So in the end, we consider that the second modelization with individual mixture weights is a better model because it gives a better predictive performance on the test set. We just did not found, yet, a way to correctly assess the number of clusters (although I would probably select 30 clusters as we did with the global model) and I leave that as an exercise for the interested reader.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_255":{"id":"1730e030f188_255","__typename":"Paragraph","name":"36f6","text":"Regarding this last point, you can reproduce all the results using the code on my github (along with the notebooks for data exploration, model selection and results analysis) =\u003E https:\u002F\u002Fgithub.com\u002Fbiarne-a\u002FMNMM","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":178,"end":210,"type":"A","href":"https:\u002F\u002Fgithub.com\u002Fbiarne-a\u002FMNMM","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_256":{"id":"1730e030f188_256","__typename":"Paragraph","name":"57ce","text":"Final thoughts on the model","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_257":{"id":"1730e030f188_257","__typename":"Paragraph","name":"5d32","text":"This model allows to predicts which products an individual is likely to purchase, but not how many or when they will be purchased. The multinomial distribution gives counts of purchased items but requires the total number of purchased items in a basket as input. So ideally we would need another model to predict the total number of items an individual would purchase on a given day. Also in order to model the rate of visits to the store we could have used a Poisson process and we would have had to take care of seasonality patterns.","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":460,"end":475,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FPoisson_point_process","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_258":{"id":"1730e030f188_258","__typename":"Paragraph","name":"6cdd","text":"One important point is that in the paper that inspired this article, the authors use the EM algorithm to find the Maximum A Posteriori (MAP) estimates of the model parameters, whereas we found the MLE estimates. This is more in line with the Bayesian philosophy. It means that they declared priors on the parameters α and β of the model (both Dirchlet priors). This approach is better because it allows among other things to regularize the model. We can see it as, starting from plausible guesses for the parameters, we refine the values according to the amount of data we have at our disposal. For the individualized model we start with the global estimates of the model. If we don’t have much data about an individual, then its estimates will stay close to the global ones. I didn’t want to take this approach for the sake of this article because it would have complicated things even more (and I would also have had to introduce the Dirichlet distribution among other things).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[{"__typename":"Markup","start":114,"end":134,"type":"A","href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FMaximum_a_posteriori_estimation","anchorType":"LINK","userId":null,"linkMetadata":null}],"dropCapImage":null},"Paragraph:1730e030f188_259":{"id":"1730e030f188_259","__typename":"Paragraph","name":"da12","text":"Final words","type":"H4","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_260":{"id":"1730e030f188_260","__typename":"Paragraph","name":"3ed2","text":"This has been quite a journey! If you read up to this point, it probably means that you have found this interesting and maybe you learned a few things along the way (at least I hope).","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"Paragraph:1730e030f188_261":{"id":"1730e030f188_261","__typename":"Paragraph","name":"f5b2","text":"In any case, take care of your selves and loved ones!","type":"P","href":null,"layout":null,"metadata":null,"hasDropCap":null,"iframe":null,"mixtapeMetadata":null,"markups":[],"dropCapImage":null},"ImageMetadata:0*x_whGwu1M7rsjHAM":{"id":"0*x_whGwu1M7rsjHAM","__typename":"ImageMetadata","originalHeight":3131,"originalWidth":4696,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*KuxiYUlTWosoktgnntET8g.png":{"id":"1*KuxiYUlTWosoktgnntET8g.png","__typename":"ImageMetadata","originalHeight":174,"originalWidth":2234,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*2y0kEIeo48sps6uL3m15eQ.png":{"id":"1*2y0kEIeo48sps6uL3m15eQ.png","__typename":"ImageMetadata","originalHeight":52,"originalWidth":536,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*6iWUsgm_BWrfj20hI3Uz5A.png":{"id":"1*6iWUsgm_BWrfj20hI3Uz5A.png","__typename":"ImageMetadata","originalHeight":284,"originalWidth":393,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*9N1RaeMdYsT91AgdXPfqlQ.png":{"id":"1*9N1RaeMdYsT91AgdXPfqlQ.png","__typename":"ImageMetadata","originalHeight":148,"originalWidth":475,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*4L76qbU59z2qJ_607qCBGw.png":{"id":"1*4L76qbU59z2qJ_607qCBGw.png","__typename":"ImageMetadata","originalHeight":186,"originalWidth":475,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*1j9610jkD--nOdPg-CMEmg.png":{"id":"1*1j9610jkD--nOdPg-CMEmg.png","__typename":"ImageMetadata","originalHeight":432,"originalWidth":582,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*3fVmjweboJz_J83IeOfYPw.png":{"id":"1*3fVmjweboJz_J83IeOfYPw.png","__typename":"ImageMetadata","originalHeight":284,"originalWidth":407,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*Hz8XBML7kezZVrSCjV6TYA.png":{"id":"1*Hz8XBML7kezZVrSCjV6TYA.png","__typename":"ImageMetadata","originalHeight":364,"originalWidth":697,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*SVJINzR9W-ggnw09N8DemA.png":{"id":"1*SVJINzR9W-ggnw09N8DemA.png","__typename":"ImageMetadata","originalHeight":353,"originalWidth":725,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*Dyv6JYH-mI29VlqD_bcDkg.png":{"id":"1*Dyv6JYH-mI29VlqD_bcDkg.png","__typename":"ImageMetadata","originalHeight":251,"originalWidth":899,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*iIN4QSMr7wMlNXyBKSetjA.png":{"id":"1*iIN4QSMr7wMlNXyBKSetjA.png","__typename":"ImageMetadata","originalHeight":436,"originalWidth":446,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*mOKMWpYOxa1WVAMjBTx9zQ.png":{"id":"1*mOKMWpYOxa1WVAMjBTx9zQ.png","__typename":"ImageMetadata","originalHeight":416,"originalWidth":516,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*e76ZuT_WZ5b7oii1Z6U2Hg.png":{"id":"1*e76ZuT_WZ5b7oii1Z6U2Hg.png","__typename":"ImageMetadata","originalHeight":426,"originalWidth":923,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*uiHRj_gyEjXt2gfe1IM_-A.png":{"id":"1*uiHRj_gyEjXt2gfe1IM_-A.png","__typename":"ImageMetadata","originalHeight":174,"originalWidth":930,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*BjKke6AR1e0GMboE7j_p9A.png":{"id":"1*BjKke6AR1e0GMboE7j_p9A.png","__typename":"ImageMetadata","originalHeight":94,"originalWidth":333,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*r_UDMlVDjs1mhmirQKzVww.png":{"id":"1*r_UDMlVDjs1mhmirQKzVww.png","__typename":"ImageMetadata","originalHeight":167,"originalWidth":760,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*aVL6ZAyu5Sz8na5Ih_j9Xw.png":{"id":"1*aVL6ZAyu5Sz8na5Ih_j9Xw.png","__typename":"ImageMetadata","originalHeight":345,"originalWidth":982,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*9bK3_8ze-b9VlnYOG_gDLg.png":{"id":"1*9bK3_8ze-b9VlnYOG_gDLg.png","__typename":"ImageMetadata","originalHeight":349,"originalWidth":325,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*wuocbRF1SCcn4T9nWu1How.png":{"id":"1*wuocbRF1SCcn4T9nWu1How.png","__typename":"ImageMetadata","originalHeight":2076,"originalWidth":9116,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*JuRaL9ctaDmtu2tp04z9Ow.png":{"id":"1*JuRaL9ctaDmtu2tp04z9Ow.png","__typename":"ImageMetadata","originalHeight":346,"originalWidth":396,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*zH_VMTYEkW4S4bQV8otJwQ.png":{"id":"1*zH_VMTYEkW4S4bQV8otJwQ.png","__typename":"ImageMetadata","originalHeight":2090,"originalWidth":11352,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*yAgm8mkXygh0xPOwn7ShIA.png":{"id":"1*yAgm8mkXygh0xPOwn7ShIA.png","__typename":"ImageMetadata","originalHeight":384,"originalWidth":1665,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*8ZS-s3MtE65XRe4UR2rTbA.png":{"id":"1*8ZS-s3MtE65XRe4UR2rTbA.png","__typename":"ImageMetadata","originalHeight":99,"originalWidth":335,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*7Q3Tp8kkfg4KFadz91ZCMg.png":{"id":"1*7Q3Tp8kkfg4KFadz91ZCMg.png","__typename":"ImageMetadata","originalHeight":81,"originalWidth":341,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*6ROdmZrIrE555SpD9RbRFA.png":{"id":"1*6ROdmZrIrE555SpD9RbRFA.png","__typename":"ImageMetadata","originalHeight":46,"originalWidth":481,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*Ng1EmRt_d9C1V4vkFTAbPg.png":{"id":"1*Ng1EmRt_d9C1V4vkFTAbPg.png","__typename":"ImageMetadata","originalHeight":125,"originalWidth":1306,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*I9KcNU4MyBHA8I-mY37WSA.png":{"id":"1*I9KcNU4MyBHA8I-mY37WSA.png","__typename":"ImageMetadata","originalHeight":125,"originalWidth":444,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*dEQwtsopQPMvOwWowZmkjw.png":{"id":"1*dEQwtsopQPMvOwWowZmkjw.png","__typename":"ImageMetadata","originalHeight":93,"originalWidth":239,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*-4acIO34XcSMnAEaD57PBg.png":{"id":"1*-4acIO34XcSMnAEaD57PBg.png","__typename":"ImageMetadata","originalHeight":225,"originalWidth":520,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*jM-bLyiuT9sPTldAv2Cdkg.png":{"id":"1*jM-bLyiuT9sPTldAv2Cdkg.png","__typename":"ImageMetadata","originalHeight":235,"originalWidth":1398,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*3e1Kujclq4go-NUPHLJggw.png":{"id":"1*3e1Kujclq4go-NUPHLJggw.png","__typename":"ImageMetadata","originalHeight":167,"originalWidth":125,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*HtSNcvLj1ZsE7vZBK-ywLQ.png":{"id":"1*HtSNcvLj1ZsE7vZBK-ywLQ.png","__typename":"ImageMetadata","originalHeight":140,"originalWidth":1449,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*pJJt_QfgW_TjgiQwgjEFRg.png":{"id":"1*pJJt_QfgW_TjgiQwgjEFRg.png","__typename":"ImageMetadata","originalHeight":1371,"originalWidth":1607,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*rfyc876v-QFXu1hwpdKQTw.png":{"id":"1*rfyc876v-QFXu1hwpdKQTw.png","__typename":"ImageMetadata","originalHeight":1021,"originalWidth":1602,"focusPercentX":null,"focusPercentY":null,"alt":null},"MediaResource:3f6cc7d3df30cdefef92c512b2b6a59d":{"id":"3f6cc7d3df30cdefef92c512b2b6a59d","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":""},"MediaResource:6fdd37fa6e1a8c8def59f05f907f0904":{"id":"6fdd37fa6e1a8c8def59f05f907f0904","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"One run of the full EM algorithm for the Multinomial Mixture Model"},"MediaResource:5a98cf6bf4f43ef39ec9ccbe343ed1c7":{"id":"5a98cf6bf4f43ef39ec9ccbe343ed1c7","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"Compute variational lower bound"},"MediaResource:6298f6ad491788bc853498dc6769a678":{"id":"6298f6ad491788bc853498dc6769a678","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"Perform the e-step of the EM algorithm for the Multinomial Mixture Model"},"MediaResource:0615710f8cabb6398c9e04d420f9f4a3":{"id":"0615710f8cabb6398c9e04d420f9f4a3","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"Perform the m-step of the EM algorithm for Multinomial Mixture Model"},"MediaResource:7c76fd2c8cab46d9073b61667181ac79":{"id":"7c76fd2c8cab46d9073b61667181ac79","__typename":"MediaResource","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"Generate observations comming from a mixture multinomials"},"ImageMetadata:1*0ievWD0wxc_b3JMQMjfiYg.png":{"id":"1*0ievWD0wxc_b3JMQMjfiYg.png","__typename":"ImageMetadata","originalHeight":123,"originalWidth":684,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*X4CdRc1i5NptX-wm-8VMEw.png":{"id":"1*X4CdRc1i5NptX-wm-8VMEw.png","__typename":"ImageMetadata","originalHeight":447,"originalWidth":921,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*9AQTAvJLmVA6vD3V696xeQ.png":{"id":"1*9AQTAvJLmVA6vD3V696xeQ.png","__typename":"ImageMetadata","originalHeight":128,"originalWidth":950,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*NeD3pmWGI8K40XU8ea94Vw.png":{"id":"1*NeD3pmWGI8K40XU8ea94Vw.png","__typename":"ImageMetadata","originalHeight":129,"originalWidth":689,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*k7rZdMsG5KSwy9vyg2yOzQ.png":{"id":"1*k7rZdMsG5KSwy9vyg2yOzQ.png","__typename":"ImageMetadata","originalHeight":447,"originalWidth":921,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*qCKPXPIzeYf0pZXsSJscqQ.png":{"id":"1*qCKPXPIzeYf0pZXsSJscqQ.png","__typename":"ImageMetadata","originalHeight":121,"originalWidth":948,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*ANHVk81RIsUgJKmlPmTlBg.png":{"id":"1*ANHVk81RIsUgJKmlPmTlBg.png","__typename":"ImageMetadata","originalHeight":125,"originalWidth":684,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*iIJ2D17afFbAMf0nN_7G9Q.png":{"id":"1*iIJ2D17afFbAMf0nN_7G9Q.png","__typename":"ImageMetadata","originalHeight":447,"originalWidth":921,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*ftkh7KPq6ZmqTEU42iswvQ.png":{"id":"1*ftkh7KPq6ZmqTEU42iswvQ.png","__typename":"ImageMetadata","originalHeight":128,"originalWidth":957,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*3YFJ9xogkbMG32jeS2gGnw.png":{"id":"1*3YFJ9xogkbMG32jeS2gGnw.png","__typename":"ImageMetadata","originalHeight":447,"originalWidth":921,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*LSdF8y3iwM_wCyYt4YnEOw.png":{"id":"1*LSdF8y3iwM_wCyYt4YnEOw.png","__typename":"ImageMetadata","originalHeight":65,"originalWidth":324,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*h0_SR1oMDYwMKPEaCeeXoQ.png":{"id":"1*h0_SR1oMDYwMKPEaCeeXoQ.png","__typename":"ImageMetadata","originalHeight":296,"originalWidth":968,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*DFLIs6R3NnOVSi78Jzc7HA.png":{"id":"1*DFLIs6R3NnOVSi78Jzc7HA.png","__typename":"ImageMetadata","originalHeight":319,"originalWidth":960,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*znI_CjZ2QUgyMWrvq2Ax-g.png":{"id":"1*znI_CjZ2QUgyMWrvq2Ax-g.png","__typename":"ImageMetadata","originalHeight":3448,"originalWidth":4600,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*gXShQC60jaZPXphKqFjfzA.png":{"id":"1*gXShQC60jaZPXphKqFjfzA.png","__typename":"ImageMetadata","originalHeight":706,"originalWidth":738,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*qFx44mBDqEUmgBpGD3kJJA.png":{"id":"1*qFx44mBDqEUmgBpGD3kJJA.png","__typename":"ImageMetadata","originalHeight":251,"originalWidth":729,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*otujZVICnoFx2gI1JNjDtg.png":{"id":"1*otujZVICnoFx2gI1JNjDtg.png","__typename":"ImageMetadata","originalHeight":387,"originalWidth":870,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*uGFfYlNpqS_1pNYDvtTIMA.png":{"id":"1*uGFfYlNpqS_1pNYDvtTIMA.png","__typename":"ImageMetadata","originalHeight":381,"originalWidth":640,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*1drRDGZ6kMFqfEfKMeMtew.png":{"id":"1*1drRDGZ6kMFqfEfKMeMtew.png","__typename":"ImageMetadata","originalHeight":183,"originalWidth":301,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*V6uk8AfFggBvRQC6xwKUfw.png":{"id":"1*V6uk8AfFggBvRQC6xwKUfw.png","__typename":"ImageMetadata","originalHeight":1027,"originalWidth":1829,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*-LMoVrAevErSe74z7VdOyw.png":{"id":"1*-LMoVrAevErSe74z7VdOyw.png","__typename":"ImageMetadata","originalHeight":336,"originalWidth":1062,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*tyumD7G7rDOxLscRyXAGuA.png":{"id":"1*tyumD7G7rDOxLscRyXAGuA.png","__typename":"ImageMetadata","originalHeight":94,"originalWidth":241,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*5LXPWsJCbYAKlt5X8Fe8ow.png":{"id":"1*5LXPWsJCbYAKlt5X8Fe8ow.png","__typename":"ImageMetadata","originalHeight":377,"originalWidth":729,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*Ur17gnm5gLR_UXVr7RNkcA.png":{"id":"1*Ur17gnm5gLR_UXVr7RNkcA.png","__typename":"ImageMetadata","originalHeight":1348,"originalWidth":1755,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*YSh55lFuFEf0gPTWAEWjmg.png":{"id":"1*YSh55lFuFEf0gPTWAEWjmg.png","__typename":"ImageMetadata","originalHeight":114,"originalWidth":750,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*6UoHeOYd3AZi4sDjpoo_oA.png":{"id":"1*6UoHeOYd3AZi4sDjpoo_oA.png","__typename":"ImageMetadata","originalHeight":95,"originalWidth":387,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*v--WQdUV1T5lkEIA7nduRg.png":{"id":"1*v--WQdUV1T5lkEIA7nduRg.png","__typename":"ImageMetadata","originalHeight":409,"originalWidth":1852,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*xEmCBFXmKraDfyBYIhOvMQ.png":{"id":"1*xEmCBFXmKraDfyBYIhOvMQ.png","__typename":"ImageMetadata","originalHeight":121,"originalWidth":912,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*xqg_YR66YOAc2iSxwfwDgg.png":{"id":"1*xqg_YR66YOAc2iSxwfwDgg.png","__typename":"ImageMetadata","originalHeight":386,"originalWidth":712,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*CkTyI1pWbXQVdo4hTK6bAw.png":{"id":"1*CkTyI1pWbXQVdo4hTK6bAw.png","__typename":"ImageMetadata","originalHeight":116,"originalWidth":678,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*cJemSVHEKwgsolEewhuM5g.png":{"id":"1*cJemSVHEKwgsolEewhuM5g.png","__typename":"ImageMetadata","originalHeight":897,"originalWidth":1852,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*aNpWWUrHsR1PKi3Fb1p1Kw.png":{"id":"1*aNpWWUrHsR1PKi3Fb1p1Kw.png","__typename":"ImageMetadata","originalHeight":897,"originalWidth":1852,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*R1RG3jt08tAT1wzm-w8pvg.png":{"id":"1*R1RG3jt08tAT1wzm-w8pvg.png","__typename":"ImageMetadata","originalHeight":112,"originalWidth":454,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*KkO5iljTJfOAEBI8Y_U6Pw.png":{"id":"1*KkO5iljTJfOAEBI8Y_U6Pw.png","__typename":"ImageMetadata","originalHeight":203,"originalWidth":289,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*rxUwb6IusG9HXqLUEzQWvA.png":{"id":"1*rxUwb6IusG9HXqLUEzQWvA.png","__typename":"ImageMetadata","originalHeight":333,"originalWidth":960,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*iPqLaNdgr-mLZmjRXTQhRg.png":{"id":"1*iPqLaNdgr-mLZmjRXTQhRg.png","__typename":"ImageMetadata","originalHeight":897,"originalWidth":1852,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*DsUVBjPxelX47EEzZL7VQA.png":{"id":"1*DsUVBjPxelX47EEzZL7VQA.png","__typename":"ImageMetadata","originalHeight":897,"originalWidth":1852,"focusPercentX":null,"focusPercentY":null,"alt":null},"ImageMetadata:1*VZyxi-Lujf_iUllFoBJdYA.png":{"id":"1*VZyxi-Lujf_iUllFoBJdYA.png","__typename":"ImageMetadata","originalHeight":589,"originalWidth":615,"focusPercentX":null,"focusPercentY":null,"alt":null},"Tag:bayesian-statistics":{"id":"bayesian-statistics","__typename":"Tag","displayTitle":"Bayesian Statistics"},"Tag:marketing":{"id":"marketing","__typename":"Tag","displayTitle":"Marketing"},"Tag:statistics":{"id":"statistics","__typename":"Tag","displayTitle":"Statistics"},"Tag:machine-learning":{"id":"machine-learning","__typename":"Tag","displayTitle":"Machine Learning"},"Tag:mixture-models":{"id":"mixture-models","__typename":"Tag","displayTitle":"Mixture Models"},"ImageMetadata:1*t8Ls5sYb8pQtEVHVhk-GOA.jpeg":{"id":"1*t8Ls5sYb8pQtEVHVhk-GOA.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:4cbd6b36e62a":{"id":"4cbd6b36e62a","__typename":"User","name":"Martin Heinz","username":"martin.heinz","bio":"Certified Red Hat Professional | DevOps Engineer at IBM | Working with Python, JavaScript, Kubernetes, OpenShift, Docker and more | https:\u002F\u002Fmartinheinz.dev\u002F","isFollowing":false,"imageId":"2*p3sIQ1Ga2bfAbZYzoCcACw.jpeg","mediumMemberAt":0,"hasDomain":false},"Post:5cfec8eff833":{"id":"5cfec8eff833","__typename":"Post","title":"You Don’t Have to Use Docker Anymore","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fits-time-to-say-goodbye-to-docker-5cfec8eff833","previewImage":{"__ref":"ImageMetadata:1*t8Ls5sYb8pQtEVHVhk-GOA.jpeg"},"isPublished":true,"firstPublishedAt":1602768560983,"readingTime":9.369811320754716,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:4cbd6b36e62a"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*5Q1joBvY2S01IeMz":{"id":"0*5Q1joBvY2S01IeMz","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:135dac1d8e6":{"id":"135dac1d8e6","__typename":"User","name":"Jason Dsouza","username":"jasmcaus","bio":"At the crossroads of technology, vision and human-centred AI. None of it matters if we don’t fix the planet.","isFollowing":false,"imageId":"1*-Y7DB5pfxgVg2tAJmEklCg.jpeg","mediumMemberAt":0,"hasDomain":false},"Post:9ca652726492":{"id":"9ca652726492","__typename":"Post","title":"Python is Slowly Losing its Charm","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fpython-is-slowly-losing-its-charm-9ca652726492","previewImage":{"__ref":"ImageMetadata:0*5Q1joBvY2S01IeMz"},"isPublished":true,"firstPublishedAt":1601978215724,"readingTime":3.719811320754717,"statusForCollection":"APPROVED","isLocked":false,"isShortform":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:135dac1d8e6"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*pNloJM4kaHbQx19G":{"id":"0*pNloJM4kaHbQx19G","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:db4a0d3b48c1":{"id":"db4a0d3b48c1","__typename":"User","name":"Dasaradh S K","username":"skdasaradh","bio":"ML\u002FDL Enthusiast | LinkedIn: https:\u002F\u002Fwww.linkedin.com\u002Fin\u002Fdasaradhsk\u002F","isFollowing":false,"imageId":"1*m0tPZA4MVOHcEQZnvX_qQQ.jpeg","mediumMemberAt":0,"hasDomain":true},"Post:71890baa8c47":{"id":"71890baa8c47","__typename":"Post","title":"Go Programming Language for Artificial Intelligence and Data Science of the 20s","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fgolang-ai-programming-language-for-the-20s-71890baa8c47","previewImage":{"__ref":"ImageMetadata:0*pNloJM4kaHbQx19G"},"isPublished":true,"firstPublishedAt":1602298004022,"readingTime":3.761320754716981,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:db4a0d3b48c1"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*0dbUWoessUtJHUsO4qkpJQ.png":{"id":"1*0dbUWoessUtJHUsO4qkpJQ.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:2fccb851bb5e":{"id":"2fccb851bb5e","__typename":"User","name":"Cassie Kozyrkov","username":"kozyrkov","bio":"Head of Decision Intelligence, Google. ❤️ Stats, ML\u002FAI, data, puns, art, theatre, decision science. All views are my own. twitter.com\u002Fquaesita","isFollowing":false,"imageId":"1*IL0mnvzNcpG2ZD0JBqo7zQ.jpeg","mediumMemberAt":1568389090000,"hasDomain":false},"Post:85785c991433":{"id":"85785c991433","__typename":"Post","title":"How to spot a data charlatan","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fhow-to-spot-a-data-charlatan-85785c991433","previewImage":{"__ref":"ImageMetadata:1*0dbUWoessUtJHUsO4qkpJQ.png"},"isPublished":true,"firstPublishedAt":1602247921764,"readingTime":7.938679245283019,"statusForCollection":"APPROVED","isLocked":false,"isShortform":false,"visibility":"PUBLIC","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:2fccb851bb5e"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*49w_B1vpnCgQx8C2TA7CUw.png":{"id":"1*49w_B1vpnCgQx8C2TA7CUw.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:d9b237bc89f0":{"id":"d9b237bc89f0","__typename":"User","name":"Farhad Malik","username":"farhadmalik","bio":"My personal blog, aiming to explain complex mathematical, financial and technological concepts in simple terms. Contact: FarhadMalik84@googlemail.com","isFollowing":false,"imageId":"1*7MhP4LsHsl3G_oE3LBVlsg.jpeg","mediumMemberAt":0,"hasDomain":false},"Post:b8c27f5eba5c":{"id":"b8c27f5eba5c","__typename":"Post","title":"10 Awesome Python 3.9 Features","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002F10-awesome-python-3-9-features-b8c27f5eba5c","previewImage":{"__ref":"ImageMetadata:1*49w_B1vpnCgQx8C2TA7CUw.png"},"isPublished":true,"firstPublishedAt":1601847709960,"readingTime":10.255974842767296,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:d9b237bc89f0"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*rhWS22PAJaqMJQYJDL0y-A.jpeg":{"id":"1*rhWS22PAJaqMJQYJDL0y-A.jpeg","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:2caa691701c0":{"id":"2caa691701c0","__typename":"User","name":"Nicole Janeway Bills","username":"nicolejaneway","bio":"Data Scientist at Atlas Research in Washington, DC | Flatiron Bootcamp grad | Quarantining in a Python virtual environment","isFollowing":false,"imageId":"2*UVCEt3tjr0W9zC3dymCPtQ.jpeg","mediumMemberAt":0,"hasDomain":false},"Post:dfdff5741fdf":{"id":"dfdff5741fdf","__typename":"Post","title":"10 Underrated Python Skills","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002F10-underrated-python-skills-dfdff5741fdf","previewImage":{"__ref":"ImageMetadata:1*rhWS22PAJaqMJQYJDL0y-A.jpeg"},"isPublished":true,"firstPublishedAt":1602622502372,"readingTime":8.912578616352201,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:2caa691701c0"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:0*lG7s6Lf_SiRpxtti":{"id":"0*lG7s6Lf_SiRpxtti","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:b9d77a4ca1d1":{"id":"b9d77a4ca1d1","__typename":"User","name":"James Calam","username":"jamescalam","bio":"Top writer on Medium. Tech consultant learning and writing about everything.","isFollowing":false,"imageId":"1*Yfx03gStkSdDc3Ov3Zo-0w.png","mediumMemberAt":1594744211000,"hasDomain":true},"Post:9c2ce1332eb4":{"id":"9c2ce1332eb4","__typename":"Post","title":"Python 3.9","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fpython-3-9-9c2ce1332eb4","previewImage":{"__ref":"ImageMetadata:0*lG7s6Lf_SiRpxtti"},"isPublished":true,"firstPublishedAt":1601657252427,"readingTime":4.365094339622641,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:b9d77a4ca1d1"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"ImageMetadata:1*ofX7aZroN2tkwOjJhECmNQ.png":{"id":"1*ofX7aZroN2tkwOjJhECmNQ.png","__typename":"ImageMetadata","focusPercentX":null,"focusPercentY":null},"User:b89dbc0712c4":{"id":"b89dbc0712c4","__typename":"User","name":"Matthew Stewart, PhD Researcher","username":"matthew_stewart","bio":"Environmental\u002FData Science Ph.D. Candidate at Harvard University | Machine learning consultant at Critical Future | Blogger at TDS. https:\u002F\u002Fmpstewart.net","isFollowing":false,"imageId":"2*AiKFMI6FEyDWnNMtiPAr1A.jpeg","mediumMemberAt":0,"hasDomain":false},"Post:495c26463868":{"id":"495c26463868","__typename":"Post","title":"Tiny Machine Learning: The Next AI Revolution","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Ftiny-machine-learning-the-next-ai-revolution-495c26463868","previewImage":{"__ref":"ImageMetadata:1*ofX7aZroN2tkwOjJhECmNQ.png"},"isPublished":true,"firstPublishedAt":1601598031040,"readingTime":15.038993710691823,"statusForCollection":"APPROVED","isLocked":true,"isShortform":false,"visibility":"LOCKED","collection":{"__ref":"Collection:7f60cf5620c9"},"creator":{"__ref":"User:b89dbc0712c4"},"previewContent":{"__typename":"PreviewContent","isFullContent":false}},"Post:268974d905da":{"id":"268974d905da","__typename":"Post","canonicalUrl":"","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","bodyModel":{"__typename":"RichText","paragraphs":[{"__ref":"Paragraph:1730e030f188_0"},{"__ref":"Paragraph:1730e030f188_1"},{"__ref":"Paragraph:1730e030f188_2"},{"__ref":"Paragraph:1730e030f188_3"},{"__ref":"Paragraph:1730e030f188_4"},{"__ref":"Paragraph:1730e030f188_5"},{"__ref":"Paragraph:1730e030f188_6"},{"__ref":"Paragraph:1730e030f188_7"},{"__ref":"Paragraph:1730e030f188_8"},{"__ref":"Paragraph:1730e030f188_9"},{"__ref":"Paragraph:1730e030f188_10"},{"__ref":"Paragraph:1730e030f188_11"},{"__ref":"Paragraph:1730e030f188_12"},{"__ref":"Paragraph:1730e030f188_13"},{"__ref":"Paragraph:1730e030f188_14"},{"__ref":"Paragraph:1730e030f188_15"},{"__ref":"Paragraph:1730e030f188_16"},{"__ref":"Paragraph:1730e030f188_17"},{"__ref":"Paragraph:1730e030f188_18"},{"__ref":"Paragraph:1730e030f188_19"},{"__ref":"Paragraph:1730e030f188_20"},{"__ref":"Paragraph:1730e030f188_21"},{"__ref":"Paragraph:1730e030f188_22"},{"__ref":"Paragraph:1730e030f188_23"},{"__ref":"Paragraph:1730e030f188_24"},{"__ref":"Paragraph:1730e030f188_25"},{"__ref":"Paragraph:1730e030f188_26"},{"__ref":"Paragraph:1730e030f188_27"},{"__ref":"Paragraph:1730e030f188_28"},{"__ref":"Paragraph:1730e030f188_29"},{"__ref":"Paragraph:1730e030f188_30"},{"__ref":"Paragraph:1730e030f188_31"},{"__ref":"Paragraph:1730e030f188_32"},{"__ref":"Paragraph:1730e030f188_33"},{"__ref":"Paragraph:1730e030f188_34"},{"__ref":"Paragraph:1730e030f188_35"},{"__ref":"Paragraph:1730e030f188_36"},{"__ref":"Paragraph:1730e030f188_37"},{"__ref":"Paragraph:1730e030f188_38"},{"__ref":"Paragraph:1730e030f188_39"},{"__ref":"Paragraph:1730e030f188_40"},{"__ref":"Paragraph:1730e030f188_41"},{"__ref":"Paragraph:1730e030f188_42"},{"__ref":"Paragraph:1730e030f188_43"},{"__ref":"Paragraph:1730e030f188_44"},{"__ref":"Paragraph:1730e030f188_45"},{"__ref":"Paragraph:1730e030f188_46"},{"__ref":"Paragraph:1730e030f188_47"},{"__ref":"Paragraph:1730e030f188_48"},{"__ref":"Paragraph:1730e030f188_49"},{"__ref":"Paragraph:1730e030f188_50"},{"__ref":"Paragraph:1730e030f188_51"},{"__ref":"Paragraph:1730e030f188_52"},{"__ref":"Paragraph:1730e030f188_53"},{"__ref":"Paragraph:1730e030f188_54"},{"__ref":"Paragraph:1730e030f188_55"},{"__ref":"Paragraph:1730e030f188_56"},{"__ref":"Paragraph:1730e030f188_57"},{"__ref":"Paragraph:1730e030f188_58"},{"__ref":"Paragraph:1730e030f188_59"},{"__ref":"Paragraph:1730e030f188_60"},{"__ref":"Paragraph:1730e030f188_61"},{"__ref":"Paragraph:1730e030f188_62"},{"__ref":"Paragraph:1730e030f188_63"},{"__ref":"Paragraph:1730e030f188_64"},{"__ref":"Paragraph:1730e030f188_65"},{"__ref":"Paragraph:1730e030f188_66"},{"__ref":"Paragraph:1730e030f188_67"},{"__ref":"Paragraph:1730e030f188_68"},{"__ref":"Paragraph:1730e030f188_69"},{"__ref":"Paragraph:1730e030f188_70"},{"__ref":"Paragraph:1730e030f188_71"},{"__ref":"Paragraph:1730e030f188_72"},{"__ref":"Paragraph:1730e030f188_73"},{"__ref":"Paragraph:1730e030f188_74"},{"__ref":"Paragraph:1730e030f188_75"},{"__ref":"Paragraph:1730e030f188_76"},{"__ref":"Paragraph:1730e030f188_77"},{"__ref":"Paragraph:1730e030f188_78"},{"__ref":"Paragraph:1730e030f188_79"},{"__ref":"Paragraph:1730e030f188_80"},{"__ref":"Paragraph:1730e030f188_81"},{"__ref":"Paragraph:1730e030f188_82"},{"__ref":"Paragraph:1730e030f188_83"},{"__ref":"Paragraph:1730e030f188_84"},{"__ref":"Paragraph:1730e030f188_85"},{"__ref":"Paragraph:1730e030f188_86"},{"__ref":"Paragraph:1730e030f188_87"},{"__ref":"Paragraph:1730e030f188_88"},{"__ref":"Paragraph:1730e030f188_89"},{"__ref":"Paragraph:1730e030f188_90"},{"__ref":"Paragraph:1730e030f188_91"},{"__ref":"Paragraph:1730e030f188_92"},{"__ref":"Paragraph:1730e030f188_93"},{"__ref":"Paragraph:1730e030f188_94"},{"__ref":"Paragraph:1730e030f188_95"},{"__ref":"Paragraph:1730e030f188_96"},{"__ref":"Paragraph:1730e030f188_97"},{"__ref":"Paragraph:1730e030f188_98"},{"__ref":"Paragraph:1730e030f188_99"},{"__ref":"Paragraph:1730e030f188_100"},{"__ref":"Paragraph:1730e030f188_101"},{"__ref":"Paragraph:1730e030f188_102"},{"__ref":"Paragraph:1730e030f188_103"},{"__ref":"Paragraph:1730e030f188_104"},{"__ref":"Paragraph:1730e030f188_105"},{"__ref":"Paragraph:1730e030f188_106"},{"__ref":"Paragraph:1730e030f188_107"},{"__ref":"Paragraph:1730e030f188_108"},{"__ref":"Paragraph:1730e030f188_109"},{"__ref":"Paragraph:1730e030f188_110"},{"__ref":"Paragraph:1730e030f188_111"},{"__ref":"Paragraph:1730e030f188_112"},{"__ref":"Paragraph:1730e030f188_113"},{"__ref":"Paragraph:1730e030f188_114"},{"__ref":"Paragraph:1730e030f188_115"},{"__ref":"Paragraph:1730e030f188_116"},{"__ref":"Paragraph:1730e030f188_117"},{"__ref":"Paragraph:1730e030f188_118"},{"__ref":"Paragraph:1730e030f188_119"},{"__ref":"Paragraph:1730e030f188_120"},{"__ref":"Paragraph:1730e030f188_121"},{"__ref":"Paragraph:1730e030f188_122"},{"__ref":"Paragraph:1730e030f188_123"},{"__ref":"Paragraph:1730e030f188_124"},{"__ref":"Paragraph:1730e030f188_125"},{"__ref":"Paragraph:1730e030f188_126"},{"__ref":"Paragraph:1730e030f188_127"},{"__ref":"Paragraph:1730e030f188_128"},{"__ref":"Paragraph:1730e030f188_129"},{"__ref":"Paragraph:1730e030f188_130"},{"__ref":"Paragraph:1730e030f188_131"},{"__ref":"Paragraph:1730e030f188_132"},{"__ref":"Paragraph:1730e030f188_133"},{"__ref":"Paragraph:1730e030f188_134"},{"__ref":"Paragraph:1730e030f188_135"},{"__ref":"Paragraph:1730e030f188_136"},{"__ref":"Paragraph:1730e030f188_137"},{"__ref":"Paragraph:1730e030f188_138"},{"__ref":"Paragraph:1730e030f188_139"},{"__ref":"Paragraph:1730e030f188_140"},{"__ref":"Paragraph:1730e030f188_141"},{"__ref":"Paragraph:1730e030f188_142"},{"__ref":"Paragraph:1730e030f188_143"},{"__ref":"Paragraph:1730e030f188_144"},{"__ref":"Paragraph:1730e030f188_145"},{"__ref":"Paragraph:1730e030f188_146"},{"__ref":"Paragraph:1730e030f188_147"},{"__ref":"Paragraph:1730e030f188_148"},{"__ref":"Paragraph:1730e030f188_149"},{"__ref":"Paragraph:1730e030f188_150"},{"__ref":"Paragraph:1730e030f188_151"},{"__ref":"Paragraph:1730e030f188_152"},{"__ref":"Paragraph:1730e030f188_153"},{"__ref":"Paragraph:1730e030f188_154"},{"__ref":"Paragraph:1730e030f188_155"},{"__ref":"Paragraph:1730e030f188_156"},{"__ref":"Paragraph:1730e030f188_157"},{"__ref":"Paragraph:1730e030f188_158"},{"__ref":"Paragraph:1730e030f188_159"},{"__ref":"Paragraph:1730e030f188_160"},{"__ref":"Paragraph:1730e030f188_161"},{"__ref":"Paragraph:1730e030f188_162"},{"__ref":"Paragraph:1730e030f188_163"},{"__ref":"Paragraph:1730e030f188_164"},{"__ref":"Paragraph:1730e030f188_165"},{"__ref":"Paragraph:1730e030f188_166"},{"__ref":"Paragraph:1730e030f188_167"},{"__ref":"Paragraph:1730e030f188_168"},{"__ref":"Paragraph:1730e030f188_169"},{"__ref":"Paragraph:1730e030f188_170"},{"__ref":"Paragraph:1730e030f188_171"},{"__ref":"Paragraph:1730e030f188_172"},{"__ref":"Paragraph:1730e030f188_173"},{"__ref":"Paragraph:1730e030f188_174"},{"__ref":"Paragraph:1730e030f188_175"},{"__ref":"Paragraph:1730e030f188_176"},{"__ref":"Paragraph:1730e030f188_177"},{"__ref":"Paragraph:1730e030f188_178"},{"__ref":"Paragraph:1730e030f188_179"},{"__ref":"Paragraph:1730e030f188_180"},{"__ref":"Paragraph:1730e030f188_181"},{"__ref":"Paragraph:1730e030f188_182"},{"__ref":"Paragraph:1730e030f188_183"},{"__ref":"Paragraph:1730e030f188_184"},{"__ref":"Paragraph:1730e030f188_185"},{"__ref":"Paragraph:1730e030f188_186"},{"__ref":"Paragraph:1730e030f188_187"},{"__ref":"Paragraph:1730e030f188_188"},{"__ref":"Paragraph:1730e030f188_189"},{"__ref":"Paragraph:1730e030f188_190"},{"__ref":"Paragraph:1730e030f188_191"},{"__ref":"Paragraph:1730e030f188_192"},{"__ref":"Paragraph:1730e030f188_193"},{"__ref":"Paragraph:1730e030f188_194"},{"__ref":"Paragraph:1730e030f188_195"},{"__ref":"Paragraph:1730e030f188_196"},{"__ref":"Paragraph:1730e030f188_197"},{"__ref":"Paragraph:1730e030f188_198"},{"__ref":"Paragraph:1730e030f188_199"},{"__ref":"Paragraph:1730e030f188_200"},{"__ref":"Paragraph:1730e030f188_201"},{"__ref":"Paragraph:1730e030f188_202"},{"__ref":"Paragraph:1730e030f188_203"},{"__ref":"Paragraph:1730e030f188_204"},{"__ref":"Paragraph:1730e030f188_205"},{"__ref":"Paragraph:1730e030f188_206"},{"__ref":"Paragraph:1730e030f188_207"},{"__ref":"Paragraph:1730e030f188_208"},{"__ref":"Paragraph:1730e030f188_209"},{"__ref":"Paragraph:1730e030f188_210"},{"__ref":"Paragraph:1730e030f188_211"},{"__ref":"Paragraph:1730e030f188_212"},{"__ref":"Paragraph:1730e030f188_213"},{"__ref":"Paragraph:1730e030f188_214"},{"__ref":"Paragraph:1730e030f188_215"},{"__ref":"Paragraph:1730e030f188_216"},{"__ref":"Paragraph:1730e030f188_217"},{"__ref":"Paragraph:1730e030f188_218"},{"__ref":"Paragraph:1730e030f188_219"},{"__ref":"Paragraph:1730e030f188_220"},{"__ref":"Paragraph:1730e030f188_221"},{"__ref":"Paragraph:1730e030f188_222"},{"__ref":"Paragraph:1730e030f188_223"},{"__ref":"Paragraph:1730e030f188_224"},{"__ref":"Paragraph:1730e030f188_225"},{"__ref":"Paragraph:1730e030f188_226"},{"__ref":"Paragraph:1730e030f188_227"},{"__ref":"Paragraph:1730e030f188_228"},{"__ref":"Paragraph:1730e030f188_229"},{"__ref":"Paragraph:1730e030f188_230"},{"__ref":"Paragraph:1730e030f188_231"},{"__ref":"Paragraph:1730e030f188_232"},{"__ref":"Paragraph:1730e030f188_233"},{"__ref":"Paragraph:1730e030f188_234"},{"__ref":"Paragraph:1730e030f188_235"},{"__ref":"Paragraph:1730e030f188_236"},{"__ref":"Paragraph:1730e030f188_237"},{"__ref":"Paragraph:1730e030f188_238"},{"__ref":"Paragraph:1730e030f188_239"},{"__ref":"Paragraph:1730e030f188_240"},{"__ref":"Paragraph:1730e030f188_241"},{"__ref":"Paragraph:1730e030f188_242"},{"__ref":"Paragraph:1730e030f188_243"},{"__ref":"Paragraph:1730e030f188_244"},{"__ref":"Paragraph:1730e030f188_245"},{"__ref":"Paragraph:1730e030f188_246"},{"__ref":"Paragraph:1730e030f188_247"},{"__ref":"Paragraph:1730e030f188_248"},{"__ref":"Paragraph:1730e030f188_249"},{"__ref":"Paragraph:1730e030f188_250"},{"__ref":"Paragraph:1730e030f188_251"},{"__ref":"Paragraph:1730e030f188_252"},{"__ref":"Paragraph:1730e030f188_253"},{"__ref":"Paragraph:1730e030f188_254"},{"__ref":"Paragraph:1730e030f188_255"},{"__ref":"Paragraph:1730e030f188_256"},{"__ref":"Paragraph:1730e030f188_257"},{"__ref":"Paragraph:1730e030f188_258"},{"__ref":"Paragraph:1730e030f188_259"},{"__ref":"Paragraph:1730e030f188_260"},{"__ref":"Paragraph:1730e030f188_261"}],"sections":[{"__typename":"Section","name":"f824","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}]}},"creator":{"__ref":"User:151fca431deb"},"customStyleSheet":null,"firstPublishedAt":1602687675741,"isLocked":true,"isPublished":true,"isShortform":false,"isEmail":false,"layerCake":3,"primaryTopic":{"__typename":"Topic","name":"Machine Learning","slug":"machine-learning","isFollowing":null},"title":"Multinomial Mixture Model for Supermarket Shoppers Segmentation (A complete tutorial)","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fmultinomial-mixture-model-for-supermarket-shoppers-segmentation-a-complete-tutorial-268974d905da","isLimitedState":false,"visibility":"LOCKED","license":"ALL_RIGHTS_RESERVED","allowResponses":true,"newsletterId":"","sequence":null,"tags":[{"__ref":"Tag:bayesian-statistics"},{"__ref":"Tag:marketing"},{"__ref":"Tag:statistics"},{"__ref":"Tag:machine-learning"},{"__ref":"Tag:mixture-models"}],"topics":[{"__typename":"Topic","topicId":"1eca0103fff3","name":"Machine Learning","slug":"machine-learning"},{"__typename":"Topic","topicId":"7808efc0cf94","name":"Math","slug":"math"},{"__typename":"Topic","topicId":"ae5d4995e225","name":"Data Science","slug":"data-science"}],"viewerClapCount":0,"inResponseToPostResult":null,"socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1602821996407,"readingTime":30.20188679245283,"previewContent":{"__typename":"PreviewContent","subtitle":"Complete analysis and implementation of a multinomial mixture model for supermarket shopper segmentation and predictive profiles prediction"},"previewImage":{"__ref":"ImageMetadata:0*x_whGwu1M7rsjHAM"},"creatorPartnerProgramEnrollmentStatus":"PERMISSION_DENIED","clapCount":40,"lockedSource":"LOCKED_POST_SOURCE_UGC","isSuspended":false,"nextPostId":"1f73401e52e0","pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"pinnedByCreatorAt":0,"responsesCount":0,"internalLinks({\"paging\":{\"limit\":8}})":{"__typename":"InternalLinksConnection","items":[{"__ref":"Post:5cfec8eff833"},{"__ref":"Post:9ca652726492"},{"__ref":"Post:71890baa8c47"},{"__ref":"Post:85785c991433"},{"__ref":"Post:b8c27f5eba5c"},{"__ref":"Post:dfdff5741fdf"},{"__ref":"Post:9c2ce1332eb4"},{"__ref":"Post:495c26463868"}]},"collaborators":[],"translationSourcePost":null,"inResponseToMediaResource":null,"curationEligibleAt":1602687673692,"isDistributionAlertDismissed":false,"audioVersionUrl":"","seoTitle":"","updatedAt":1602822005633,"shortformType":"SHORTFORM_TYPE_LINK","structuredData":"","seoDescription":"","postResponses":{"__typename":"PostResponses","count":0},"latestPublishedVersion":"1730e030f188","readingList":"READING_LIST_NONE","voterCount":14,"recommenders":[],"shareKey":null}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.ca6c97ed.js"></script><script src="https://cdn-client.medium.com/lite/static/js/vendors~main.dcfe56d4.chunk.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.39cf8597.chunk.js"></script><script src="https://cdn-client.medium.com/lite/static/js/vendors~instrumentation.7f992f90.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/instrumentation.acd8fd3c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.ffa3aeeb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/vendors~AMPPost~CollectionAbout~CollectionHomepage~CollectionHomepagePreview~CollectionNewShortformE~74d53cd4.ee0a8adb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/vendors~AMPPost~CollectionHomepage~CollectionHomepagePreview~CollectionStyleEditor~CollectionTagged~~42f7530a.0dd746e8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/vendors~AMPPost~CollectionNewShortformEditor~CollectionPostShortformEditor~DebugCachedPost~Post~Sequ~19f09bd3.1bf7a765.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/AMPPost~CollectionHomepage~CollectionHomepagePreview~CollectionNewShortformEditor~CollectionPostShor~250d4f3e.3840d390.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/Post.b333ab44.chunk.js"></script><script>window.main();</script></body></html>